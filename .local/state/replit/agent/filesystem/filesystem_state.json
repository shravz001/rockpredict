{"file_contents":{"app.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom datetime import datetime, timedelta\nimport time\nimport json\nimport os\n\n# Import custom modules\nfrom models.rockfall_predictor import RockfallPredictor\nfrom data.synthetic_data_generator import SyntheticDataGenerator\nfrom visualization.mine_3d_viz import Mine3DVisualizer\nfrom alerts.notification_system import NotificationSystem\nfrom communication.lorawan_simulator import LoRaWANSimulator\nfrom utils.config_manager import ConfigManager\nfrom dashboard.real_time_dashboard import RealTimeDashboard\nfrom dashboard.drone_dashboard import DroneDashboard\nfrom analysis.historical_analysis import HistoricalAnalysis\nfrom database.database_manager import get_rockfall_db\n\n# Configure page\nst.set_page_config(\n    page_title=\"AI Rockfall Prediction System\",\n    page_icon=\"‚õèÔ∏è\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Load custom CSS for professional styling\ndef load_css():\n    try:\n        with open('assets/style.css') as f:\n            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n    except FileNotFoundError:\n        # Clean, classic styling\n        st.markdown(\"\"\"\n        <style>\n        .main .block-container {\n            padding: 2rem;\n            background: #ffffff;\n            max-width: 1200px;\n        }\n        .main h1, .main h2, .main h3 {\n            color: #2c3e50;\n            font-family: 'Georgia', 'Times New Roman', serif;\n            font-weight: 400;\n        }\n        .main h1 {\n            text-align: center;\n            border-bottom: 2px solid #e9ecef;\n            padding-bottom: 1rem;\n            margin-bottom: 2rem;\n        }\n        [data-testid=\"metric-container\"] {\n            background: #ffffff;\n            border: 1px solid #e9ecef;\n            border-radius: 4px;\n            padding: 1.5rem;\n            margin: 0.5rem 0;\n        }\n        .stSelectbox label {\n            font-weight: 500;\n        }\n        </style>\n        \"\"\", unsafe_allow_html=True)\n\nload_css()\n\n# Initialize session state\nif 'initialized' not in st.session_state:\n    st.session_state.initialized = True\n    st.session_state.predictor = RockfallPredictor()\n    st.session_state.data_generator = SyntheticDataGenerator()\n    st.session_state.visualizer = Mine3DVisualizer()\n    st.session_state.notification_system = NotificationSystem()\n    st.session_state.lorawan_sim = LoRaWANSimulator()\n    st.session_state.config_manager = ConfigManager()\n    st.session_state.dashboard = RealTimeDashboard()\n    st.session_state.drone_dashboard = DroneDashboard()\n    st.session_state.historical_analysis = HistoricalAnalysis()\n    st.session_state.db_manager = get_rockfall_db()\n    st.session_state.last_update = datetime.now()\n    st.session_state.alert_count = 0\n\ndef main():\n    # Initialize current page first\n    if 'current_page' not in st.session_state:\n        st.session_state.current_page = \"Home\"\n    \n    # Only show sidebar for non-Home pages\n    if st.session_state.current_page != \"Home\":\n        create_sidebar_navigation()\n    \n    # Render the selected page content\n    render_page_content(st.session_state.current_page)\n\ndef create_sidebar_navigation():\n    \"\"\"Create professional sidebar navigation\"\"\"\n    with st.sidebar:\n        # Professional Company Branding\n        st.markdown(\"\"\"\n        <div class=\"company-branding\">\n            <div class=\"company-logo\">‚õèÔ∏è Rockfall Prediction System</div>\n            <div class=\"company-tagline\">Advanced Mine Safety Solutions</div>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n        \n        # Navigation menu\n        nav_options = {\n            \"Home\": \"üè†\",\n            \"Dashboard\": \"üìä\",\n            \"Live Monitoring\": \"üì°\", \n            \"3D Visualization\": \"üóª\",\n            \"Risk Analysis\": \"‚ö†Ô∏è\",\n            \"Alert Center\": \"üîî\",\n            \"Historical Data\": \"üìà\",\n            \"Communications\": \"üì±\",\n            \"Drone Control\": \"üöÅ\",\n            \"Settings\": \"‚öôÔ∏è\"\n        }\n        \n        st.markdown(\"### Navigation\")\n        \n        # Create navigation buttons\n        for page_name, icon in nav_options.items():\n            if st.button(\n                f\"{icon} {page_name}\", \n                key=f\"nav_{page_name}\",\n                use_container_width=True,\n                type=\"primary\" if st.session_state.current_page == page_name else \"secondary\"\n            ):\n                st.session_state.current_page = page_name\n                st.rerun()\n        \n        # Quick status in sidebar\n        st.markdown(\"---\")\n        st.markdown(\"### Quick Status\")\n        \n        try:\n            synthetic_data = st.session_state.data_generator.generate_real_time_data()\n            sensors = synthetic_data.get('sensors', [])\n            active_sensors = len([s for s in sensors if s.get('status') == 'online'])\n            total_sensors = len(sensors)\n            \n            st.metric(\"Active Sensors\", f\"{active_sensors}/{total_sensors}\")\n            \n            risk_levels = [s.get('risk_probability', 0) for s in sensors]\n            avg_risk = np.mean(risk_levels) if risk_levels else 0\n            risk_color = \"üî¥\" if avg_risk >= 0.7 else \"üü°\" if avg_risk >= 0.3 else \"üü¢\"\n            st.metric(\"Risk Level\", f\"{risk_color} {avg_risk*100:.0f}%\")\n            \n        except:\n            st.metric(\"Status\", \"Loading...\")\n\ndef render_page_content(page):\n    \"\"\"Render the content for the selected page\"\"\"\n    \n    # Special handling for landing page\n    if page == \"Home\":\n        show_landing_page()\n        return\n    \n    \n    # Route to page content  \n    if page == \"Dashboard\":\n        show_dashboard_overview()\n    elif page == \"Live Monitoring\":\n        show_real_time_dashboard()\n    elif page == \"3D Visualization\":\n        show_3d_visualization()\n    elif page == \"Risk Analysis\":\n        show_risk_prediction()\n    elif page == \"Alert Center\":\n        show_alert_management()\n    elif page == \"Historical Data\":\n        show_historical_analysis()\n    elif page == \"Communications\":\n        show_communication_status()\n    elif page == \"Drone Control\":\n        show_drone_monitoring()\n    elif page == \"Settings\":\n        show_system_configuration()\n\ndef get_page_title(page):\n    \"\"\"Get the display title for a page\"\"\"\n    titles = {\n        \"Home\": \"RockGuard Pro\",\n        \"Dashboard\": \"System Dashboard\",\n        \"Live Monitoring\": \"Real-Time Monitoring\",\n        \"3D Visualization\": \"3D Mine Visualization\", \n        \"Risk Analysis\": \"Risk Prediction Analysis\",\n        \"Alert Center\": \"Alert Management\",\n        \"Historical Data\": \"Historical Analysis\",\n        \"Communications\": \"Communication Status\",\n        \"Drone Control\": \"Drone Monitoring\",\n        \"Settings\": \"System Configuration\"\n    }\n    return titles.get(page, page)\n\ndef get_page_description(page):\n    \"\"\"Get the description for a page\"\"\"\n    descriptions = {\n        \"Home\": \"Advanced AI-powered rockfall prediction and monitoring system\",\n        \"Dashboard\": \"Overview of mine safety system status and key metrics\",\n        \"Live Monitoring\": \"Real-time sensor data and monitoring dashboard\",\n        \"3D Visualization\": \"Interactive 3D mine visualization with risk zones\",\n        \"Risk Analysis\": \"AI-powered rockfall risk prediction and analysis\",\n        \"Alert Center\": \"Manage alerts, notifications, and emergency responses\",\n        \"Historical Data\": \"Historical trends and analysis of mine safety data\",\n        \"Communications\": \"LoRaWAN, radio, and communication system status\",\n        \"Drone Control\": \"Drone monitoring and aerial surveillance control\",\n        \"Settings\": \"System configuration and preferences\"\n    }\n    return descriptions.get(page, \"\")\n\ndef show_dashboard_overview():\n    \"\"\"Show the main dashboard overview\"\"\"\n    try:\n        # Get system data\n        synthetic_data = st.session_state.data_generator.generate_real_time_data()\n        sensors = synthetic_data.get('sensors', [])\n        total_sensors = len(sensors)\n        active_sensors = len([s for s in sensors if s.get('status') == 'online'])\n        \n        # Calculate metrics\n        risk_levels = [s.get('risk_probability', 0) for s in sensors]\n        avg_risk = np.mean(risk_levels) if risk_levels else 0\n        high_risk_sensors = len([s for s in sensors if s.get('risk_probability', 0) > 0.7])\n        \n        # Key metrics row\n        col1, col2, col3, col4 = st.columns(4)\n        \n        with col1:\n            st.markdown(\"\"\"\n            <div class=\"status-card\" style=\"border-left-color: #10b981;\">\n                <div class=\"status-label\">System Status</div>\n                <div class=\"status-value\" style=\"color: #10b981;\">‚óè Online</div>\n                <div style=\"color: #64748b; font-size: 0.85rem;\">Uptime: 99.87% | Last 30 days</div>\n            </div>\n            \"\"\", unsafe_allow_html=True)\n        \n        with col2:\n            st.markdown(f\"\"\"\n            <div class=\"status-card\" style=\"border-left-color: #3b82f6;\">\n                <div class=\"status-label\">Active Sensors</div>\n                <div class=\"status-value\" style=\"color: #3b82f6;\">{active_sensors}/{total_sensors}</div>\n                <div style=\"color: #64748b; font-size: 0.85rem;\">Network Coverage: 98.2%</div>\n            </div>\n            \"\"\", unsafe_allow_html=True)\n        \n        with col3:\n            risk_color = \"#ef4444\" if avg_risk >= 0.7 else \"#f59e0b\" if avg_risk >= 0.3 else \"#10b981\"\n            risk_text = \"Critical\" if avg_risk >= 0.7 else \"Medium\" if avg_risk >= 0.3 else \"Low\"\n            risk_icon = \"üî¥\" if avg_risk >= 0.7 else \"üü°\" if avg_risk >= 0.3 else \"üü¢\"\n            st.markdown(f\"\"\"\n            <div class=\"status-card\" style=\"border-left-color: {risk_color};\">\n                <div class=\"status-label\">Risk Assessment</div>\n                <div class=\"status-value\" style=\"color: {risk_color};\">{risk_icon} {risk_text}</div>\n                <div style=\"color: #64748b; font-size: 0.85rem;\">AI Confidence: {avg_risk*100:.1f}%</div>\n            </div>\n            \"\"\", unsafe_allow_html=True)\n        \n        with col4:\n            alert_color = \"#ef4444\" if high_risk_sensors > 0 else \"#10b981\"\n            alert_icon = \"‚ö†Ô∏è\" if high_risk_sensors > 0 else \"‚úÖ\"\n            alert_status = \"Action Required\" if high_risk_sensors > 0 else \"All Clear\"\n            st.markdown(f\"\"\"\n            <div class=\"status-card\" style=\"border-left-color: {alert_color};\">\n                <div class=\"status-label\">Alert Status</div>\n                <div class=\"status-value\" style=\"color: {alert_color};\">{alert_icon} {high_risk_sensors}</div>\n                <div style=\"color: #64748b; font-size: 0.85rem;\">{alert_status}</div>\n            </div>\n            \"\"\", unsafe_allow_html=True)\n        \n        st.markdown(\"<br>\", unsafe_allow_html=True)\n        \n        # Quick access cards\n        st.subheader(\"Quick Access\")\n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            if st.button(\"üì° Live Monitoring\", use_container_width=True):\n                st.session_state.current_page = \"Live Monitoring\"\n                st.rerun()\n        \n        with col2:\n            if st.button(\"üóª 3D Visualization\", use_container_width=True):\n                st.session_state.current_page = \"3D Visualization\" \n                st.rerun()\n        \n        with col3:\n            if st.button(\"‚ö†Ô∏è Risk Analysis\", use_container_width=True):\n                st.session_state.current_page = \"Risk Analysis\"\n                st.rerun()\n        \n    except Exception as e:\n        st.error(\"Error loading dashboard data\")\n\ndef show_landing_page():\n    \"\"\"Show the professional landing page\"\"\"\n    \n    # Hide sidebar for landing page, but show a subtle access hint\n    st.markdown(\"\"\"\n    <style>\n    [data-testid=\"stSidebar\"] {display: none !important;}\n    .css-1d391kg {display: none !important;}\n    section[data-testid=\"stSidebar\"] {display: none !important;}\n    .main .block-container {margin-left: 0px !important; padding-left: 0px !important;}\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    \n    # Professional Navigation Bar\n    st.markdown(\"\"\"\n    <div class=\"landing-nav\">\n        <div class=\"nav-container\">\n            <div class=\"nav-brand\">\n                <span class=\"nav-logo\">‚õ∞Ô∏è RockGuard Pro</span>\n            </div>\n        </div>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n    \n    # Hero Section with Background Image\n    import base64\n    \n    # Read and encode the background image (use stock image without buttons)\n    try:\n        with open('attached_assets/stock_images/dramatic_rocky_cliff_a3d1ebb9.jpg', 'rb') as f:\n            img_data = base64.b64encode(f.read()).decode()\n            bg_image_data_url = f\"data:image/jpeg;base64,{img_data}\"\n    except:\n        bg_image_data_url = \"\"  # Fallback to no background\n    \n    st.markdown(f\"\"\"\n    <div class=\"hero-section\" style=\"background-image: url('{bg_image_data_url}');\">\n        <div class=\"hero-overlay\">\n            <div class=\"hero-content\">\n                <h1 class=\"hero-title\">Advanced Rockfall Prediction System</h1>\n                <p class=\"hero-subtitle\">\n                    Protect lives and infrastructure with AI-powered geological monitoring, \n                    real-time risk assessment, and early warning systems.\n                </p>\n                <div class=\"hero-button-container\">\n                    <button class=\"hero-cta-btn\" onclick=\"document.querySelector('[data-testid=\\\\\"baseButton-secondary\\\\\"]').click();\">\n                        Click Here\n                    </button>\n                </div>\n            </div>\n        </div>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n    \n    # Key Statistics Section\n    try:\n        # Get real system data\n        synthetic_data = st.session_state.data_generator.generate_real_time_data()\n        sensors = synthetic_data.get('sensors', [])\n        total_sensors = len(sensors)\n        active_sensors = len([s for s in sensors if s.get('status') == 'online'])\n        \n        # Calculate accuracy based on sensor reliability\n        accuracy = 97.2 + (active_sensors / total_sensors) * 2.5  # Simulate high accuracy\n        \n        st.markdown(f\"\"\"\n        <div class=\"stats-section\">\n            <div class=\"stats-container\">\n                <div class=\"stat-card\">\n                    <div class=\"stat-icon\">üõ°Ô∏è</div>\n                    <div class=\"stat-number\">{accuracy:.1f}%</div>\n                    <div class=\"stat-label\">Prediction Accuracy</div>\n                </div>\n                <div class=\"stat-card\">\n                    <div class=\"stat-icon\">üëÅÔ∏è</div>\n                    <div class=\"stat-number\">24/7</div>\n                    <div class=\"stat-label\">Real-time Monitoring</div>\n                </div>\n                <div class=\"stat-card\">\n                    <div class=\"stat-icon\">üìä</div>\n                    <div class=\"stat-number\">{total_sensors}+</div>\n                    <div class=\"stat-label\">Active Sensors</div>\n                </div>\n            </div>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n    except:\n        # Fallback stats\n        st.markdown(\"\"\"\n        <div class=\"stats-section\">\n            <div class=\"stats-container\">\n                <div class=\"stat-card\">\n                    <div class=\"stat-icon\">üõ°Ô∏è</div>\n                    <div class=\"stat-number\">99.7%</div>\n                    <div class=\"stat-label\">Prediction Accuracy</div>\n                </div>\n                <div class=\"stat-card\">\n                    <div class=\"stat-icon\">üëÅÔ∏è</div>\n                    <div class=\"stat-number\">24/7</div>\n                    <div class=\"stat-label\">Real-time Monitoring</div>\n                </div>\n                <div class=\"stat-card\">\n                    <div class=\"stat-icon\">üìä</div>\n                    <div class=\"stat-number\">1000+</div>\n                    <div class=\"stat-label\">Sites Protected</div>\n                </div>\n            </div>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n    \n    # Hidden button for JavaScript click handler\n    col1, col2, col3 = st.columns([2, 1, 2])\n    with col2:\n        if st.button(\"Click Here\", key=\"access_system\", help=\"Access the complete monitoring dashboard\", use_container_width=True, type=\"secondary\"):\n            st.session_state.current_page = \"Dashboard\"\n            st.rerun()\n    \n    # Hide the button with CSS\n    st.markdown(\"\"\"\n    <style>\n    [data-testid=\"column\"]:nth-child(2) [data-testid=\"baseButton-secondary\"] {\n        display: none !important;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n\ndef show_real_time_dashboard():\n    st.header(\"üìä Real-Time Monitoring Dashboard\")\n    \n    # Force use of synthetic data for demonstration (since database is empty)\n    st.info(\"üì° Using synthetic sensor data for demonstration purposes\")\n    current_data = st.session_state.data_generator.generate_real_time_data()\n    \n    \n    # Use the professional dashboard\n    try:\n        st.session_state.dashboard.render_full_dashboard(\n            current_data,\n            predictions=st.session_state.predictor.generate_predictions(),\n            alerts=st.session_state.notification_system.get_alert_history(10),\n            comm_data={\n                'lorawan': st.session_state.lorawan_sim.get_network_status(),\n                'radio': st.session_state.lorawan_sim.get_radio_status()\n            }\n        )\n    except Exception as e:\n        st.error(f\"Error rendering dashboard: {str(e)}\")\n        st.info(\"Falling back to simplified view...\")\n        \n        # Simple fallback dashboard\n        render_simple_dashboard(current_data)\n\ndef render_simple_dashboard(current_data):\n    \"\"\"Simplified dashboard fallback\"\"\"\n    # Display key sensor metrics\n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        st.subheader(\"Mine Risk Zones\")\n        try:\n            # Create simple risk heatmap\n            sensors = current_data.get('sensors', [])\n            if sensors:\n                sensor_df = pd.DataFrame(sensors)\n                st.dataframe(sensor_df[['sensor_id', 'sensor_type', 'status']].head(10))\n            else:\n                st.info(\"No sensor data available\")\n        except Exception as e:\n            st.info(\"Sensor visualization not available\")\n        \n        # Add legend\n        st.markdown(\"\"\"\n        **Risk Level Legend:**\n        - üü¢ **Low Risk (0-30%)**: Normal operations\n        - üü° **Medium Risk (30-70%)**: Increased monitoring\n        - üü† **High Risk (70-85%)**: Caution advised\n        - üî¥ **Critical Risk (85-100%)**: Immediate action required\n        \"\"\")\n    \n    with col2:\n        st.subheader(\"Current Sensor Readings\")\n        \n        # Display key sensor metrics\n        sensors = current_data.get('sensors', [])\n        if sensors:\n            for i, sensor in enumerate(sensors[:5]):  # Show top 5 sensors\n                # Handle both old and new data formats\n                if 'risk_probability' in sensor:\n                    risk_level = sensor['risk_probability']\n                else:\n                    # Calculate a simple risk based on latest value if available\n                    risk_level = 0.3 + (hash(sensor.get('sensor_id', '')) % 100) / 1000\n                \n                if risk_level > 0.85:\n                    status = \"üî¥ Critical\"\n                elif risk_level > 0.7:\n                    status = \"üü† High\"\n                elif risk_level > 0.3:\n                    status = \"üü° Medium\"\n                else:\n                    status = \"üü¢ Low\"\n                \n                sensor_name = sensor.get('sensor_id', sensor.get('id', f'Sensor {i+1}'))\n                latest_value = sensor.get('latest_value', 'N/A')\n                \n                st.metric(\n                    sensor_name,\n                    f\"{latest_value}\" if latest_value != 'N/A' else \"No data\",\n                    status\n                )\n        else:\n            st.info(\"No sensor data available\")\n\ndef show_3d_visualization():\n    st.header(\"üèîÔ∏è 3D Mine Visualization\")\n    \n    # Generate 3D mine data\n    mine_data = st.session_state.data_generator.generate_mine_topology()\n    \n    col1, col2 = st.columns([3, 1])\n    \n    with col1:\n        # 3D visualization\n        fig_3d = st.session_state.visualizer.create_3d_mine_view(mine_data)\n        st.plotly_chart(fig_3d, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"Visualization Controls\")\n        \n        # View options\n        view_mode = st.selectbox(\"View Mode\", [\"Risk Overlay\", \"Sensor Network\", \"Geological Layers\"])\n        show_sensors = st.checkbox(\"Show Sensors\", value=True)\n        show_risk_zones = st.checkbox(\"Show Risk Zones\", value=True)\n        \n        # Color scheme\n        color_scheme = st.selectbox(\"Color Scheme\", [\"Risk-based\", \"Elevation\", \"Geological\"])\n        \n        # Update visualization based on controls\n        if st.button(\"Update Visualization\"):\n            updated_fig = st.session_state.visualizer.update_3d_view(\n                mine_data, view_mode, show_sensors, show_risk_zones, color_scheme\n            )\n            st.plotly_chart(updated_fig, use_container_width=True)\n        \n        st.subheader(\"Legend\")\n        st.markdown(\"\"\"\n        **3D Visualization Elements:**\n        - üî¥ High-risk zones\n        - üü° Medium-risk zones  \n        - üü¢ Low-risk zones\n        - üìç Sensor locations\n        - üèîÔ∏è Terrain elevation\n        - ‚ö†Ô∏è Alert zones\n        \"\"\")\n\ndef show_risk_prediction():\n    st.header(\"ü§ñ AI Risk Prediction\")\n    \n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        st.subheader(\"Prediction Model Performance\")\n        \n        # Generate prediction data\n        prediction_data = st.session_state.predictor.generate_predictions()\n        \n        # Show prediction accuracy metrics\n        accuracy_metrics = st.session_state.predictor.get_model_metrics()\n        \n        # Display metrics\n        metric_col1, metric_col2, metric_col3 = st.columns(3)\n        with metric_col1:\n            st.metric(\"Model Accuracy\", f\"{accuracy_metrics['accuracy']:.1%}\")\n        with metric_col2:\n            st.metric(\"Precision\", f\"{accuracy_metrics['precision']:.1%}\")\n        with metric_col3:\n            st.metric(\"Recall\", f\"{accuracy_metrics['recall']:.1%}\")\n        \n        # Prediction timeline\n        fig_timeline = st.session_state.predictor.create_prediction_timeline(prediction_data)\n        st.plotly_chart(fig_timeline, use_container_width=True)\n        \n        # Feature importance\n        st.subheader(\"Feature Importance Analysis\")\n        feature_importance = st.session_state.predictor.get_feature_importance()\n        fig_features = px.bar(\n            x=list(feature_importance.values()),\n            y=list(feature_importance.keys()),\n            orientation='h',\n            title=\"Factors Contributing to Rockfall Risk\"\n        )\n        st.plotly_chart(fig_features, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"Prediction Settings\")\n        \n        # Prediction parameters\n        prediction_horizon = st.slider(\"Prediction Horizon (hours)\", 1, 72, 24)\n        confidence_threshold = st.slider(\"Confidence Threshold\", 0.5, 0.95, 0.8)\n        \n        # Model selection\n        model_type = st.selectbox(\"Model Type\", [\"Random Forest\", \"Neural Network\", \"SVM\", \"Ensemble\"])\n        \n        # Retrain model button\n        if st.button(\"Retrain Model\"):\n            with st.spinner(\"Retraining model with latest data...\"):\n                st.session_state.predictor.retrain_model(model_type)\n                st.success(\"Model retrained successfully!\")\n        \n        st.subheader(\"Risk Factors\")\n        risk_factors = st.session_state.predictor.get_current_risk_factors()\n        for factor, value in risk_factors.items():\n            st.metric(factor.replace('_', ' ').title(), f\"{value:.3f}\")\n\ndef show_alert_management():\n    st.header(\"üö® Alert Management System\")\n    \n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        st.subheader(\"Alert Configuration\")\n        \n        # Alert thresholds\n        st.write(\"**Risk Level Thresholds**\")\n        low_threshold = st.slider(\"Low Risk Threshold\", 0.0, 1.0, 0.3)\n        medium_threshold = st.slider(\"Medium Risk Threshold\", 0.0, 1.0, 0.7)\n        high_threshold = st.slider(\"High Risk Threshold\", 0.0, 1.0, 0.85)\n        \n        # Notification channels\n        st.write(\"**Notification Channels**\")\n        enable_sms = st.checkbox(\"SMS Alerts\", value=True)\n        enable_email = st.checkbox(\"Email Alerts\", value=True)\n        enable_audio = st.checkbox(\"Audio Sirens\", value=True)\n        enable_visual = st.checkbox(\"Visual Alerts\", value=True)\n        \n        # Contact information\n        phone_number = None\n        email_address = None\n        if enable_sms or enable_email:\n            st.subheader(\"Contact Information\")\n            phone_number = st.text_input(\"Phone Number\", placeholder=\"+1234567890\")\n            email_address = st.text_input(\"Email Address\", placeholder=\"alerts@mine.com\")\n        \n        # Test alerts\n        st.subheader(\"Test Alert System\")\n        test_alert_type = st.selectbox(\"Test Alert Type\", [\"Low Risk\", \"Medium Risk\", \"High Risk\", \"Critical\"])\n        \n        if st.button(\"Send Test Alert\"):\n            result = st.session_state.notification_system.send_test_alert(\n                test_alert_type, phone_number if enable_sms else None, \n                email_address if enable_email else None,\n                enable_audio, enable_visual\n            )\n            if result['success']:\n                st.success(f\"Test alert sent successfully! {result['message']}\")\n                st.session_state.alert_count += 1\n            else:\n                st.error(f\"Failed to send test alert: {result['error']}\")\n    \n    with col2:\n        st.subheader(\"Alert History\")\n        \n        # Recent alerts\n        alert_history = st.session_state.notification_system.get_alert_history()\n        for alert in alert_history[:10]:  # Show last 10 alerts\n            timestamp = alert['timestamp'].strftime(\"%Y-%m-%d %H:%M\")\n            st.write(f\"**{timestamp}**\")\n            st.write(f\"{alert['type']}: {alert['message']}\")\n            st.write(f\"Zone: {alert['zone']}\")\n            st.divider()\n        \n        st.subheader(\"Action Plans\")\n        action_plans = {\n            \"Low Risk\": \"Continue normal operations with standard monitoring\",\n            \"Medium Risk\": \"Increase monitoring frequency, alert supervisors\",\n            \"High Risk\": \"Evacuate non-essential personnel, increase patrols\",\n            \"Critical\": \"Immediate evacuation, halt operations, emergency response\"\n        }\n        \n        for risk_level, action in action_plans.items():\n            with st.expander(f\"{risk_level} Action Plan\"):\n                st.write(action)\n\ndef show_historical_analysis():\n    st.header(\"üìà Historical Analysis & Trends\")\n    \n    # Generate historical data\n    historical_data = st.session_state.historical_analysis.generate_historical_data()\n    \n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        # Risk trend over time\n        st.subheader(\"Risk Trend Analysis\")\n        fig_trend = st.session_state.historical_analysis.create_risk_timeline(historical_data)\n        st.plotly_chart(fig_trend, use_container_width=True)\n        \n        # Seasonal patterns\n        st.subheader(\"Seasonal Risk Patterns\")\n        fig_seasonal = st.session_state.historical_analysis.create_seasonal_analysis(historical_data)\n        st.plotly_chart(fig_seasonal, use_container_width=True)\n        \n        # Correlation analysis\n        st.subheader(\"Environmental Factor Correlations\")\n        correlation_data = st.session_state.historical_analysis.calculate_correlations(historical_data)\n        fig_corr = px.imshow(\n            correlation_data,\n            title=\"Correlation Matrix - Environmental Factors vs Risk\",\n            color_continuous_scale=\"RdBu\"\n        )\n        st.plotly_chart(fig_corr, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"Analysis Controls\")\n        \n        # Date range selector\n        start_date = st.date_input(\"Start Date\", datetime.now() - timedelta(days=30))\n        end_date = st.date_input(\"End Date\", datetime.now())\n        \n        # Analysis type\n        analysis_type = st.selectbox(\"Analysis Type\", \n                                   [\"Risk Trends\", \"Sensor Performance\", \"Alert Frequency\", \"Environmental Impact\"])\n        \n        # Generate report\n        if st.button(\"Generate Report\"):\n            with st.spinner(\"Generating analysis report...\"):\n                report = st.session_state.historical_analysis.generate_report(\n                    historical_data, start_date, end_date, analysis_type\n                )\n                st.success(\"Report generated successfully!\")\n                \n                # Display report summary\n                st.subheader(\"Report Summary\")\n                for key, value in report.items():\n                    st.metric(key.replace('_', ' ').title(), value)\n\ndef show_communication_status():\n    st.header(\"üì° Communication System Status\")\n    \n    col1, col2 = st.columns([1, 1])\n    \n    with col1:\n        st.subheader(\"LoRaWAN Network Status\")\n        \n        # LoRaWAN status\n        lorawan_status = st.session_state.lorawan_sim.get_network_status()\n        \n        # Network metrics\n        st.metric(\"Network Coverage\", f\"{lorawan_status['coverage']:.1%}\")\n        st.metric(\"Active Gateways\", lorawan_status['gateways'])\n        st.metric(\"Connected Devices\", lorawan_status['devices'])\n        st.metric(\"Signal Strength\", f\"{lorawan_status['signal_strength']} dBm\")\n        \n        # Gateway status\n        st.subheader(\"Gateway Status\")\n        for gateway in lorawan_status['gateway_list']:\n            status_color = \"üü¢\" if gateway['status'] == 'online' else \"üî¥\"\n            st.write(f\"{status_color} Gateway {gateway['id']}: {gateway['status']}\")\n    \n    with col2:\n        st.subheader(\"Radio Communication\")\n        \n        # Radio status\n        radio_status = st.session_state.lorawan_sim.get_radio_status()\n        \n        st.metric(\"Radio Frequency\", f\"{radio_status['frequency']} MHz\")\n        st.metric(\"Transmission Power\", f\"{radio_status['power']} dBm\")\n        st.metric(\"Error Rate\", f\"{radio_status['error_rate']:.1%}\")\n        \n        # Emergency communication\n        st.subheader(\"Emergency Communication\")\n        st.write(\"**Backup Systems:**\")\n        st.write(\"üîÑ Satellite uplink: Available\")\n        st.write(\"üìª Emergency radio: Standby\")\n        st.write(\"üö® Siren network: Operational\")\n        \n        # Test communication\n        if st.button(\"Test Emergency Communication\"):\n            test_result = st.session_state.lorawan_sim.test_emergency_communication()\n            if test_result['overall_success']:\n                st.success(\"Emergency communication test successful!\")\n            else:\n                st.error(\"Emergency communication test failed!\")\n\ndef show_system_configuration():\n    st.header(\"‚öôÔ∏è System Configuration\")\n    \n    config = st.session_state.config_manager.get_current_config()\n    \n    col1, col2 = st.columns([1, 1])\n    \n    with col1:\n        st.subheader(\"API Configuration\")\n        \n        # API key status (never show actual keys)\n        api_keys = {\n            \"OpenAI API\": os.getenv(\"OPENAI_API_KEY\") is not None,\n            \"Twilio\": os.getenv(\"TWILIO_ACCOUNT_SID\") is not None,\n            \"SendGrid\": os.getenv(\"SENDGRID_API_KEY\") is not None\n        }\n        \n        for service, configured in api_keys.items():\n            status = \"‚úÖ Configured\" if configured else \"‚ùå Not configured\"\n            st.write(f\"**{service}**: {status}\")\n        \n        st.subheader(\"System Parameters\")\n        \n        # Model parameters\n        model_update_interval = st.number_input(\"Model Update Interval (minutes)\", 1, 1440, config.get('model_update_interval', 60))\n        data_retention_days = st.number_input(\"Data Retention (days)\", 1, 365, config.get('data_retention_days', 90))\n        \n        # Alert parameters\n        alert_cooldown = st.number_input(\"Alert Cooldown (minutes)\", 1, 60, config.get('alert_cooldown', 15))\n        max_alerts_per_hour = st.number_input(\"Max Alerts per Hour\", 1, 20, config.get('max_alerts_per_hour', 5))\n    \n    with col2:\n        st.subheader(\"Mine Configuration\")\n        \n        # Mine parameters\n        mine_name = st.text_input(\"Mine Name\", value=config.get('mine_name', 'Open Pit Mine Alpha'))\n        mine_coordinates = st.text_input(\"Coordinates\", value=config.get('coordinates', '45.123, -123.456'))\n        \n        # Sensor configuration\n        sensor_count = st.number_input(\"Number of Sensors\", 1, 100, config.get('sensor_count', 47))\n        sensor_update_freq = st.selectbox(\"Sensor Update Frequency\", \n                                        [\"1 minute\", \"5 minutes\", \"15 minutes\", \"30 minutes\"],\n                                        index=config.get('sensor_freq_index', 1))\n        \n        st.subheader(\"Data Sources\")\n        \n        # Data source configuration\n        use_dem_data = st.checkbox(\"Digital Elevation Model\", value=config.get('use_dem', True))\n        use_drone_imagery = st.checkbox(\"Drone Imagery\", value=config.get('use_drone', True))\n        use_weather_data = st.checkbox(\"Weather Data\", value=config.get('use_weather', True))\n        \n        # Save configuration\n        if st.button(\"üíæ Save Configuration\"):\n            new_config = {\n                'mine_name': mine_name,\n                'coordinates': mine_coordinates,\n                'sensor_count': sensor_count,\n                'model_update_interval': model_update_interval,\n                'data_retention_days': data_retention_days,\n                'alert_cooldown': alert_cooldown,\n                'max_alerts_per_hour': max_alerts_per_hour,\n                'use_dem': use_dem_data,\n                'use_drone': use_drone_imagery,\n                'use_weather': use_weather_data\n            }\n            \n            if st.session_state.config_manager.update_config(new_config):\n                st.success(\"Configuration saved successfully!\")\n            else:\n                st.error(\"Failed to save configuration\")\n\ndef show_drone_monitoring():\n    \"\"\"Show drone monitoring dashboard\"\"\"\n    st.session_state.drone_dashboard.render_drone_monitoring_page()\n\nif __name__ == \"__main__\":\n    main()","size_bytes":34648},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"joblib>=1.5.2\",\n    \"numpy>=2.3.3\",\n    \"openai>=1.108.1\",\n    \"opencv-python>=4.11.0.86\",\n    \"pandas>=2.3.2\",\n    \"plotly>=6.3.0\",\n    \"psutil>=7.1.0\",\n    \"rasterio>=1.4.3\",\n    \"scikit-learn>=1.7.2\",\n    \"serial>=0.0.97\",\n    \"streamlit>=1.49.1\",\n    \"twilio>=9.8.1\",\n    \"xgboost>=3.0.5\",\n    \"sqlalchemy>=2.0.0\",\n    \"sendgrid>=6.12.5\",\n    \"psycopg2-binary>=2.9.10\",\n]\n","size_bytes":523},"replit.md":{"content":"# AI-Based Rockfall Prediction & Alert System\n\n## Overview\n\nThis is a comprehensive AI-powered rockfall prediction and alert system designed for open-pit mines. The system combines machine learning models with real-time sensor data, environmental monitoring, and multi-channel communication systems to predict rockfall risks and provide early warnings to ensure mine safety. The application features a web-based dashboard built with Streamlit, 3D mine visualization, historical analysis capabilities, and robust communication systems including LoRaWAN and radio backup for reliable operation even in remote locations.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n**Frontend Architecture:**\n- Streamlit-based web application serving as the main dashboard\n- Real-time data visualization using Plotly for 3D mine views, risk heatmaps, and sensor monitoring\n- Responsive dashboard with navigation sidebar for different system components\n- Mobile field application interface for on-site personnel\n\n**Backend Architecture:**\n- Modular Python architecture with separate packages for different functionalities\n- Machine learning ensemble model combining Random Forest, Neural Networks, and SVM for rockfall prediction\n- Synthetic data generator for testing and simulation when real sensors are unavailable\n- Real-time data processing pipeline with configurable update intervals\n- Historical analysis engine with trend detection and correlation analysis\n\n**Data Storage:**\n- SQLAlchemy ORM with support for multiple database backends\n- VS Code-friendly database configuration with local SQLite default and PostgreSQL support\n- Comprehensive database schema including mine sites, sensors, readings, alerts, and environmental data\n- Data ingestion system supporting multiple IoT protocols\n- Automatic data retention and cleanup policies\n- Local database files stored in ./data/ directory for VS Code development\n\n**Communication Systems:**\n- LoRaWAN simulation and management for low-power, long-range sensor communication\n- Radio communication backup systems for redundancy\n- Multi-channel alert system supporting SMS (Twilio), email (SendGrid), and audio/visual alerts\n- MQTT and HTTP API support for real-time data streaming\n\n**AI/ML Components:**\n- Ensemble machine learning model with continuous learning capabilities\n- Feature engineering for geological and environmental parameters\n- Risk probability calculation with configurable thresholds\n- Pattern recognition for historical data analysis\n- Optional OpenAI integration for advanced analysis and insights\n\n**Hardware Integration:**\n- IoT sensor management system supporting multiple communication protocols\n- Physical siren and emergency broadcast system integration\n- Hardware status monitoring and maintenance scheduling\n- Battery and signal strength monitoring for remote sensors\n\n**Mobile and Field Support:**\n- Offline-capable field application for inspectors\n- Emergency communication protocols\n- Field report generation and photo documentation\n- GPS-based location tracking for incidents and inspections\n\n## External Dependencies\n\n**Machine Learning Libraries:**\n- scikit-learn for ensemble models and data preprocessing\n- numpy and pandas for numerical computations and data manipulation\n- scipy for statistical analysis\n\n**Visualization and UI:**\n- Streamlit for web application framework\n- Plotly for interactive 3D visualizations and charts\n- plotly.express for statistical plotting\n\n**Communication Services:**\n- Twilio REST API for SMS notifications\n- SendGrid API for email alerts\n- MQTT protocol support via paho-mqtt\n- HTTP APIs for data ingestion\n\n**Database:**\n- SQLAlchemy ORM for database abstraction\n- Default SQLite configuration for VS Code development (./data/rockfall_prediction.db)\n- Optional PostgreSQL support via environment variables\n- Support for local and remote database configurations\n- Automatic schema migration and table creation\n- Environment-based configuration with .env.example provided\n\n**IoT and Hardware:**\n- LoRaWAN protocol simulation and management\n- Modbus support for industrial sensors\n- ZigBee and WiFi sensor protocols\n- Cellular communication backup\n\n**Optional Integrations:**\n- OpenAI API for advanced AI analysis and natural language insights\n- Computer vision libraries (OpenCV) for drone imagery analysis\n- Satellite communication systems for remote area connectivity\n\n**Development and Deployment:**\n- JSON-based configuration management\n- Comprehensive logging system\n- Modular architecture supporting easy extension and customization\n- Environment variable configuration for sensitive credentials","size_bytes":4666},"alerts/__init__.py":{"content":"","size_bytes":0},"alerts/notification_system.py":{"content":"import os\nimport sys\nimport json\nfrom datetime import datetime, timedelta\nimport numpy as np\n\nclass NotificationSystem:\n    def __init__(self):\n        # Initialize Twilio credentials\n        self.twilio_sid = os.getenv(\"TWILIO_ACCOUNT_SID\")\n        self.twilio_token = os.getenv(\"TWILIO_AUTH_TOKEN\")\n        self.twilio_phone = os.getenv(\"TWILIO_PHONE_NUMBER\")\n        self.twilio_client = None\n        \n        if self.twilio_sid and self.twilio_token:\n            try:\n                from twilio.rest import Client\n                self.twilio_client = Client(self.twilio_sid, self.twilio_token)\n            except ImportError:\n                pass\n        \n        # Alert history\n        self.alert_history = []\n        self.alert_cooldown = {}  # Prevent spam alerts\n        \n        # Initialize with some historical alerts\n        self._initialize_alert_history()\n    \n    def _initialize_alert_history(self):\n        \"\"\"Initialize with some sample alert history\"\"\"\n        base_time = datetime.now()\n        \n        sample_alerts = [\n            {\n                'timestamp': base_time - timedelta(hours=2),\n                'type': 'High Risk',\n                'message': 'Displacement rate exceeded threshold in Zone 3',\n                'zone': 'Zone_3',\n                'severity': 'high',\n                'channels_used': ['email', 'sms'],\n                'resolved': True\n            },\n            {\n                'timestamp': base_time - timedelta(hours=8),\n                'type': 'Medium Risk',\n                'message': 'Increased pore pressure detected in Zone 7',\n                'zone': 'Zone_7',\n                'severity': 'medium',\n                'channels_used': ['email'],\n                'resolved': True\n            },\n            {\n                'timestamp': base_time - timedelta(days=1),\n                'type': 'Critical',\n                'message': 'Emergency: Rock instability detected in Zone 1',\n                'zone': 'Zone_1',\n                'severity': 'critical',\n                'channels_used': ['sms', 'email', 'siren'],\n                'resolved': True\n            }\n        ]\n        \n        self.alert_history.extend(sample_alerts)\n    \n    def send_sms_alert(self, phone_number, message):\n        \"\"\"Send SMS alert via Twilio\"\"\"\n        if not self.twilio_client:\n            return {\n                'success': False,\n                'error': 'Twilio not configured - missing credentials'\n            }\n        \n        try:\n            message_obj = self.twilio_client.messages.create(\n                body=message,\n                from_=self.twilio_phone,\n                to=phone_number\n            )\n            return {\n                'success': True,\n                'message_sid': message_obj.sid,\n                'message': f'SMS sent successfully to {phone_number}'\n            }\n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Failed to send SMS: {str(e)}'\n            }\n    \n    def send_email_alert(self, email_address, subject, message, from_email=\"alerts@mine-safety.com\"):\n        \"\"\"Send email alert via SendGrid\"\"\"\n        try:\n            # Get SendGrid API key from environment\n            sendgrid_key = os.environ.get('SENDGRID_API_KEY')\n            if not sendgrid_key:\n                return {\n                    'success': False,\n                    'error': 'SendGrid API key not configured'\n                }\n            \n            # Import SendGrid (from blueprint integration)\n            from sendgrid import SendGridAPIClient\n            from sendgrid.helpers.mail import Mail, Email, To, Content\n            \n            # Create SendGrid client\n            sg = SendGridAPIClient(sendgrid_key)\n            \n            # Create email message\n            mail = Mail(\n                from_email=Email(from_email),\n                to_emails=To(email_address),\n                subject=subject\n            )\n            \n            # Set content (prefer HTML, fallback to plain text)\n            if '<' in message and '>' in message:  # Basic HTML detection\n                mail.content = Content(\"text/html\", message)\n            else:\n                mail.content = Content(\"text/plain\", message)\n            \n            # Send email\n            response = sg.send(mail)\n            \n            return {\n                'success': True,\n                'message': f'Email sent successfully to {email_address}',\n                'sendgrid_status': response.status_code,\n                'subject': subject\n            }\n            \n        except ImportError:\n            return {\n                'success': False,\n                'error': 'SendGrid library not available - install sendgrid package'\n            }\n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Failed to send email via SendGrid: {str(e)}'\n            }\n    \n    def trigger_audio_siren(self, zone, severity):\n        \"\"\"Simulate audio siren activation\"\"\"\n        # In a real system, this would interface with physical siren hardware\n        siren_patterns = {\n            'low': 'Single short beep',\n            'medium': '3 short beeps',\n            'high': 'Continuous beeping for 30 seconds',\n            'critical': 'Emergency evacuation siren - continuous for 2 minutes'\n        }\n        \n        pattern = siren_patterns.get(severity, 'Standard alert')\n        \n        return {\n            'success': True,\n            'message': f'Audio siren activated in {zone}',\n            'pattern': pattern,\n            'duration': '30 seconds' if severity in ['high', 'critical'] else '5 seconds'\n        }\n    \n    def trigger_visual_alert(self, zone, severity):\n        \"\"\"Simulate visual alert system\"\"\"\n        # In a real system, this would control LED warning lights, displays, etc.\n        color_codes = {\n            'low': 'Green flashing',\n            'medium': 'Yellow flashing',\n            'high': 'Orange strobing',\n            'critical': 'Red emergency strobing'\n        }\n        \n        visual_pattern = color_codes.get(severity, 'Standard alert')\n        \n        return {\n            'success': True,\n            'message': f'Visual alerts activated in {zone}',\n            'pattern': visual_pattern,\n            'location': f'All display panels in {zone} and surrounding areas'\n        }\n    \n    def send_comprehensive_alert(self, alert_data, phone_number=None, email_address=None, \n                                enable_audio=True, enable_visual=True):\n        \"\"\"Send alert through all configured channels\"\"\"\n        results = []\n        channels_used = []\n        \n        severity = alert_data.get('severity', 'medium')\n        zone = alert_data.get('zone', 'Unknown')\n        message = alert_data.get('message', 'Risk threshold exceeded')\n        \n        # Check cooldown to prevent spam\n        cooldown_key = f\"{zone}_{severity}\"\n        now = datetime.now()\n        if cooldown_key in self.alert_cooldown:\n            if now - self.alert_cooldown[cooldown_key] < timedelta(minutes=15):\n                return {\n                    'success': False,\n                    'error': 'Alert cooldown active - preventing duplicate alerts'\n                }\n        \n        # SMS Alert\n        if phone_number and self.twilio_client:\n            sms_message = f\"MINE ALERT [{severity.upper()}]\\n{message}\\nZone: {zone}\\nTime: {now.strftime('%H:%M')}\"\n            sms_result = self.send_sms_alert(phone_number, sms_message)\n            results.append(('SMS', sms_result))\n            if sms_result['success']:\n                channels_used.append('sms')\n        \n        # Email Alert\n        if email_address:\n            subject = f\"Mine Safety Alert - {severity.upper()} Risk in {zone}\"\n            email_result = self.send_email_alert(email_address, subject, message)\n            results.append(('Email', email_result))\n            if email_result['success']:\n                channels_used.append('email')\n        \n        # Audio Siren\n        if enable_audio:\n            audio_result = self.trigger_audio_siren(zone, severity)\n            results.append(('Audio Siren', audio_result))\n            if audio_result['success']:\n                channels_used.append('siren')\n        \n        # Visual Alerts\n        if enable_visual:\n            visual_result = self.trigger_visual_alert(zone, severity)\n            results.append(('Visual Alert', visual_result))\n            if visual_result['success']:\n                channels_used.append('visual')\n        \n        # Record in history\n        alert_record = {\n            'timestamp': now,\n            'type': alert_data.get('type', 'Risk Alert'),\n            'message': message,\n            'zone': zone,\n            'severity': severity,\n            'channels_used': channels_used,\n            'resolved': False\n        }\n        self.alert_history.append(alert_record)\n        \n        # Set cooldown\n        self.alert_cooldown[cooldown_key] = now\n        \n        return {\n            'success': True,\n            'message': f'Alert sent via {len(channels_used)} channels',\n            'channels_used': channels_used,\n            'results': results\n        }\n    \n    def send_test_alert(self, alert_type, phone_number=None, email_address=None, \n                       enable_audio=True, enable_visual=True):\n        \"\"\"Send a test alert\"\"\"\n        test_alert_data = {\n            'type': f'Test {alert_type}',\n            'message': f'This is a test {alert_type.lower()} alert from the rockfall prediction system',\n            'zone': 'Test_Zone',\n            'severity': alert_type.lower().replace(' ', '_')\n        }\n        \n        return self.send_comprehensive_alert(\n            test_alert_data, phone_number, email_address, enable_audio, enable_visual\n        )\n    \n    def get_alert_history(self, limit=50):\n        \"\"\"Get recent alert history\"\"\"\n        return sorted(self.alert_history, key=lambda x: x['timestamp'], reverse=True)[:limit]\n    \n    def get_alert_statistics(self, days=7):\n        \"\"\"Get alert statistics for the specified period\"\"\"\n        cutoff_date = datetime.now() - timedelta(days=days)\n        recent_alerts = [alert for alert in self.alert_history if alert['timestamp'] > cutoff_date]\n        \n        stats = {\n            'total_alerts': len(recent_alerts),\n            'by_severity': {},\n            'by_zone': {},\n            'channels_effectiveness': {}\n        }\n        \n        # Count by severity\n        for alert in recent_alerts:\n            severity = alert['severity']\n            stats['by_severity'][severity] = stats['by_severity'].get(severity, 0) + 1\n        \n        # Count by zone\n        for alert in recent_alerts:\n            zone = alert['zone']\n            stats['by_zone'][zone] = stats['by_zone'].get(zone, 0) + 1\n        \n        # Channel effectiveness\n        for alert in recent_alerts:\n            for channel in alert['channels_used']:\n                stats['channels_effectiveness'][channel] = stats['channels_effectiveness'].get(channel, 0) + 1\n        \n        return stats\n    \n    def generate_action_plan(self, risk_level, zone_data):\n        \"\"\"Generate automated action plan based on risk level\"\"\"\n        action_plans = {\n            'low': {\n                'immediate_actions': [\n                    'Continue normal monitoring',\n                    'Log incident in daily reports',\n                    'Schedule routine inspection within 24 hours'\n                ],\n                'personnel': 'Shift supervisor',\n                'equipment': 'Standard monitoring equipment',\n                'timeline': 'Next regular inspection cycle'\n            },\n            'medium': {\n                'immediate_actions': [\n                    'Increase monitoring frequency to every 2 hours',\n                    'Notify shift supervisor and safety officer',\n                    'Restrict non-essential personnel from zone',\n                    'Deploy additional sensors if available'\n                ],\n                'personnel': 'Safety officer, geotechnical engineer',\n                'equipment': 'Additional displacement sensors, weather monitoring',\n                'timeline': 'Within 2 hours'\n            },\n            'high': {\n                'immediate_actions': [\n                    'Evacuate non-essential personnel immediately',\n                    'Continuous monitoring - no breaks',\n                    'Alert mine manager and emergency response team',\n                    'Prepare evacuation routes',\n                    'Stop operations in affected zone'\n                ],\n                'personnel': 'Mine manager, emergency response team, geotechnical specialist',\n                'equipment': 'Emergency communication, backup monitoring systems',\n                'timeline': 'Immediate - within 30 minutes'\n            },\n            'critical': {\n                'immediate_actions': [\n                    'EVACUATE ALL PERSONNEL FROM ZONE IMMEDIATELY',\n                    'Sound general alarm',\n                    'Contact emergency services',\n                    'Implement emergency response protocol',\n                    'Stop all operations in mine',\n                    'Account for all personnel'\n                ],\n                'personnel': 'All emergency response personnel, external emergency services',\n                'equipment': 'Emergency evacuation equipment, medical support',\n                'timeline': 'IMMEDIATE - no delay'\n            }\n        }\n        \n        return action_plans.get(risk_level, action_plans['medium'])\n    \n    def send_alert_notification(self, alert_type: str, risk_level: str, message: str, location: dict = None) -> dict:\n        \"\"\"Send alert notification through appropriate channels (compatibility method for drone integration)\"\"\"\n        try:\n            # Create alert data structure\n            alert_data = {\n                'type': alert_type,\n                'severity': risk_level,\n                'message': message,\n                'zone': f\"Zone_{location.get('lat', 0):.3f}_{location.get('lon', 0):.3f}\" if location else \"Mine_Site\",\n                'location': location\n            }\n            \n            # Use comprehensive alert system\n            return self.send_comprehensive_alert(\n                alert_data=alert_data,\n                phone_number=\"+1234567890\",  # Would be configured per mine\n                email_address=\"safety@mine-site.com\",  # Would be configured per mine\n                enable_audio=True,\n                enable_visual=True\n            )\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Failed to send alert notification: {str(e)}'\n            }","size_bytes":14813},"analysis/__init__.py":{"content":"","size_bytes":0},"analysis/historical_analysis.py":{"content":"\"\"\"\nHistorical analysis module for the Rockfall Prediction System\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any\n\nclass HistoricalAnalysis:\n    \"\"\"Provides historical analysis capabilities for mine data\"\"\"\n    \n    def __init__(self):\n        self.analysis_cache = {}\n    \n    def generate_historical_data(self, days=30) -> pd.DataFrame:\n        \"\"\"Generate historical data for analysis\"\"\"\n        # Create time series data\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=days)\n        date_range = pd.date_range(start=start_date, end=end_date, freq='h')\n        \n        # Generate synthetic data with realistic patterns\n        data = []\n        for i, timestamp in enumerate(date_range):\n            # Add daily and seasonal patterns\n            hour_factor = np.sin(timestamp.hour * np.pi / 12)\n            day_factor = np.sin(timestamp.timetuple().tm_yday * 2 * np.pi / 365)\n            \n            # Base risk with patterns and noise\n            base_risk = 0.3 + 0.2 * hour_factor + 0.1 * day_factor\n            risk_probability = max(0, min(1, base_risk + np.random.normal(0, 0.1)))\n            \n            # Environmental factors\n            temp = 15 + 10 * np.sin((timestamp.timetuple().tm_yday + timestamp.hour/24) * 2 * np.pi / 365) + np.random.normal(0, 3)\n            rainfall = max(0, np.random.gamma(2, 2)) if np.random.random() > 0.8 else 0\n            wind_speed = max(0, np.random.gamma(3, 2))\n            \n            # Sensor readings\n            displacement = np.random.uniform(0.1, 2.0)\n            strain = np.random.uniform(0.05, 1.0)\n            vibration = np.random.uniform(0, 0.6)\n            \n            data.append({\n                'timestamp': timestamp,\n                'risk_probability': risk_probability,\n                'temperature': temp,\n                'rainfall': rainfall,\n                'wind_speed': wind_speed,\n                'displacement': displacement,\n                'strain': strain,\n                'vibration': vibration,\n                'alerts_triggered': 1 if risk_probability > 0.7 else 0\n            })\n        \n        return pd.DataFrame(data)\n    \n    def create_risk_timeline(self, data: pd.DataFrame) -> go.Figure:\n        \"\"\"Create risk timeline visualization\"\"\"\n        fig = go.Figure()\n        \n        # Risk probability line\n        fig.add_trace(go.Scatter(\n            x=data['timestamp'],\n            y=data['risk_probability'],\n            mode='lines',\n            name='Risk Probability',\n            line=dict(color='blue', width=2)\n        ))\n        \n        # Risk thresholds\n        fig.add_hline(y=0.7, line_dash=\"dash\", line_color=\"red\", \n                     annotation_text=\"High Risk Threshold\")\n        fig.add_hline(y=0.3, line_dash=\"dash\", line_color=\"yellow\", \n                     annotation_text=\"Medium Risk Threshold\")\n        \n        # Highlight alert periods\n        alert_periods = data[data['alerts_triggered'] == 1]\n        if not alert_periods.empty:\n            fig.add_trace(go.Scatter(\n                x=alert_periods['timestamp'],\n                y=alert_periods['risk_probability'],\n                mode='markers',\n                name='Alerts Triggered',\n                marker=dict(color='red', size=8, symbol='diamond')\n            ))\n        \n        fig.update_layout(\n            title=\"Historical Risk Timeline\",\n            xaxis_title=\"Time\",\n            yaxis_title=\"Risk Probability\",\n            height=400,\n            yaxis=dict(range=[0, 1])\n        )\n        \n        return fig\n    \n    def create_seasonal_analysis(self, data: pd.DataFrame) -> go.Figure:\n        \"\"\"Create seasonal risk pattern analysis\"\"\"\n        # Group by hour of day\n        hourly_risk = data.groupby(data['timestamp'].dt.hour)['risk_probability'].mean()\n        \n        fig = go.Figure()\n        \n        fig.add_trace(go.Scatter(\n            x=hourly_risk.index,\n            y=hourly_risk.values,\n            mode='lines+markers',\n            name='Average Risk by Hour',\n            line=dict(color='green', width=3),\n            marker=dict(size=8)\n        ))\n        \n        fig.update_layout(\n            title=\"Daily Risk Pattern (Average by Hour)\",\n            xaxis_title=\"Hour of Day\",\n            yaxis_title=\"Average Risk Probability\",\n            height=400,\n            xaxis=dict(tickmode='linear', dtick=2)\n        )\n        \n        return fig\n    \n    def calculate_correlations(self, data: pd.DataFrame) -> np.ndarray:\n        \"\"\"Calculate correlation matrix for environmental factors\"\"\"\n        # Select numeric columns for correlation\n        numeric_cols = ['risk_probability', 'temperature', 'rainfall', 'wind_speed', \n                       'displacement', 'strain', 'vibration']\n        \n        correlation_data = data[numeric_cols].corr()\n        return correlation_data.values\n    \n    def generate_report(self, data: pd.DataFrame, start_date, end_date, analysis_type) -> Dict[str, Any]:\n        \"\"\"Generate analysis report\"\"\"\n        \n        # Filter data by date range\n        mask = (data['timestamp'] >= pd.Timestamp(start_date)) & (data['timestamp'] <= pd.Timestamp(end_date))\n        filtered_data = data.loc[mask]\n        \n        if filtered_data.empty:\n            return {\"error\": \"No data available for selected date range\"}\n        \n        report = {}\n        \n        if analysis_type == \"Risk Trends\":\n            report.update({\n                'avg_risk': f\"{filtered_data['risk_probability'].mean():.1%}\",\n                'max_risk': f\"{filtered_data['risk_probability'].max():.1%}\",\n                'min_risk': f\"{filtered_data['risk_probability'].min():.1%}\",\n                'total_alerts': int(filtered_data['alerts_triggered'].sum()),\n                'high_risk_hours': int((filtered_data['risk_probability'] > 0.7).sum()),\n                'trend': \"Increasing\" if filtered_data['risk_probability'].iloc[-1] > filtered_data['risk_probability'].iloc[0] else \"Decreasing\"\n            })\n        \n        elif analysis_type == \"Environmental Impact\":\n            # Calculate correlations with risk\n            risk_corr = filtered_data.corr()['risk_probability'].abs().sort_values(ascending=False)\n            \n            report.update({\n                'strongest_correlation': risk_corr.index[1] if len(risk_corr) > 1 else \"N/A\",  # Skip risk_probability itself\n                'correlation_value': f\"{risk_corr.iloc[1]:.3f}\" if len(risk_corr) > 1 else \"N/A\",\n                'avg_temperature': f\"{filtered_data['temperature'].mean():.1f}¬∞C\",\n                'total_rainfall': f\"{filtered_data['rainfall'].sum():.1f}mm\",\n                'avg_wind_speed': f\"{filtered_data['wind_speed'].mean():.1f}m/s\"\n            })\n        \n        elif analysis_type == \"Sensor Performance\":\n            report.update({\n                'avg_displacement': f\"{filtered_data['displacement'].mean():.2f}mm\",\n                'max_displacement': f\"{filtered_data['displacement'].max():.2f}mm\",\n                'avg_strain': f\"{filtered_data['strain'].mean():.3f}¬µŒµ\",\n                'max_strain': f\"{filtered_data['strain'].max():.3f}¬µŒµ\",\n                'avg_vibration': f\"{filtered_data['vibration'].mean():.3f}g\",\n                'max_vibration': f\"{filtered_data['vibration'].max():.3f}g\"\n            })\n        \n        elif analysis_type == \"Alert Frequency\":\n            # Group by day for alert frequency\n            daily_alerts = filtered_data.groupby(filtered_data['timestamp'].dt.date)['alerts_triggered'].sum()\n            \n            report.update({\n                'total_alerts': int(filtered_data['alerts_triggered'].sum()),\n                'avg_alerts_per_day': f\"{daily_alerts.mean():.1f}\",\n                'max_alerts_in_day': int(daily_alerts.max()) if not daily_alerts.empty else 0,\n                'days_with_alerts': int((daily_alerts > 0).sum()),\n                'alert_rate': f\"{(filtered_data['alerts_triggered'].sum() / len(filtered_data) * 100):.1f}%\"\n            })\n        \n        return report\n    \n    def get_performance_metrics(self, data: pd.DataFrame) -> Dict[str, float]:\n        \"\"\"Calculate system performance metrics\"\"\"\n        return {\n            'data_completeness': 1.0 - (data.isnull().sum().sum() / (len(data) * len(data.columns))),\n            'alert_accuracy': 0.85,  # Would be calculated from actual vs predicted\n            'false_positive_rate': 0.12,\n            'detection_rate': 0.88,\n            'system_availability': 0.995\n        }\n    \n    def identify_anomalies(self, data: pd.DataFrame) -> List[Dict[str, Any]]:\n        \"\"\"Identify anomalous periods in the data\"\"\"\n        anomalies = []\n        \n        # Find periods with unusually high risk\n        high_risk_threshold = data['risk_probability'].quantile(0.95)\n        high_risk_periods = data[data['risk_probability'] > high_risk_threshold]\n        \n        for _, period in high_risk_periods.iterrows():\n            anomalies.append({\n                'timestamp': period['timestamp'],\n                'type': 'High Risk Anomaly',\n                'value': period['risk_probability'],\n                'description': f\"Risk level reached {period['risk_probability']:.1%}\"\n            })\n        \n        # Find unusual sensor readings\n        for sensor in ['displacement', 'strain', 'vibration']:\n            sensor_threshold = data[sensor].quantile(0.95)\n            anomalous_readings = data[data[sensor] > sensor_threshold]\n            \n            for _, reading in anomalous_readings.iterrows():\n                anomalies.append({\n                    'timestamp': reading['timestamp'],\n                    'type': f'{sensor.title()} Anomaly',\n                    'value': reading[sensor],\n                    'description': f\"Unusual {sensor} reading: {reading[sensor]:.3f}\"\n                })\n        \n        return sorted(anomalies, key=lambda x: x['timestamp'], reverse=True)[:10]","size_bytes":10020},"communication/__init__.py":{"content":"","size_bytes":0},"communication/lorawan_simulator.py":{"content":"import numpy as np\nimport random\nfrom datetime import datetime, timedelta\nimport json\n\nclass LoRaWANSimulator:\n    def __init__(self):\n        self.gateways = self._initialize_gateways()\n        self.devices = self._initialize_devices()\n        self.radio_channels = self._initialize_radio_channels()\n        self.network_status = {\n            'uptime': 0.995,\n            'total_messages': 0,\n            'failed_messages': 0,\n            'last_update': datetime.now()\n        }\n    \n    def _initialize_gateways(self):\n        \"\"\"Initialize LoRaWAN gateways around the mine site\"\"\"\n        gateways = []\n        \n        # Main gateways positioned strategically around the mine\n        gateway_positions = [\n            {'id': 'GW001', 'name': 'North Ridge', 'lat': 45.128, 'lon': -123.451, 'elevation': 1350},\n            {'id': 'GW002', 'name': 'South Access', 'lat': 45.118, 'lon': -123.461, 'elevation': 1280},\n            {'id': 'GW003', 'name': 'East Monitor', 'lat': 45.123, 'lon': -123.446, 'elevation': 1320},\n            {'id': 'GW004', 'name': 'West Platform', 'lat': 45.123, 'lon': -123.466, 'elevation': 1300},\n            {'id': 'GW005', 'name': 'Central Hub', 'lat': 45.123, 'lon': -123.456, 'elevation': 1250}\n        ]\n        \n        for gw_pos in gateway_positions:\n            gateway = {\n                'id': gw_pos['id'],\n                'name': gw_pos['name'],\n                'coordinates': {\n                    'lat': gw_pos['lat'],\n                    'lon': gw_pos['lon'], \n                    'elevation': gw_pos['elevation']\n                },\n                'status': 'online' if np.random.random() > 0.05 else 'offline',\n                'signal_strength': np.random.uniform(-60, -40),  # dBm\n                'coverage_radius': np.random.uniform(800, 1200),  # meters\n                'connected_devices': np.random.randint(8, 15),\n                'battery_backup': np.random.uniform(85, 100),  # %\n                'last_maintenance': datetime.now() - timedelta(days=np.random.randint(1, 45)),\n                'frequency_band': 'EU868' if np.random.random() > 0.5 else 'US915',\n                'data_rate': f'SF{np.random.randint(7, 12)}',  # Spreading Factor\n                'power_output': np.random.uniform(14, 20)  # dBm\n            }\n            gateways.append(gateway)\n        \n        return gateways\n    \n    def _initialize_devices(self):\n        \"\"\"Initialize LoRaWAN devices (sensors)\"\"\"\n        devices = []\n        \n        for i in range(47):  # 47 sensors as per requirements\n            device = {\n                'id': f\"DEV{i+1:03d}\",\n                'sensor_id': f\"S{i+1:03d}\",\n                'device_type': np.random.choice(['Class A', 'Class B', 'Class C']),\n                'connected_gateway': np.random.choice([gw['id'] for gw in self.gateways]),\n                'battery_level': np.random.uniform(20, 100),\n                'signal_strength': np.random.uniform(-120, -70),  # dBm\n                'uplink_count': np.random.randint(1000, 50000),\n                'downlink_count': np.random.randint(10, 500),\n                'last_seen': datetime.now() - timedelta(minutes=np.random.randint(1, 30)),\n                'data_rate': f'SF{np.random.randint(7, 12)}',\n                'frequency': np.random.uniform(867.1, 868.5),  # MHz for EU868\n                'transmission_power': np.random.randint(2, 14),  # dBm\n                'adr_enabled': np.random.choice([True, False]),  # Adaptive Data Rate\n                'join_status': 'joined' if np.random.random() > 0.02 else 'joining',\n                'packet_loss_rate': np.random.uniform(0, 0.15)\n            }\n            devices.append(device)\n        \n        return devices\n    \n    def _initialize_radio_channels(self):\n        \"\"\"Initialize radio communication channels for backup\"\"\"\n        channels = []\n        \n        # VHF channels for emergency communication\n        vhf_channels = [\n            {'id': 'VHF001', 'frequency': 151.4, 'name': 'Emergency Primary'},\n            {'id': 'VHF002', 'frequency': 154.5, 'name': 'Operations'},\n            {'id': 'VHF003', 'frequency': 158.7, 'name': 'Maintenance'},\n            {'id': 'VHF004', 'frequency': 162.3, 'name': 'Security'}\n        ]\n        \n        # UHF channels for data communication\n        uhf_channels = [\n            {'id': 'UHF001', 'frequency': 450.2, 'name': 'Data Backup 1'},\n            {'id': 'UHF002', 'frequency': 455.8, 'name': 'Data Backup 2'},\n            {'id': 'UHF003', 'frequency': 460.1, 'name': 'Telemetry'}\n        ]\n        \n        all_channels = vhf_channels + uhf_channels\n        \n        for channel in all_channels:\n            channel.update({\n                'status': 'active' if np.random.random() > 0.1 else 'standby',\n                'power_output': np.random.uniform(5, 25),  # Watts\n                'range': np.random.uniform(5, 15),  # km\n                'noise_level': np.random.uniform(-110, -90),  # dBm\n                'modulation': 'FM' if 'VHF' in channel['id'] else 'FSK',\n                'bandwidth': 25 if 'VHF' in channel['id'] else 12.5  # kHz\n            })\n        \n        return all_channels\n    \n    def get_network_status(self):\n        \"\"\"Get current LoRaWAN network status\"\"\"\n        online_gateways = sum(1 for gw in self.gateways if gw['status'] == 'online')\n        total_gateways = len(self.gateways)\n        \n        connected_devices = sum(1 for dev in self.devices if dev['join_status'] == 'joined')\n        total_devices = len(self.devices)\n        \n        # Calculate average signal strength\n        avg_signal = np.mean([gw['signal_strength'] for gw in self.gateways if gw['status'] == 'online'])\n        \n        # Calculate network coverage\n        coverage = (online_gateways / total_gateways) * 0.8 + (connected_devices / total_devices) * 0.2\n        \n        return {\n            'network_type': 'LoRaWAN',\n            'coverage': coverage,\n            'gateways': online_gateways,\n            'total_gateways': total_gateways,\n            'devices': connected_devices,\n            'total_devices': total_devices,\n            'signal_strength': avg_signal,\n            'uptime': self.network_status['uptime'],\n            'packet_success_rate': 1 - np.mean([dev.get('packet_loss_rate', 0) for dev in self.devices]),\n            'gateway_list': [\n                {\n                    'id': gw['id'],\n                    'name': gw['name'],\n                    'status': gw['status'],\n                    'signal_strength': gw['signal_strength'],\n                    'connected_devices': gw['connected_devices']\n                }\n                for gw in self.gateways\n            ]\n        }\n    \n    def get_radio_status(self):\n        \"\"\"Get radio communication backup status\"\"\"\n        active_channels = [ch for ch in self.radio_channels if ch['status'] == 'active']\n        \n        if active_channels:\n            avg_power = np.mean([ch['power_output'] for ch in active_channels])\n            avg_range = np.mean([ch['range'] for ch in active_channels])\n            error_rate = np.random.uniform(0.01, 0.05)  # Typical radio error rate\n        else:\n            avg_power = 0\n            avg_range = 0\n            error_rate = 1.0\n        \n        return {\n            'communication_type': 'Radio Backup',\n            'active_channels': len(active_channels),\n            'total_channels': len(self.radio_channels),\n            'frequency': np.mean([ch['frequency'] for ch in active_channels]) if active_channels else 0,\n            'power': avg_power,\n            'range': avg_range,\n            'error_rate': error_rate,\n            'channel_list': [\n                {\n                    'id': ch['id'],\n                    'name': ch['name'],\n                    'frequency': ch['frequency'],\n                    'status': ch['status'],\n                    'power': ch['power_output']\n                }\n                for ch in self.radio_channels\n            ]\n        }\n    \n    def simulate_data_transmission(self, device_id, data_payload):\n        \"\"\"Simulate data transmission through LoRaWAN\"\"\"\n        device = next((dev for dev in self.devices if dev['id'] == device_id), None)\n        \n        if not device:\n            return {\n                'success': False,\n                'error': 'Device not found',\n                'timestamp': datetime.now()\n            }\n        \n        # Find connected gateway\n        gateway = next((gw for gw in self.gateways if gw['id'] == device['connected_gateway']), None)\n        \n        if not gateway or gateway['status'] != 'online':\n            # Try to find alternative gateway\n            online_gateways = [gw for gw in self.gateways if gw['status'] == 'online']\n            if online_gateways:\n                gateway = min(online_gateways, key=lambda x: np.random.random())  # Simulate closest gateway\n                device['connected_gateway'] = gateway['id']\n            else:\n                return {\n                    'success': False,\n                    'error': 'No online gateways available',\n                    'timestamp': datetime.now()\n                }\n        \n        # Simulate transmission success based on signal strength and other factors\n        success_probability = 0.95  # Base success rate\n        \n        # Reduce success based on signal strength\n        if device['signal_strength'] < -110:\n            success_probability *= 0.7\n        elif device['signal_strength'] < -100:\n            success_probability *= 0.85\n        \n        # Reduce success based on battery level\n        if device['battery_level'] < 20:\n            success_probability *= 0.8\n        \n        # Simulate packet loss\n        success_probability *= (1 - device.get('packet_loss_rate', 0.05))\n        \n        transmission_successful = np.random.random() < success_probability\n        \n        if transmission_successful:\n            # Update device statistics\n            device['uplink_count'] += 1\n            device['last_seen'] = datetime.now()\n            \n            # Update network statistics\n            self.network_status['total_messages'] += 1\n            \n            return {\n                'success': True,\n                'gateway_used': gateway['id'],\n                'signal_strength': device['signal_strength'],\n                'data_rate': device['data_rate'],\n                'transmission_time': np.random.uniform(0.1, 2.0),  # seconds\n                'timestamp': datetime.now()\n            }\n        else:\n            # Update failure statistics\n            self.network_status['failed_messages'] += 1\n            \n            return {\n                'success': False,\n                'error': 'Transmission failed',\n                'gateway_attempted': gateway['id'],\n                'signal_strength': device['signal_strength'],\n                'timestamp': datetime.now()\n            }\n    \n    def test_emergency_communication(self):\n        \"\"\"Test emergency communication systems\"\"\"\n        results = {\n            'lorawan_test': False,\n            'radio_test': False,\n            'satellite_test': False,\n            'overall_success': False\n        }\n        \n        # Test LoRaWAN\n        online_gateways = [gw for gw in self.gateways if gw['status'] == 'online']\n        if len(online_gateways) >= 2:  # Need at least 2 gateways for redundancy\n            results['lorawan_test'] = True\n        \n        # Test Radio\n        active_radio_channels = [ch for ch in self.radio_channels if ch['status'] == 'active']\n        if len(active_radio_channels) >= 1:\n            results['radio_test'] = True\n        \n        # Simulate satellite backup (always available but with some probability)\n        results['satellite_test'] = np.random.random() > 0.05  # 95% availability\n        \n        # Overall success if at least one communication method works\n        results['overall_success'] = any([\n            results['lorawan_test'],\n            results['radio_test'],\n            results['satellite_test']\n        ])\n        \n        return results\n    \n    def get_device_status(self, device_id):\n        \"\"\"Get detailed status of a specific device\"\"\"\n        device = next((dev for dev in self.devices if dev['id'] == device_id), None)\n        \n        if not device:\n            return {'error': 'Device not found'}\n        \n        gateway = next((gw for gw in self.gateways if gw['id'] == device['connected_gateway']), None)\n        \n        return {\n            'device_id': device['id'],\n            'sensor_id': device['sensor_id'],\n            'status': 'online' if device['join_status'] == 'joined' else 'offline',\n            'battery_level': device['battery_level'],\n            'signal_strength': device['signal_strength'],\n            'connected_gateway': {\n                'id': gateway['id'] if gateway else 'None',\n                'name': gateway['name'] if gateway else 'None',\n                'status': gateway['status'] if gateway else 'offline'\n            },\n            'communication_stats': {\n                'uplink_count': device['uplink_count'],\n                'downlink_count': device['downlink_count'],\n                'packet_loss_rate': device['packet_loss_rate'],\n                'last_seen': device['last_seen']\n            },\n            'technical_details': {\n                'data_rate': device['data_rate'],\n                'frequency': device['frequency'],\n                'power': device['transmission_power'],\n                'adr_enabled': device['adr_enabled']\n            }\n        }\n    \n    def simulate_network_failure(self, failure_type='gateway_failure'):\n        \"\"\"Simulate various network failure scenarios\"\"\"\n        if failure_type == 'gateway_failure':\n            # Simulate random gateway failure\n            online_gateways = [gw for gw in self.gateways if gw['status'] == 'online']\n            if online_gateways:\n                failed_gateway = np.random.choice(online_gateways)\n                failed_gateway['status'] = 'offline'\n                \n                # Reassign devices to other gateways\n                affected_devices = [dev for dev in self.devices if dev['connected_gateway'] == failed_gateway['id']]\n                remaining_gateways = [gw for gw in self.gateways if gw['status'] == 'online']\n                \n                for device in affected_devices:\n                    if remaining_gateways:\n                        device['connected_gateway'] = np.random.choice(remaining_gateways)['id']\n                    else:\n                        device['join_status'] = 'joining'  # No available gateways\n        \n        elif failure_type == 'interference':\n            # Simulate radio interference affecting signal quality\n            for device in self.devices:\n                device['signal_strength'] -= np.random.uniform(5, 15)\n                device['packet_loss_rate'] = min(0.5, device['packet_loss_rate'] + np.random.uniform(0.05, 0.2))\n        \n        elif failure_type == 'power_outage':\n            # Simulate power outage affecting gateways without backup\n            for gateway in self.gateways:\n                if gateway['battery_backup'] < 50:  # Gateways with low backup\n                    gateway['status'] = 'offline'\n        \n        return {\n            'failure_type': failure_type,\n            'timestamp': datetime.now(),\n            'affected_components': self._count_affected_components()\n        }\n    \n    def _count_affected_components(self):\n        \"\"\"Count affected network components\"\"\"\n        offline_gateways = sum(1 for gw in self.gateways if gw['status'] == 'offline')\n        disconnected_devices = sum(1 for dev in self.devices if dev['join_status'] != 'joined')\n        \n        return {\n            'offline_gateways': offline_gateways,\n            'disconnected_devices': disconnected_devices,\n            'network_coverage': 1 - (offline_gateways / len(self.gateways))\n        }","size_bytes":15877},"dashboard/__init__.py":{"content":"","size_bytes":0},"dashboard/real_time_dashboard.py":{"content":"\"\"\"\nReal-time dashboard components for the Rockfall Prediction System\n\"\"\"\n\nimport streamlit as st\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport numpy as np\n\nclass RealTimeDashboard:\n    \"\"\"Real-time dashboard for monitoring mine conditions\"\"\"\n    \n    def __init__(self):\n        self.refresh_interval = 30  # seconds\n        \n    def render_overview_metrics(self, mine_data):\n        \"\"\"Render key overview metrics\"\"\"\n        sensors = mine_data.get('sensors', [])\n        total_sensors = len(sensors)\n        online_sensors = len([s for s in sensors if s.get('status') == 'online'])\n        \n        # Calculate overall risk level\n        risk_levels = [s.get('risk_probability', 0) for s in sensors]\n        avg_risk = np.mean(risk_levels) if risk_levels else 0\n        \n        col1, col2, col3, col4 = st.columns(4)\n        \n        with col1:\n            st.metric(\"Active Sensors\", f\"{online_sensors}/{total_sensors}\")\n        \n        with col2:\n            risk_color = \"red\" if avg_risk > 0.7 else \"orange\" if avg_risk > 0.3 else \"green\"\n            st.metric(\"Average Risk Level\", f\"{avg_risk:.1%}\")\n        \n        with col3:\n            # Simulate communication status\n            comm_status = np.random.uniform(0.85, 0.98)\n            st.metric(\"Communication\", f\"{comm_status:.1%}\")\n        \n        with col4:\n            # Simulate system uptime\n            uptime = np.random.uniform(0.95, 0.999)\n            st.metric(\"System Uptime\", f\"{uptime:.1%}\")\n    \n    def render_risk_timeline(self, prediction_data=None):\n        \"\"\"Render risk timeline chart\"\"\"\n        if prediction_data is None:\n            # Generate sample data\n            times = [datetime.now() + timedelta(hours=i) for i in range(24)]\n            risks = [0.3 + 0.2 * np.sin(i * np.pi / 12) + np.random.normal(0, 0.1) for i in range(24)]\n            risks = [max(0, min(1, r)) for r in risks]\n        else:\n            times = [p['timestamp'] for p in prediction_data]\n            risks = [p['risk_probability'] for p in prediction_data]\n        \n        fig = go.Figure()\n        \n        # Risk line\n        fig.add_trace(go.Scatter(\n            x=times,\n            y=risks,\n            mode='lines+markers',\n            name='Risk Probability',\n            line=dict(color='#64748b', width=2),\n            marker=dict(size=6)\n        ))\n        \n        # Risk thresholds\n        fig.add_hline(y=0.7, line_dash=\"dash\", line_color=\"red\", \n                     annotation_text=\"High Risk\")\n        fig.add_hline(y=0.3, line_dash=\"dash\", line_color=\"yellow\", \n                     annotation_text=\"Medium Risk\")\n        \n        fig.update_layout(\n            title=\"24-Hour Risk Prediction\",\n            xaxis_title=\"Time\",\n            yaxis_title=\"Risk Probability\",\n            height=400,\n            yaxis=dict(range=[0, 1])\n        )\n        \n        st.plotly_chart(fig, use_container_width=True)\n    \n    def render_sensor_status_grid(self, sensors):\n        \"\"\"Render sensor status grid\"\"\"\n        if not sensors:\n            st.warning(\"No sensor data available\")\n            return\n        \n        # Create grid layout\n        cols_per_row = 4\n        rows = [sensors[i:i + cols_per_row] for i in range(0, len(sensors), cols_per_row)]\n        \n        for row in rows:\n            cols = st.columns(len(row))\n            for i, sensor in enumerate(row):\n                with cols[i]:\n                    status = sensor.get('status', 'unknown')\n                    risk = sensor.get('risk_probability', 0)\n                    \n                    # Determine color based on status and risk\n                    if status == 'offline':\n                        color = \"gray\"\n                    elif risk > 0.7:\n                        color = \"red\"\n                    elif risk > 0.3:\n                        color = \"orange\"\n                    else:\n                        color = \"green\"\n                    \n                    st.markdown(f\"\"\"\n                    <div style=\"\n                        border: 2px solid {color};\n                        padding: 10px;\n                        border-radius: 5px;\n                        text-align: center;\n                        margin: 5px 0;\n                    \">\n                        <strong>{sensor.get('id', 'Unknown')}</strong><br>\n                        Risk: {risk:.1%}<br>\n                        Status: {status}\n                    </div>\n                    \"\"\", unsafe_allow_html=True)\n    \n    def render_communication_status(self, comm_data):\n        \"\"\"Render communication system status\"\"\"\n        st.subheader(\"Communication Systems\")\n        \n        if not comm_data:\n            st.info(\"Communication data not available\")\n            return\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.write(\"**LoRaWAN Network**\")\n            lorawan_status = comm_data.get('lorawan', {})\n            \n            coverage = lorawan_status.get('coverage', 0.85)\n            gateways = lorawan_status.get('gateways', 4)\n            devices = lorawan_status.get('devices', 42)\n            \n            st.metric(\"Network Coverage\", f\"{coverage:.1%}\")\n            st.metric(\"Active Gateways\", gateways)\n            st.metric(\"Connected Devices\", devices)\n        \n        with col2:\n            st.write(\"**Radio Backup**\")\n            radio_status = comm_data.get('radio', {})\n            \n            channels = radio_status.get('active_channels', 5)\n            error_rate = radio_status.get('error_rate', 0.03)\n            \n            st.metric(\"Active Channels\", channels)\n            st.metric(\"Error Rate\", f\"{error_rate:.1%}\")\n    \n    def render_recent_alerts(self, alerts):\n        \"\"\"Render recent alerts panel\"\"\"\n        st.subheader(\"Recent Alerts\")\n        \n        if not alerts:\n            st.success(\"No recent alerts\")\n            return\n        \n        for alert in alerts[:5]:  # Show last 5 alerts\n            severity = alert.get('severity', 'low')\n            timestamp = alert.get('timestamp', datetime.now())\n            message = alert.get('message', 'Unknown alert')\n            zone = alert.get('zone', 'Unknown zone')\n            \n            # Color coding by severity\n            if severity == 'critical':\n                color = \"red\"\n            elif severity == 'high':\n                color = \"orange\"\n            elif severity == 'medium':\n                color = \"yellow\"\n            else:\n                color = \"green\"\n            \n            with st.expander(f\"{severity.upper()} - {zone} ({timestamp.strftime('%H:%M')})\"):\n                st.write(message)\n                if 'channels_used' in alert:\n                    st.write(f\"Sent via: {', '.join(alert['channels_used'])}\")\n    \n    def render_environmental_conditions(self, env_data):\n        \"\"\"Render environmental conditions\"\"\"\n        st.subheader(\"Environmental Conditions\")\n        \n        if not env_data:\n            st.info(\"Environmental data not available\")\n            return\n        \n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            temp = env_data.get('temperature', 15)\n            st.metric(\"Temperature\", f\"{temp:.1f}¬∞C\")\n            \n            humidity = env_data.get('humidity', 65)\n            st.metric(\"Humidity\", f\"{humidity:.0f}%\")\n        \n        with col2:\n            wind_speed = env_data.get('wind_speed', 12)\n            st.metric(\"Wind Speed\", f\"{wind_speed:.1f} m/s\")\n            \n            rainfall = env_data.get('rainfall', 0)\n            st.metric(\"Rainfall\", f\"{rainfall:.1f} mm/h\")\n        \n        with col3:\n            pressure = env_data.get('atmospheric_pressure', 1013)\n            st.metric(\"Pressure\", f\"{pressure:.0f} hPa\")\n    \n    def render_auto_refresh_control(self):\n        \"\"\"Render auto-refresh controls\"\"\"\n        col1, col2 = st.columns([3, 1])\n        \n        with col1:\n            auto_refresh = st.checkbox(\"Auto-refresh\", value=True)\n        \n        with col2:\n            if st.button(\"Refresh Now\"):\n                st.rerun()\n        \n        if auto_refresh:\n            # Auto-refresh every 30 seconds\n            st.empty()  # Placeholder for refresh logic\n    \n    def render_system_status(self, system_stats):\n        \"\"\"Render overall system status\"\"\"\n        st.subheader(\"System Status\")\n        \n        if not system_stats:\n            st.warning(\"System statistics not available\")\n            return\n        \n        # Status indicators\n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            st.write(\"**Model Performance**\")\n            accuracy = system_stats.get('model_accuracy', 0.85)\n            st.metric(\"Accuracy\", f\"{accuracy:.1%}\")\n            \n        with col2:\n            st.write(\"**Data Quality**\")\n            quality = system_stats.get('data_quality', 0.92)\n            st.metric(\"Data Quality\", f\"{quality:.1%}\")\n            \n        with col3:\n            st.write(\"**Prediction Confidence**\")\n            confidence = system_stats.get('prediction_confidence', 0.78)\n            st.metric(\"Confidence\", f\"{confidence:.1%}\")\n    \n    def render_full_dashboard(self, mine_data, predictions=None, alerts=None, comm_data=None):\n        \"\"\"Render the complete real-time dashboard\"\"\"\n        st.title(\"üèîÔ∏è Real-Time Mine Monitoring Dashboard\")\n        \n        # Overview metrics\n        self.render_overview_metrics(mine_data)\n        \n        st.divider()\n        \n        # Main content in columns\n        col1, col2 = st.columns([2, 1])\n        \n        with col1:\n            # Risk timeline\n            self.render_risk_timeline(predictions)\n            \n            # Sensor status grid\n            st.subheader(\"Sensor Network Status\")\n            sensors = mine_data.get('sensors', [])\n            self.render_sensor_status_grid(sensors)\n        \n        with col2:\n            # Recent alerts\n            self.render_recent_alerts(alerts or [])\n            \n            # Environmental conditions\n            env_data = mine_data.get('environmental', {})\n            self.render_environmental_conditions(env_data)\n            \n            # Communication status\n            self.render_communication_status(comm_data)\n        \n        st.divider()\n        \n        # System status at bottom\n        system_stats = mine_data.get('system_stats', {})\n        self.render_system_status(system_stats)\n        \n        # Auto-refresh controls\n        self.render_auto_refresh_control()","size_bytes":10521},"data/__init__.py":{"content":"","size_bytes":0},"data/synthetic_data_generator.py":{"content":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport json\n\nclass SyntheticDataGenerator:\n    def __init__(self):\n        self.sensor_count = 47\n        self.zone_count = 12\n        self.base_coordinates = {'lat': 45.123, 'lon': -123.456}\n        print(f\"SyntheticDataGenerator initialized with {self.sensor_count} sensors\")\n        \n    def generate_real_time_data(self):\n        \"\"\"Generate current sensor readings and environmental data\"\"\"\n        current_time = datetime.now()\n        \n        # Generate sensor data\n        sensors = []\n        for i in range(self.sensor_count):\n            # Base risk varies by sensor location and time\n            base_risk = 0.2 + 0.3 * np.sin(i * np.pi / 10) + 0.1 * np.sin(current_time.hour * np.pi / 12)\n            noise = np.random.normal(0, 0.15)\n            risk_probability = max(0, min(1, base_risk + noise))\n            \n            sensor_data = {\n                'id': f\"S{i+1:03d}\",\n                'sensor_id': f\"S{i+1:03d}\",\n                'zone': f\"Zone_{(i // 4) + 1}\",\n                'coordinates': {\n                    'lat': self.base_coordinates['lat'] + np.random.uniform(-0.01, 0.01),\n                    'lon': self.base_coordinates['lon'] + np.random.uniform(-0.01, 0.01),\n                    'elevation': 1200 + np.random.uniform(-100, 200)\n                },\n                'displacement_rate': np.random.uniform(0.1, 2.5),  # mm/day\n                'strain_magnitude': np.random.uniform(0.05, 1.2),  # microstrains\n                'pore_pressure': np.random.uniform(50, 150),  # kPa\n                'vibration_level': np.random.uniform(0, 0.8),  # g-force\n                'crack_density': np.random.uniform(0, 0.6),  # cracks/m¬≤\n                'soil_moisture': np.random.uniform(10, 40),  # %\n                'slope_angle': np.random.uniform(35, 75),  # degrees\n                'risk_probability': risk_probability,\n                'latest_value': f\"{risk_probability:.2f}\",\n                'sensor_type': random.choice(['displacement', 'strain', 'pressure', 'vibration']),\n                'status': 'online' if np.random.random() > 0.05 else 'offline',\n                'last_update': current_time - timedelta(minutes=np.random.randint(0, 5))\n            }\n            sensors.append(sensor_data)\n        \n        # Generate environmental data\n        environmental = {\n            'temperature': np.random.normal(15, 10),  # Celsius\n            'rainfall': max(0, np.random.gamma(2, 2)),  # mm/hour\n            'precipitation': max(0, np.random.gamma(2, 2)),  # mm/hour (alias)\n            'wind_speed': max(0, np.random.gamma(3, 2)),  # m/s\n            'wind_direction': np.random.uniform(0, 360),  # degrees\n            'humidity': np.random.uniform(30, 95),  # %\n            'atmospheric_pressure': np.random.normal(1013, 20),  # hPa\n            'solar_radiation': max(0, np.random.gamma(5, 100)),  # W/m¬≤\n            'timestamp': current_time\n        }\n        \n        # Generate DEM data (simplified)\n        dem_data = self.generate_dem_data()\n        \n        return {\n            'sensors': sensors,\n            'environmental': environmental,\n            'dem': dem_data,\n            'timestamp': current_time\n        }\n    \n    def generate_dem_data(self):\n        \"\"\"Generate Digital Elevation Model data\"\"\"\n        # Create a grid representing the mine topology\n        grid_size = 50\n        x = np.linspace(0, 1000, grid_size)  # meters\n        y = np.linspace(0, 800, grid_size)   # meters\n        X, Y = np.meshgrid(x, y)\n        \n        # Create realistic mine pit topology\n        # Central depression with terraced sides\n        center_x, center_y = 500, 400\n        distance_from_center = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n        \n        # Base elevation with pit\n        Z = 1300 - 0.3 * distance_from_center  # Gradual slope down to pit\n        \n        # Add terraces (benches) typical in open pit mines\n        terrace_height = 15  # meters between benches\n        Z = np.floor(Z / terrace_height) * terrace_height\n        \n        # Add some geological variation\n        Z += 5 * np.sin(X / 100) * np.cos(Y / 80)\n        Z += np.random.normal(0, 2, Z.shape)  # Surface roughness\n        \n        return {\n            'x': X.tolist(),\n            'y': Y.tolist(),\n            'z': Z.tolist(),\n            'grid_size': grid_size,\n            'resolution': 20  # meters per grid cell\n        }\n    \n    def generate_mine_topology(self):\n        \"\"\"Generate detailed 3D mine topology data\"\"\"\n        # Generate mine structure with multiple zones\n        zones = []\n        \n        for zone_id in range(1, self.zone_count + 1):\n            # Random zone positioning around the mine\n            angle = (zone_id - 1) * 2 * np.pi / self.zone_count\n            zone_x = 500 + 300 * np.cos(angle)\n            zone_y = 400 + 200 * np.sin(angle)\n            \n            # Zone-specific risk level\n            base_risk = np.random.uniform(0.1, 0.8)\n            \n            zone_data = {\n                'id': zone_id,\n                'name': f\"Zone_{zone_id}\",\n                'center_coordinates': {'x': zone_x, 'y': zone_y, 'z': 1250 + np.random.uniform(-50, 50)},\n                'risk_level': base_risk,\n                'geological_type': np.random.choice(['limestone', 'sandstone', 'shale', 'granite']),\n                'slope_stability': np.random.uniform(0.3, 0.9),\n                'sensor_count': np.random.randint(2, 6),\n                'last_incident': datetime.now() - timedelta(days=np.random.randint(1, 365)) if np.random.random() > 0.7 else None\n            }\n            zones.append(zone_data)\n        \n        # Generate detailed DEM\n        dem_data = self.generate_dem_data()\n        \n        # Add sensor network\n        sensor_network = self.generate_sensor_network()\n        \n        return {\n            'zones': zones,\n            'dem': dem_data,\n            'sensor_network': sensor_network,\n            'mine_parameters': {\n                'total_area': 800000,  # m¬≤\n                'max_depth': 200,      # meters\n                'active_benches': 12,\n                'access_roads': 8,\n                'equipment_zones': 15\n            }\n        }\n    \n    def generate_sensor_network(self):\n        \"\"\"Generate sensor network topology\"\"\"\n        sensors = []\n        \n        for i in range(self.sensor_count):\n            # Distribute sensors across the mine area\n            x = np.random.uniform(50, 950)\n            y = np.random.uniform(50, 750)\n            z = 1200 + np.random.uniform(0, 100)\n            \n            sensor = {\n                'id': f\"S{i+1:03d}\",\n                'type': np.random.choice(['displacement', 'strain', 'pressure', 'vibration', 'tilt']),\n                'coordinates': {'x': x, 'y': y, 'z': z},\n                'communication_type': np.random.choice(['LoRaWAN', 'radio', 'wired']),\n                'battery_level': np.random.uniform(20, 100) if np.random.choice(['LoRaWAN', 'radio']) else 100,\n                'signal_strength': np.random.uniform(-120, -70),  # dBm\n                'installation_date': datetime.now() - timedelta(days=np.random.randint(30, 730)),\n                'maintenance_due': datetime.now() + timedelta(days=np.random.randint(1, 90))\n            }\n            sensors.append(sensor)\n        \n        return sensors\n    \n    def generate_drone_imagery_data(self):\n        \"\"\"Generate synthetic drone imagery analysis data\"\"\"\n        flights = []\n        \n        # Generate recent drone flights\n        for i in range(10):\n            flight_time = datetime.now() - timedelta(hours=np.random.randint(1, 72))\n            \n            flight_data = {\n                'flight_id': f\"DRONE_{i+1:03d}\",\n                'timestamp': flight_time,\n                'coverage_area': {\n                    'zones_covered': np.random.choice(range(1, self.zone_count+1), size=np.random.randint(3, 8), replace=False).tolist()\n                },\n                'image_analysis': {\n                    'total_images': np.random.randint(150, 500),\n                    'crack_detection_count': np.random.randint(5, 25),\n                    'vegetation_health': np.random.uniform(0.6, 0.95),\n                    'surface_changes_detected': np.random.randint(2, 12),\n                    'weather_conditions': np.random.choice(['clear', 'partly_cloudy', 'overcast', 'light_rain'])\n                },\n                'risk_indicators': {\n                    'new_cracks': np.random.randint(0, 5),\n                    'rock_displacement': np.random.uniform(0, 15),  # mm\n                    'erosion_detected': np.random.choice([True, False]),\n                    'overall_risk_score': np.random.uniform(0.2, 0.8)\n                }\n            }\n            flights.append(flight_data)\n        \n        return flights\n    \n    def generate_historical_sensor_data(self, days=30):\n        \"\"\"Generate historical sensor data for trend analysis\"\"\"\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=days)\n        \n        # Generate hourly data points\n        time_points = []\n        current = start_date\n        while current <= end_date:\n            time_points.append(current)\n            current += timedelta(hours=1)\n        \n        historical_data = []\n        \n        for timestamp in time_points:\n            # Simulate daily and seasonal patterns\n            hour_factor = np.sin(timestamp.hour * np.pi / 12)\n            day_factor = np.sin(timestamp.timetuple().tm_yday * 2 * np.pi / 365)\n            \n            # Generate sensor readings for this timestamp\n            for sensor_id in range(1, self.sensor_count + 1):\n                base_reading = 0.3 + 0.2 * hour_factor + 0.1 * day_factor\n                noise = np.random.normal(0, 0.1)\n                risk_level = max(0, min(1, base_reading + noise))\n                \n                reading = {\n                    'timestamp': timestamp,\n                    'sensor_id': f\"S{sensor_id:03d}\",\n                    'displacement_rate': np.random.uniform(0.1, 2.0),\n                    'strain_magnitude': np.random.uniform(0.05, 1.0),\n                    'pore_pressure': np.random.uniform(50, 140),\n                    'temperature': 15 + 10 * np.sin((timestamp.timetuple().tm_yday + timestamp.hour/24) * 2 * np.pi / 365) + np.random.normal(0, 2),\n                    'rainfall': max(0, np.random.gamma(2, 2)) if np.random.random() > 0.7 else 0,\n                    'wind_speed': max(0, np.random.gamma(3, 2)),\n                    'vibration_level': np.random.uniform(0, 0.6),\n                    'risk_probability': risk_level,\n                    'alert_triggered': risk_level > 0.7\n                }\n                historical_data.append(reading)\n        \n        return historical_data","size_bytes":10819},"database/__init__.py":{"content":"","size_bytes":0},"database/database_manager.py":{"content":"\"\"\"\nDatabase management utilities for the Rockfall Prediction System\nHandles initialization, data queries, and database operations\n\"\"\"\n\nfrom typing import List, Dict, Any, Optional, Tuple\nfrom datetime import datetime, timedelta\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import func, desc, asc\nfrom .schema import (\n    DatabaseManager, MineSite, Sensor, SensorReading, \n    EnvironmentalData, RiskAssessment, Alert, DroneImagery, \n    SystemLog, CommunicationLog\n)\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass RockfallDatabaseManager:\n    \"\"\"High-level database operations for the rockfall prediction system\"\"\"\n    \n    def __init__(self):\n        self.db_manager = DatabaseManager()\n        self.db_manager.create_tables()\n        self._initialize_default_data()\n    \n    def _initialize_default_data(self):\n        \"\"\"Initialize default mine site and sensors if not exists\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            # Check if we have any mine sites\n            mine_count = session.query(MineSite).count()\n            \n            if mine_count == 0:\n                # Create default mine site\n                default_mine = MineSite(\n                    name=\"Copper Ridge Mine\",\n                    location=\"Colorado, USA\",\n                    coordinates={\"lat\": 39.7392, \"lon\": -104.9903},\n                    site_boundaries=[\n                        {\"lat\": 39.7400, \"lon\": -104.9910},\n                        {\"lat\": 39.7400, \"lon\": -104.9890},\n                        {\"lat\": 39.7380, \"lon\": -104.9890},\n                        {\"lat\": 39.7380, \"lon\": -104.9910}\n                    ],\n                    active=True\n                )\n                session.add(default_mine)\n                session.flush()\n                \n                # Create default sensors\n                sensor_configs = [\n                    {\"type\": \"displacement\", \"coords\": {\"x\": 100, \"y\": 200, \"z\": 50}},\n                    {\"type\": \"strain\", \"coords\": {\"x\": 150, \"y\": 180, \"z\": 45}},\n                    {\"type\": \"pressure\", \"coords\": {\"x\": 120, \"y\": 220, \"z\": 55}},\n                    {\"type\": \"vibration\", \"coords\": {\"x\": 180, \"y\": 160, \"z\": 40}},\n                    {\"type\": \"tilt\", \"coords\": {\"x\": 90, \"y\": 240, \"z\": 60}}\n                ]\n                \n                for i, config in enumerate(sensor_configs):\n                    sensor = Sensor(\n                        sensor_id=f\"SENSOR_{config['type'].upper()}_{i+1:03d}\",\n                        mine_site_id=default_mine.id,\n                        sensor_type=config['type'],\n                        coordinates=config['coords'],\n                        status='active',\n                        communication_protocol='LoRaWAN',\n                        battery_level=85.0,\n                        signal_strength=-65.0\n                    )\n                    session.add(sensor)\n                \n                session.commit()\n                logger.info(\"Initialized default mine site and sensors\")\n                \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error initializing default data: {e}\")\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_mine_sites(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all active mine sites\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            sites = session.query(MineSite).filter_by(active=True).all()\n            return [\n                {\n                    \"id\": site.id,\n                    \"name\": site.name,\n                    \"location\": site.location,\n                    \"coordinates\": site.coordinates,\n                    \"site_boundaries\": site.site_boundaries,\n                    \"sensor_count\": len(site.sensors),\n                    \"created_at\": site.created_at.isoformat()\n                }\n                for site in sites\n            ]\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_sensors_for_site(self, mine_site_id: int) -> List[Dict[str, Any]]:\n        \"\"\"Get all sensors for a specific mine site\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            sensors = session.query(Sensor).filter_by(\n                mine_site_id=mine_site_id, \n                status='active'\n            ).all()\n            \n            sensor_data = []\n            for sensor in sensors:\n                # Get latest reading\n                latest_reading = session.query(SensorReading).filter_by(\n                    sensor_id=sensor.id\n                ).order_by(desc(SensorReading.timestamp)).first()\n                \n                sensor_data.append({\n                    \"id\": sensor.id,\n                    \"sensor_id\": sensor.sensor_id,\n                    \"sensor_type\": sensor.sensor_type,\n                    \"coordinates\": sensor.coordinates,\n                    \"status\": sensor.status,\n                    \"communication_protocol\": sensor.communication_protocol,\n                    \"battery_level\": sensor.battery_level,\n                    \"signal_strength\": sensor.signal_strength,\n                    \"latest_value\": latest_reading.value if latest_reading else None,\n                    \"latest_timestamp\": latest_reading.timestamp.isoformat() if latest_reading else None,\n                    \"installation_date\": sensor.installation_date.isoformat() if sensor.installation_date is not None else None\n                })\n            \n            return sensor_data\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_sensor_readings(self, sensor_id: int, hours: int = 24) -> List[Dict[str, Any]]:\n        \"\"\"Get recent sensor readings for a specific sensor\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            cutoff_time = datetime.now() - timedelta(hours=hours)\n            \n            readings = session.query(SensorReading).filter(\n                SensorReading.sensor_id == sensor_id,\n                SensorReading.timestamp >= cutoff_time\n            ).order_by(asc(SensorReading.timestamp)).all()\n            \n            return [\n                {\n                    \"timestamp\": reading.timestamp.isoformat(),\n                    \"value\": reading.value,\n                    \"unit\": reading.unit,\n                    \"quality_score\": reading.quality_score,\n                    \"anomaly_detected\": reading.anomaly_detected\n                }\n                for reading in readings\n            ]\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_environmental_data(self, mine_site_id: int, hours: int = 24) -> List[Dict[str, Any]]:\n        \"\"\"Get recent environmental data for a mine site\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            cutoff_time = datetime.now() - timedelta(hours=hours)\n            \n            env_data = session.query(EnvironmentalData).filter(\n                EnvironmentalData.mine_site_id == mine_site_id,\n                EnvironmentalData.timestamp >= cutoff_time\n            ).order_by(asc(EnvironmentalData.timestamp)).all()\n            \n            return [\n                {\n                    \"timestamp\": data.timestamp.isoformat(),\n                    \"temperature\": data.temperature,\n                    \"humidity\": data.humidity,\n                    \"wind_speed\": data.wind_speed,\n                    \"wind_direction\": data.wind_direction,\n                    \"precipitation\": data.precipitation,\n                    \"atmospheric_pressure\": data.atmospheric_pressure,\n                    \"seismic_activity\": data.seismic_activity,\n                    \"source\": data.source\n                }\n                for data in env_data\n            ]\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def store_risk_assessment(self, mine_site_id: int, risk_level: str, \n                            risk_score: float, affected_zones: List[Dict],\n                            contributing_factors: Dict, model_version: str,\n                            confidence_score: float, timeframe: str,\n                            recommendations: str) -> int:\n        \"\"\"Store a new risk assessment\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            assessment = RiskAssessment(\n                mine_site_id=mine_site_id,\n                risk_level=risk_level,\n                risk_score=risk_score,\n                affected_zones=affected_zones,\n                contributing_factors=contributing_factors,\n                model_version=model_version,\n                confidence_score=confidence_score,\n                predicted_timeframe=timeframe,\n                recommendations=recommendations\n            )\n            \n            session.add(assessment)\n            session.commit()\n            session.refresh(assessment)\n            return getattr(assessment, 'id')\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error storing risk assessment: {e}\")\n            raise\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_recent_risk_assessments(self, mine_site_id: int, limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"Get recent risk assessments for a mine site\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            assessments = session.query(RiskAssessment).filter_by(\n                mine_site_id=mine_site_id\n            ).order_by(desc(RiskAssessment.timestamp)).limit(limit).all()\n            \n            return [\n                {\n                    \"id\": assessment.id,\n                    \"timestamp\": assessment.timestamp.isoformat(),\n                    \"risk_level\": assessment.risk_level,\n                    \"risk_score\": assessment.risk_score,\n                    \"affected_zones\": assessment.affected_zones,\n                    \"contributing_factors\": assessment.contributing_factors,\n                    \"confidence_score\": assessment.confidence_score,\n                    \"predicted_timeframe\": assessment.predicted_timeframe,\n                    \"recommendations\": assessment.recommendations\n                }\n                for assessment in assessments\n            ]\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def create_alert(self, mine_site_id: int, alert_type: str, severity: str,\n                    title: str, message: str, location: Optional[Dict] = None,\n                    triggered_by: Optional[str] = None) -> int:\n        \"\"\"Create a new alert\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            alert = Alert(\n                mine_site_id=mine_site_id,\n                alert_type=alert_type,\n                severity=severity,\n                title=title,\n                message=message,\n                location=location,\n                triggered_by=triggered_by\n            )\n            \n            session.add(alert)\n            session.commit()\n            session.refresh(alert)\n            return getattr(alert, 'id')\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error creating alert: {e}\")\n            raise\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_active_alerts(self, mine_site_id: Optional[int] = None) -> List[Dict[str, Any]]:\n        \"\"\"Get active (unresolved) alerts\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            query = session.query(Alert).filter_by(resolved=False)\n            \n            if mine_site_id:\n                query = query.filter_by(mine_site_id=mine_site_id)\n            \n            alerts = query.order_by(desc(Alert.timestamp)).all()\n            \n            return [\n                {\n                    \"id\": alert.id,\n                    \"mine_site_id\": alert.mine_site_id,\n                    \"alert_type\": alert.alert_type,\n                    \"severity\": alert.severity,\n                    \"title\": alert.title,\n                    \"message\": alert.message,\n                    \"location\": alert.location,\n                    \"timestamp\": alert.timestamp.isoformat(),\n                    \"acknowledged\": alert.acknowledged,\n                    \"acknowledged_by\": alert.acknowledged_by,\n                    \"sms_sent\": alert.sms_sent,\n                    \"email_sent\": alert.email_sent,\n                    \"siren_activated\": alert.siren_activated\n                }\n                for alert in alerts\n            ]\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def acknowledge_alert(self, alert_id: int, acknowledged_by: str) -> bool:\n        \"\"\"Acknowledge an alert\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            alert = session.query(Alert).get(alert_id)\n            if alert:\n                alert.acknowledged = True\n                alert.acknowledged_by = acknowledged_by\n                alert.acknowledged_at = datetime.now()\n                session.commit()\n                return True\n            return False\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error acknowledging alert: {e}\")\n            return False\n        finally:\n            self.db_manager.close_session(session)\n    \n    def resolve_alert(self, alert_id: int, resolved_by: str, actions_taken: str) -> bool:\n        \"\"\"Resolve an alert\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            alert = session.query(Alert).get(alert_id)\n            if alert:\n                alert.resolved = True\n                alert.resolved_by = resolved_by\n                alert.resolved_at = datetime.now()\n                alert.actions_taken = actions_taken\n                session.commit()\n                return True\n            return False\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error resolving alert: {e}\")\n            return False\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_system_statistics(self, mine_site_id: int) -> Dict[str, Any]:\n        \"\"\"Get system statistics for a mine site\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            # Sensor statistics\n            total_sensors = session.query(Sensor).filter_by(\n                mine_site_id=mine_site_id, status='active'\n            ).count()\n            \n            # Recent readings count (last 24 hours)\n            cutoff_time = datetime.now() - timedelta(hours=24)\n            recent_readings = session.query(SensorReading).join(Sensor).filter(\n                Sensor.mine_site_id == mine_site_id,\n                SensorReading.timestamp >= cutoff_time\n            ).count()\n            \n            # Active alerts\n            active_alerts = session.query(Alert).filter_by(\n                mine_site_id=mine_site_id, resolved=False\n            ).count()\n            \n            # Latest risk assessment\n            latest_risk = session.query(RiskAssessment).filter_by(\n                mine_site_id=mine_site_id\n            ).order_by(desc(RiskAssessment.timestamp)).first()\n            \n            # Communication statistics - simplified to avoid SQLAlchemy function issues\n            comm_logs = session.query(CommunicationLog).filter(\n                CommunicationLog.mine_site_id == mine_site_id,\n                CommunicationLog.timestamp >= cutoff_time\n            ).all()\n            \n            if comm_logs:\n                successful_comms = sum(1 for log in comm_logs if bool(log.success))\n                comm_success_rate = successful_comms / len(comm_logs)\n            else:\n                comm_success_rate = 0\n            \n            return {\n                \"total_sensors\": total_sensors,\n                \"recent_readings\": recent_readings,\n                \"active_alerts\": active_alerts,\n                \"latest_risk_level\": latest_risk.risk_level if latest_risk else \"unknown\",\n                \"latest_risk_score\": latest_risk.risk_score if latest_risk else 0,\n                \"communication_success_rate\": float(comm_success_rate),\n                \"system_uptime\": \"99.2%\",  # This would come from system monitoring\n                \"last_updated\": datetime.now().isoformat()\n            }\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_historical_trends(self, mine_site_id: int, days: int = 30) -> Dict[str, Any]:\n        \"\"\"Get historical trends for risk analysis\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            cutoff_time = datetime.now() - timedelta(days=days)\n            \n            # Risk score trends\n            risk_assessments = session.query(RiskAssessment).filter(\n                RiskAssessment.mine_site_id == mine_site_id,\n                RiskAssessment.timestamp >= cutoff_time\n            ).order_by(asc(RiskAssessment.timestamp)).all()\n            \n            # Alert frequency trends\n            alerts_by_day = session.query(\n                func.date(Alert.timestamp).label('date'),\n                func.count(Alert.id).label('count')\n            ).filter(\n                Alert.mine_site_id == mine_site_id,\n                Alert.timestamp >= cutoff_time\n            ).group_by(func.date(Alert.timestamp)).all()\n            \n            return {\n                \"risk_trends\": [\n                    {\n                        \"timestamp\": assessment.timestamp.isoformat(),\n                        \"risk_score\": assessment.risk_score,\n                        \"risk_level\": assessment.risk_level\n                    }\n                    for assessment in risk_assessments\n                ],\n                \"alert_frequency\": [\n                    {\n                        \"date\": alert_day.date.isoformat(),\n                        \"count\": alert_day.count\n                    }\n                    for alert_day in alerts_by_day\n                ]\n            }\n            \n        finally:\n            self.db_manager.close_session(session)\n\n# Global database manager instance - initialize lazily\nrockfall_db = None\n\ndef get_rockfall_db():\n    \"\"\"Get or create the global database manager instance\"\"\"\n    global rockfall_db\n    if rockfall_db is None:\n        rockfall_db = RockfallDatabaseManager()\n    return rockfall_db","size_bytes":18469},"database/schema.py":{"content":"\"\"\"\nDatabase schema definitions for the Rockfall Prediction System\n\"\"\"\n\nfrom sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Boolean, Text, JSON, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, relationship\nfrom datetime import datetime\nimport os\n\nBase = declarative_base()\n\nclass MineSite(Base):\n    __tablename__ = 'mine_sites'\n    \n    id = Column(Integer, primary_key=True)\n    name = Column(String(255), nullable=False)\n    location = Column(String(255))\n    coordinates = Column(JSON)  # Store lat/lon as JSON\n    site_boundaries = Column(JSON)  # Store boundary coordinates\n    active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=datetime.now)\n    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)\n    \n    # Relationships\n    sensors = relationship(\"Sensor\", back_populates=\"mine_site\")\n    environmental_data = relationship(\"EnvironmentalData\", back_populates=\"mine_site\")\n    risk_assessments = relationship(\"RiskAssessment\", back_populates=\"mine_site\")\n    alerts = relationship(\"Alert\", back_populates=\"mine_site\")\n\nclass Sensor(Base):\n    __tablename__ = 'sensors'\n    \n    id = Column(Integer, primary_key=True)\n    sensor_id = Column(String(50), unique=True, nullable=False)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    sensor_type = Column(String(50), nullable=False)  # displacement, strain, pressure, etc.\n    coordinates = Column(JSON)  # x, y, z coordinates\n    status = Column(String(20), default='active')  # active, inactive, maintenance\n    communication_protocol = Column(String(50))  # LoRaWAN, radio, wired\n    battery_level = Column(Float)\n    signal_strength = Column(Float)\n    installation_date = Column(DateTime)\n    last_maintenance = Column(DateTime)\n    created_at = Column(DateTime, default=datetime.now)\n    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)\n    \n    # Relationships\n    mine_site = relationship(\"MineSite\", back_populates=\"sensors\")\n    readings = relationship(\"SensorReading\", back_populates=\"sensor\")\n\nclass SensorReading(Base):\n    __tablename__ = 'sensor_readings'\n    \n    id = Column(Integer, primary_key=True)\n    sensor_id = Column(Integer, ForeignKey('sensors.id'), nullable=False)\n    timestamp = Column(DateTime, nullable=False)\n    value = Column(Float, nullable=False)\n    unit = Column(String(20))\n    quality_score = Column(Float)  # Data quality indicator\n    anomaly_detected = Column(Boolean, default=False)\n    created_at = Column(DateTime, default=datetime.now)\n    \n    # Relationships\n    sensor = relationship(\"Sensor\", back_populates=\"readings\")\n\nclass EnvironmentalData(Base):\n    __tablename__ = 'environmental_data'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    timestamp = Column(DateTime, nullable=False)\n    temperature = Column(Float)\n    humidity = Column(Float)\n    wind_speed = Column(Float)\n    wind_direction = Column(Float)\n    precipitation = Column(Float)\n    atmospheric_pressure = Column(Float)\n    seismic_activity = Column(Float)\n    source = Column(String(100))  # weather_station, satellite, manual\n    created_at = Column(DateTime, default=datetime.now)\n    \n    # Relationships\n    mine_site = relationship(\"MineSite\", back_populates=\"environmental_data\")\n\nclass RiskAssessment(Base):\n    __tablename__ = 'risk_assessments'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    timestamp = Column(DateTime, default=datetime.now)\n    risk_level = Column(String(20), nullable=False)  # low, medium, high, critical\n    risk_score = Column(Float, nullable=False)\n    affected_zones = Column(JSON)  # List of affected zone identifiers\n    contributing_factors = Column(JSON)  # Key factors contributing to risk\n    model_version = Column(String(50))\n    confidence_score = Column(Float)\n    predicted_timeframe = Column(String(100))  # Time window for prediction\n    recommendations = Column(Text)\n    created_at = Column(DateTime, default=datetime.now)\n    \n    # Relationships\n    mine_site = relationship(\"MineSite\", back_populates=\"risk_assessments\")\n\nclass Alert(Base):\n    __tablename__ = 'alerts'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    alert_type = Column(String(50), nullable=False)  # risk_threshold, sensor_failure, etc.\n    severity = Column(String(20), nullable=False)  # low, medium, high, critical\n    title = Column(String(255), nullable=False)\n    message = Column(Text, nullable=False)\n    location = Column(JSON)  # Specific location within mine site\n    timestamp = Column(DateTime, default=datetime.now)\n    acknowledged = Column(Boolean, default=False)\n    acknowledged_by = Column(String(100))\n    acknowledged_at = Column(DateTime)\n    resolved = Column(Boolean, default=False)\n    resolved_by = Column(String(100))\n    resolved_at = Column(DateTime)\n    actions_taken = Column(Text)\n    triggered_by = Column(String(100))  # sensor_id or system component\n    sms_sent = Column(Boolean, default=False)\n    email_sent = Column(Boolean, default=False)\n    siren_activated = Column(Boolean, default=False)\n    created_at = Column(DateTime, default=datetime.now)\n    \n    # Relationships\n    mine_site = relationship(\"MineSite\", back_populates=\"alerts\")\n\nclass DroneImagery(Base):\n    __tablename__ = 'drone_imagery'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    flight_id = Column(String(50), nullable=False)\n    timestamp = Column(DateTime, nullable=False)\n    coverage_area = Column(JSON)  # Areas covered by this flight\n    image_analysis = Column(JSON)  # Results of automated image analysis\n    risk_indicators = Column(JSON)  # Risk factors detected in imagery\n    storage_path = Column(String(500))  # Path to stored images\n    analysis_status = Column(String(20), default='pending')  # pending, completed, failed\n    created_at = Column(DateTime, default=datetime.now)\n    \n    # Relationships\n    mine_site = relationship(\"MineSite\")\n\nclass SystemLog(Base):\n    __tablename__ = 'system_logs'\n    \n    id = Column(Integer, primary_key=True)\n    timestamp = Column(DateTime, default=datetime.now)\n    level = Column(String(20), nullable=False)  # DEBUG, INFO, WARNING, ERROR, CRITICAL\n    component = Column(String(100), nullable=False)  # Which system component\n    message = Column(Text, nullable=False)\n    details = Column(JSON)  # Additional structured details\n    user_id = Column(String(100))\n    session_id = Column(String(100))\n\nclass CommunicationLog(Base):\n    __tablename__ = 'communication_logs'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'))\n    timestamp = Column(DateTime, default=datetime.now)\n    communication_type = Column(String(50), nullable=False)  # SMS, email, LoRaWAN, radio\n    recipient = Column(String(255))\n    message_content = Column(Text)\n    success = Column(Boolean, nullable=False)\n    error_message = Column(Text)\n    response_time = Column(Float)  # Response time in seconds\n    gateway_used = Column(String(100))  # For LoRaWAN/radio communications\n\nclass DroneFlightLog(Base):\n    __tablename__ = 'drone_flight_logs'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'))\n    drone_id = Column(String(50), nullable=False)\n    mission_type = Column(String(50), nullable=False)  # patrol, emergency, inspection\n    start_time = Column(DateTime, nullable=False)\n    end_time = Column(DateTime)\n    flight_status = Column(String(20), nullable=False)  # grounded, flying, hovering, returning, completed\n    battery_start = Column(Float)\n    battery_end = Column(Float)\n    weather_conditions = Column(String(100))\n    flight_path = Column(JSON)  # Store flight path coordinates\n    images_captured = Column(Integer, default=0)\n    risk_alerts_generated = Column(Integer, default=0)\n    total_flight_time = Column(Integer)  # Flight time in minutes\n\nclass DroneImageAnalysis(Base):\n    __tablename__ = 'drone_image_analysis'\n    \n    id = Column(Integer, primary_key=True)\n    flight_log_id = Column(Integer, ForeignKey('drone_flight_logs.id'))\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'))\n    timestamp = Column(DateTime, nullable=False)\n    image_path = Column(String(500), nullable=False)\n    capture_location = Column(JSON, nullable=False)  # lat, lon, altitude\n    risk_score = Column(Float, nullable=False)\n    risk_level = Column(String(20), nullable=False)  # low, medium, high, critical\n    confidence = Column(Float)\n    analysis_time_ms = Column(Integer)\n    features_detected = Column(JSON)  # Array of detected geological features\n    risk_indicators = Column(JSON)  # Detailed risk analysis data\n    camera_settings = Column(JSON)  # Camera configuration used\n    weather_conditions = Column(String(100))\n    lighting_conditions = Column(String(50))\n    image_quality = Column(String(20))\n    processed = Column(Boolean, default=True)\n\nclass DroneAlert(Base):\n    __tablename__ = 'drone_alerts'\n    \n    id = Column(Integer, primary_key=True)\n    image_analysis_id = Column(Integer, ForeignKey('drone_image_analysis.id'))\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'))\n    drone_id = Column(String(50), nullable=False)\n    timestamp = Column(DateTime, nullable=False)\n    alert_type = Column(String(50), nullable=False)  # rockfall_risk, sensor_failure_backup, emergency\n    risk_level = Column(String(20), nullable=False)\n    location = Column(JSON, nullable=False)\n    description = Column(Text)\n    recommended_actions = Column(JSON)  # Array of recommended actions\n    auto_generated = Column(Boolean, default=True)\n    sensor_backup_mode = Column(Boolean, default=False)  # True if triggered by sensor failure\n    resolved = Column(Boolean, default=False)\n    resolved_by = Column(String(100))\n    resolved_at = Column(DateTime)\n    notification_sent = Column(Boolean, default=False)\n\nclass DatabaseManager:\n    \"\"\"Database manager for handling connections and operations\"\"\"\n    \n    def __init__(self, database_url=None):\n        if database_url is None:\n            # Check for DATABASE_URL environment variable first (preferred for Replit/production)\n            database_url = os.getenv('DATABASE_URL')\n            \n            if database_url is None:\n                # Fallback to individual PostgreSQL environment variables\n                db_host = os.getenv('PGHOST')\n                db_port = os.getenv('PGPORT')\n                db_name = os.getenv('PGDATABASE')\n                db_user = os.getenv('PGUSER')\n                db_password = os.getenv('PGPASSWORD')\n                \n                if all([db_host, db_port, db_name, db_user, db_password]):\n                    database_url = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'\n                else:\n                    # Final fallback to SQLite for local development\n                    db_path = os.getenv('DB_PATH', './data/rockfall_prediction.db')\n                    # Ensure directory exists\n                    os.makedirs(os.path.dirname(db_path) if os.path.dirname(db_path) else '.', exist_ok=True)\n                    database_url = f'sqlite:///{db_path}'\n        \n        try:\n            self.engine = create_engine(database_url, echo=False)\n            self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)\n            print(f\"Database connected: {database_url.split('://')[0].upper()}\")\n        except Exception as e:\n            # Final fallback to simple SQLite\n            print(f\"Database connection failed, using fallback SQLite: {e}\")\n            fallback_path = './rockfall_prediction.db'\n            self.engine = create_engine(f'sqlite:///{fallback_path}', echo=False)\n            self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)\n    \n    def create_tables(self):\n        \"\"\"Create all database tables\"\"\"\n        Base.metadata.create_all(bind=self.engine)\n    \n    def get_session(self):\n        \"\"\"Get a database session\"\"\"\n        return self.SessionLocal()\n    \n    def close_session(self, session):\n        \"\"\"Close a database session\"\"\"\n        session.close()\n    \n    def drop_tables(self):\n        \"\"\"Drop all database tables - USE WITH CAUTION\"\"\"\n        Base.metadata.drop_all(bind=self.engine)","size_bytes":12671},"hardware/__init__.py":{"content":"","size_bytes":0},"iot/__init__.py":{"content":"","size_bytes":0},"mobile/__init__.py":{"content":"","size_bytes":0},"models/__init__.py":{"content":"","size_bytes":0},"models/rockfall_predictor.py":{"content":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom datetime import datetime, timedelta\nimport json\nimport os\ntry:\n    from openai import OpenAI\n    OPENAI_AVAILABLE = True\nexcept ImportError:\n    OPENAI_AVAILABLE = False\n    OpenAI = None\n\nclass RockfallPredictor:\n    def __init__(self):\n        self.model = None\n        self.feature_names = [\n            'displacement_rate', 'strain_magnitude', 'pore_pressure',\n            'temperature', 'rainfall', 'wind_speed', 'vibration_level',\n            'slope_angle', 'soil_moisture', 'crack_density'\n        ]\n        self.model_metrics = {'accuracy': 0.85, 'precision': 0.82, 'recall': 0.88}\n        self.feature_importance = {}\n        self.initialize_model()\n        \n        # Initialize OpenAI for advanced analysis\n        self.openai_client = None\n        if OPENAI_AVAILABLE and os.getenv(\"OPENAI_API_KEY\"):\n            self.openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n    \n    def initialize_model(self):\n        \"\"\"Initialize the ensemble machine learning model\"\"\"\n        # Create ensemble model\n        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n        nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000)\n        svm_model = SVC(probability=True, random_state=42)\n        \n        self.model = VotingClassifier(\n            estimators=[('rf', rf_model), ('nn', nn_model), ('svm', svm_model)],\n            voting='soft'\n        )\n        \n        # Train with synthetic data\n        self._train_initial_model()\n    \n    def _train_initial_model(self):\n        \"\"\"Train the model with synthetic data\"\"\"\n        # Generate synthetic training data\n        n_samples = 1000\n        X = np.random.randn(n_samples, len(self.feature_names))\n        \n        # Create realistic relationships for rockfall risk\n        risk_score = (\n            X[:, 0] * 0.3 +  # displacement_rate\n            X[:, 1] * 0.25 + # strain_magnitude\n            X[:, 2] * 0.2 +  # pore_pressure\n            X[:, 4] * 0.15 + # rainfall\n            X[:, 6] * 0.1    # vibration_level\n        )\n        \n        # Add some noise and non-linear relationships\n        risk_score += np.random.normal(0, 0.1, n_samples)\n        risk_score += 0.1 * X[:, 0] * X[:, 4]  # displacement-rainfall interaction\n        \n        # Convert to binary classification (1 = high risk, 0 = low risk)\n        y = (risk_score > np.percentile(risk_score, 70)).astype(int)\n        \n        # Train model\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        if self.model is not None:\n            self.model.fit(X_train, y_train)\n            \n            # Calculate metrics\n            y_pred = self.model.predict(X_test)\n        else:\n            y_pred = np.random.choice([0, 1], size=len(y_test))\n        self.model_metrics = {\n            'accuracy': accuracy_score(y_test, y_pred),\n            'precision': precision_score(y_test, y_pred, average='weighted'),\n            'recall': recall_score(y_test, y_pred, average='weighted')\n        }\n        \n        # Calculate feature importance (using Random Forest component)\n        if hasattr(self.model, 'named_estimators_'):\n            rf_model = self.model.named_estimators_['rf']\n            importance_values = rf_model.feature_importances_\n            self.feature_importance = dict(zip(self.feature_names, importance_values))\n        else:\n            # Fallback feature importance\n            self.feature_importance = {name: np.random.uniform(0.05, 0.25) for name in self.feature_names}\n    \n    def predict_risk(self, sensor_data):\n        \"\"\"Predict rockfall risk for given sensor data\"\"\"\n        if isinstance(sensor_data, dict):\n            # Convert dict to array\n            features = np.array([sensor_data.get(name, 0) for name in self.feature_names]).reshape(1, -1)\n        else:\n            features = np.array(sensor_data).reshape(1, -1)\n        \n        # Get prediction probability\n        if self.model is not None:\n            proba = self.model.predict_proba(features)[0]\n            risk_probability = proba[1]\n            confidence = float(np.max(proba))\n        else:\n            # Fallback prediction\n            risk_probability = np.random.uniform(0.1, 0.8)\n            confidence = 0.75\n        \n        return {\n            'risk_probability': risk_probability,\n            'risk_level': self._categorize_risk(risk_probability),\n            'confidence': confidence\n        }\n    \n    def _categorize_risk(self, probability):\n        \"\"\"Categorize risk level based on probability\"\"\"\n        if probability >= 0.85:\n            return 'critical'\n        elif probability >= 0.7:\n            return 'high'\n        elif probability >= 0.3:\n            return 'medium'\n        else:\n            return 'low'\n    \n    def generate_predictions(self):\n        \"\"\"Generate prediction data for dashboard\"\"\"\n        # Generate predictions for next 24 hours\n        time_points = []\n        predictions = []\n        current_time = datetime.now()\n        \n        for i in range(24):\n            time_point = current_time + timedelta(hours=i)\n            time_points.append(time_point)\n            \n            # Simulate varying conditions over time\n            base_risk = 0.3 + 0.2 * np.sin(i * np.pi / 12)  # Daily cycle\n            noise = np.random.normal(0, 0.1)\n            risk = max(0, min(1, base_risk + noise))\n            \n            predictions.append({\n                'timestamp': time_point,\n                'risk_probability': risk,\n                'risk_level': self._categorize_risk(risk)\n            })\n        \n        return predictions\n    \n    def create_prediction_timeline(self, prediction_data):\n        \"\"\"Create timeline visualization of predictions\"\"\"\n        timestamps = [p['timestamp'] for p in prediction_data]\n        risks = [p['risk_probability'] for p in prediction_data]\n        levels = [p['risk_level'] for p in prediction_data]\n        \n        # Color mapping for risk levels\n        color_map = {'low': 'green', 'medium': 'yellow', 'high': 'orange', 'critical': 'red'}\n        colors = [color_map[level] for level in levels]\n        \n        fig = go.Figure()\n        \n        # Add risk probability line\n        fig.add_trace(go.Scatter(\n            x=timestamps,\n            y=risks,\n            mode='lines+markers',\n            name='Risk Probability',\n            line=dict(color='#64748b', width=2),\n            marker=dict(color=colors, size=8)\n        ))\n        \n        # Add risk level zones\n        fig.add_hline(y=0.85, line_dash=\"dash\", line_color=\"red\", \n                     annotation_text=\"Critical Threshold\")\n        fig.add_hline(y=0.7, line_dash=\"dash\", line_color=\"orange\", \n                     annotation_text=\"High Risk Threshold\")\n        fig.add_hline(y=0.3, line_dash=\"dash\", line_color=\"yellow\", \n                     annotation_text=\"Medium Risk Threshold\")\n        \n        fig.update_layout(\n            title=\"24-Hour Risk Prediction Timeline\",\n            xaxis_title=\"Time\",\n            yaxis_title=\"Risk Probability\",\n            yaxis=dict(range=[0, 1]),\n            hovermode='x unified'\n        )\n        \n        return fig\n    \n    def get_model_metrics(self):\n        \"\"\"Return current model performance metrics\"\"\"\n        return self.model_metrics\n    \n    def get_feature_importance(self):\n        \"\"\"Return feature importance dictionary\"\"\"\n        return self.feature_importance\n    \n    def get_current_risk_factors(self):\n        \"\"\"Get current risk factors affecting predictions\"\"\"\n        # Simulate current environmental conditions\n        return {\n            'displacement_rate': np.random.uniform(0.1, 0.8),\n            'strain_magnitude': np.random.uniform(0.05, 0.6),\n            'pore_pressure': np.random.uniform(0.2, 0.7),\n            'temperature_factor': np.random.uniform(0.1, 0.5),\n            'rainfall_impact': np.random.uniform(0.0, 0.9),\n            'vibration_level': np.random.uniform(0.0, 0.4)\n        }\n    \n    def retrain_model(self, model_type=\"ensemble\"):\n        \"\"\"Retrain the model with updated data\"\"\"\n        if model_type == \"Random Forest\":\n            self.model = RandomForestClassifier(n_estimators=150, random_state=42)\n        elif model_type == \"Neural Network\":\n            self.model = MLPClassifier(hidden_layer_sizes=(150, 75), random_state=42, max_iter=1000)\n        elif model_type == \"SVM\":\n            self.model = SVC(probability=True, random_state=42)\n        else:  # Ensemble\n            rf_model = RandomForestClassifier(n_estimators=150, random_state=42)\n            nn_model = MLPClassifier(hidden_layer_sizes=(150, 75), random_state=42, max_iter=1000)\n            svm_model = SVC(probability=True, random_state=42)\n            \n            self.model = VotingClassifier(\n                estimators=[('rf', rf_model), ('nn', nn_model), ('svm', svm_model)],\n                voting='soft'\n            )\n        \n        # Retrain with new synthetic data\n        self._train_initial_model()\n    \n    def analyze_with_ai(self, sensor_data, environmental_data):\n        \"\"\"Use OpenAI to provide advanced analysis of risk factors\"\"\"\n        if not OPENAI_AVAILABLE:\n            return {\"analysis\": \"AI analysis not available - OpenAI package not installed\"}\n        if not self.openai_client:\n            return {\"analysis\": \"AI analysis not available - API key not configured\"}\n        \n        try:\n            # Use OpenAI model for analysis\n            prompt = f\"\"\"\n            Analyze the following mine sensor and environmental data for rockfall risk assessment:\n            \n            Sensor Data: {json.dumps(sensor_data, indent=2)}\n            Environmental Data: {json.dumps(environmental_data, indent=2)}\n            \n            Provide a comprehensive risk analysis including:\n            1. Key risk factors identified\n            2. Potential failure mechanisms\n            3. Recommended monitoring focus areas\n            4. Suggested preventive measures\n            \n            Respond in JSON format with the analysis.\n            \"\"\"\n            \n            response = self.openai_client.chat.completions.create(\n                model=\"gpt-4\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                response_format={\"type\": \"json_object\"}\n            )\n            \n            content = response.choices[0].message.content\n            if content:\n                return json.loads(content)\n            else:\n                return {\"error\": \"Empty response from AI analysis\"}\n            \n        except Exception as e:\n            return {\"error\": f\"AI analysis failed: {str(e)}\"}","size_bytes":11015},"utils/__init__.py":{"content":"","size_bytes":0},"utils/config_manager.py":{"content":"\"\"\"\nConfiguration management for the Rockfall Prediction System\n\"\"\"\n\nimport os\nimport json\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\n\nclass ConfigManager:\n    \"\"\"Manages system configuration and settings\"\"\"\n    \n    def __init__(self):\n        self.config_file = 'config.json'\n        self.default_config = {\n            'mine_name': 'Open Pit Mine Alpha',\n            'coordinates': '45.123, -123.456',\n            'sensor_count': 47,\n            'model_update_interval': 60,  # minutes\n            'data_retention_days': 90,\n            'alert_cooldown': 15,  # minutes\n            'max_alerts_per_hour': 5,\n            'sensor_freq_index': 1,\n            'use_dem': True,\n            'use_drone': True,\n            'use_weather': True,\n            'risk_thresholds': {\n                'low': 0.3,\n                'medium': 0.7,\n                'high': 0.85\n            },\n            'communication': {\n                'sms_enabled': True,\n                'email_enabled': True,\n                'audio_enabled': True,\n                'visual_enabled': True\n            },\n            'created_at': datetime.now().isoformat(),\n            'updated_at': datetime.now().isoformat()\n        }\n        self.config = self.load_config()\n    \n    def load_config(self) -> Dict[str, Any]:\n        \"\"\"Load configuration from file or create default\"\"\"\n        try:\n            if os.path.exists(self.config_file):\n                with open(self.config_file, 'r') as f:\n                    config = json.load(f)\n                # Merge with defaults for any missing keys\n                for key, value in self.default_config.items():\n                    if key not in config:\n                        config[key] = value\n                return config\n            else:\n                return self.default_config.copy()\n        except Exception as e:\n            print(f\"Error loading config: {e}\")\n            return self.default_config.copy()\n    \n    def save_config(self) -> bool:\n        \"\"\"Save current configuration to file\"\"\"\n        try:\n            self.config['updated_at'] = datetime.now().isoformat()\n            with open(self.config_file, 'w') as f:\n                json.dump(self.config, f, indent=2)\n            return True\n        except Exception as e:\n            print(f\"Error saving config: {e}\")\n            return False\n    \n    def get_current_config(self) -> Dict[str, Any]:\n        \"\"\"Get current configuration\"\"\"\n        return self.config.copy()\n    \n    def update_config(self, updates: Dict[str, Any]) -> bool:\n        \"\"\"Update configuration with new values\"\"\"\n        try:\n            self.config.update(updates)\n            return self.save_config()\n        except Exception as e:\n            print(f\"Error updating config: {e}\")\n            return False\n    \n    def get_api_status(self) -> Dict[str, bool]:\n        \"\"\"Check status of API keys\"\"\"\n        return {\n            'openai': os.getenv(\"OPENAI_API_KEY\") is not None,\n            'twilio': os.getenv(\"TWILIO_ACCOUNT_SID\") is not None,\n            'sendgrid': os.getenv(\"SENDGRID_API_KEY\") is not None\n        }\n    \n    def get_mine_parameters(self) -> Dict[str, Any]:\n        \"\"\"Get mine-specific parameters\"\"\"\n        return {\n            'name': self.config.get('mine_name', 'Unknown Mine'),\n            'coordinates': self.config.get('coordinates', '0, 0'),\n            'sensor_count': self.config.get('sensor_count', 47),\n            'boundaries': self.config.get('mine_boundaries', [])\n        }\n    \n    def get_alert_settings(self) -> Dict[str, Any]:\n        \"\"\"Get alert configuration\"\"\"\n        return {\n            'thresholds': self.config.get('risk_thresholds', self.default_config['risk_thresholds']),\n            'cooldown': self.config.get('alert_cooldown', 15),\n            'max_per_hour': self.config.get('max_alerts_per_hour', 5),\n            'communication': self.config.get('communication', self.default_config['communication'])\n        }\n    \n    def reset_to_defaults(self) -> bool:\n        \"\"\"Reset configuration to defaults\"\"\"\n        self.config = self.default_config.copy()\n        return self.save_config()","size_bytes":4144},"visualization/__init__.py":{"content":"","size_bytes":0},"visualization/mine_3d_viz.py":{"content":"import plotly.graph_objects as go\nimport plotly.express as px\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport time\n\nclass Mine3DVisualizer:\n    def __init__(self):\n        self.color_schemes = {\n            'Risk-based': {\n                'low': '#00FF00',      # Green\n                'medium': '#FFFF00',   # Yellow\n                'high': '#FF8000',     # Orange\n                'critical': '#FF0000'  # Red\n            },\n            'Elevation': px.colors.sequential.Viridis,\n            'Geological': {\n                'limestone': '#E6E6FA',\n                'sandstone': '#F4A460',\n                'shale': '#708090',\n                'granite': '#696969'\n            }\n        }\n        self.blink_state = 0  # For blinking animation\n    \n    def create_3d_mine_view(self, mine_data):\n        \"\"\"Create comprehensive 3D visualization of the mine\"\"\"\n        fig = go.Figure()\n        \n        # Add terrain surface\n        dem_data = mine_data['dem']\n        x_terrain = np.array(dem_data['x'])\n        y_terrain = np.array(dem_data['y'])\n        z_terrain = np.array(dem_data['z'])\n        \n        # Create surface plot for terrain\n        fig.add_trace(go.Surface(\n            x=x_terrain,\n            y=y_terrain,\n            z=z_terrain,\n            colorscale='Earth',\n            opacity=0.7,\n            name='Terrain',\n            showscale=False,\n            hovertemplate='X: %{x}<br>Y: %{y}<br>Elevation: %{z}m<extra></extra>'\n        ))\n        \n        # Add risk zones as colored overlays\n        zones = mine_data['zones']\n        for zone in zones:\n            self._add_risk_zone(fig, zone)\n        \n        # Add sensor network\n        sensors = mine_data['sensor_network']\n        self._add_sensor_network(fig, sensors)\n        \n        # Add mine infrastructure\n        self._add_mine_infrastructure(fig, mine_data)\n        \n        # Configure enhanced layout for clarity\n        fig.update_layout(\n            title={\n                'text': \"<b>3D Mine Risk Assessment</b><br><span style='font-size:14px'>‚ö†Ô∏è High risk zones blink | üî¥ Critical | üü† High | üü° Medium | üü¢ Low</span>\",\n                'x': 0.5,\n                'xanchor': 'center',\n                'font': {'size': 18}\n            },\n            scene=dict(\n                xaxis_title=\"X Coordinate (m)\",\n                yaxis_title=\"Y Coordinate (m)\",\n                zaxis_title=\"Elevation (m)\",\n                camera=dict(\n                    eye=dict(x=1.8, y=1.8, z=1.5)  # Better viewing angle\n                ),\n                aspectmode='cube',  # Better proportions\n                bgcolor='rgba(240,240,240,0.1)',  # Light background\n                xaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=1),\n                yaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=1),\n                zaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=1)\n            ),\n            width=1100,\n            height=800,\n            margin=dict(l=50, r=200, t=100, b=50),\n            legend=dict(\n                x=1.02,\n                y=1,\n                bgcolor='rgba(255,255,255,0.9)',\n                bordercolor='gray',\n                borderwidth=1,\n                font=dict(size=12)\n            ),\n            showlegend=True\n        )\n        \n        return fig\n    \n    def _add_risk_zone(self, fig, zone):\n        \"\"\"Add prominent risk zone visualization with blinking for high-risk areas\"\"\"\n        center = zone['center_coordinates']\n        risk_level = zone['risk_level']\n        \n        # Enhanced color and visibility based on risk level\n        if risk_level >= 0.7:  # Critical/High risk - RED with blinking\n            color = '#FF0000'  # Bright red\n            fill_color = 'rgba(255, 0, 0, 0.4)'\n            border_width = 12\n            marker_size = 20\n            blink_effect = True\n        elif risk_level >= 0.5:  # Medium-High risk - ORANGE\n            color = '#FF6600'\n            fill_color = 'rgba(255, 102, 0, 0.3)'\n            border_width = 8\n            marker_size = 16\n            blink_effect = False\n        elif risk_level >= 0.3:  # Medium risk - YELLOW\n            color = '#FFAA00'\n            fill_color = 'rgba(255, 170, 0, 0.25)'\n            border_width = 6\n            marker_size = 12\n            blink_effect = False\n        else:  # Low risk - GREEN\n            color = '#00AA00'\n            fill_color = 'rgba(0, 170, 0, 0.2)'\n            border_width = 4\n            marker_size = 10\n            blink_effect = False\n        \n        # Create larger, more visible risk zone\n        radius = 100  # Larger radius for better visibility\n        theta = np.linspace(0, 2*np.pi, 30)  # More points for smoother circle\n        \n        # Zone boundary at terrain level\n        zone_x = center['x'] + radius * np.cos(theta)\n        zone_y = center['y'] + radius * np.sin(theta)\n        zone_z = np.full_like(zone_x, center['z'] + 2)  # Just above terrain\n        \n        # Create filled surface for risk zone\n        # Create a mesh grid for the filled area\n        r_fill = np.linspace(0, radius, 10)\n        theta_fill = np.linspace(0, 2*np.pi, 30)\n        R, THETA = np.meshgrid(r_fill, theta_fill)\n        X_fill = center['x'] + R * np.cos(THETA)\n        Y_fill = center['y'] + R * np.sin(THETA)\n        Z_fill = np.full_like(X_fill, center['z'] + 1)\n        \n        # Add filled surface for the risk zone\n        fig.add_trace(go.Surface(\n            x=X_fill,\n            y=Y_fill,\n            z=Z_fill,\n            colorscale=[[0, fill_color], [1, fill_color]],\n            showscale=False,\n            opacity=0.6 if blink_effect else 0.4,\n            name=f\"üî¥ Critical Risk Zones\" if risk_level >= 0.7 else f\"üü† High Risk Zones\" if risk_level >= 0.5 else f\"üü° Medium Risk Zones\" if risk_level >= 0.3 else f\"üü¢ Low Risk Zones\",\n            legendgroup=f\"risk_zones\",\n            showlegend=risk_level >= 0.7,  # Only show high-risk zones in legend\n            hovertemplate=f\"<b>{zone['name']}</b><br>Risk Level: {risk_level:.1%}<br>Status: {'‚ö†Ô∏è HIGH RISK' if risk_level >= 0.7 else '‚ö° MEDIUM RISK' if risk_level >= 0.3 else '‚úÖ LOW RISK'}<extra></extra>\"\n        ))\n        \n        # Add prominent zone boundary\n        fig.add_trace(go.Scatter3d(\n            x=zone_x,\n            y=zone_y,\n            z=zone_z,\n            mode='lines',\n            line=dict(\n                color=color,\n                width=border_width\n            ),\n            name=f\"{zone['name']} Boundary\",\n            showlegend=False,\n            hovertemplate=f\"Zone: {zone['name']}<br>Risk: {risk_level:.1%}<extra></extra>\"\n        ))\n        \n        # Add large, prominent center marker\n        marker_symbol = 'diamond' if risk_level >= 0.7 else 'circle'\n        fig.add_trace(go.Scatter3d(\n            x=[center['x']],\n            y=[center['y']],\n            z=[center['z'] + 15],\n            mode='markers+text',\n            marker=dict(\n                size=marker_size,\n                color=color,\n                symbol=marker_symbol,\n                line=dict(width=3, color='white'),\n                opacity=1.0\n            ),\n            text=[f\"‚ö†Ô∏è {zone['name']}\" if risk_level >= 0.7 else zone['name']],\n            textposition='top center',\n            textfont=dict(size=14, color=color),\n            name=f\"{zone['name']} Center\",\n            showlegend=False,\n            hovertemplate=f\"<b>Zone: {zone['name']}</b><br>Risk Level: {risk_level:.1%}<br>Coordinates: ({center['x']:.0f}, {center['y']:.0f})<br>Type: {zone.get('geological_type', 'Unknown')}<extra></extra>\"\n        ))\n        \n        # Add blinking effect for high-risk zones by adding a secondary marker\n        if blink_effect:\n            # Calculate blinking opacity based on current time\n            current_time = time.time()\n            blink_cycle = (current_time * 2) % 2  # 2-second cycle\n            blink_opacity = 0.3 + 0.7 * abs(np.sin(blink_cycle * np.pi))  # Smooth blinking\n            \n            fig.add_trace(go.Scatter3d(\n                x=[center['x']],\n                y=[center['y']],\n                z=[center['z'] + 20],\n                mode='markers',\n                marker=dict(\n                    size=25,\n                    color='red',\n                    symbol='circle',\n                    line=dict(width=4, color='yellow'),\n                    opacity=blink_opacity\n                ),\n                name=f\"üö® {zone['name']} ALERT\",\n                showlegend=True,\n                hovertemplate=f\"<b>üö® HIGH RISK ALERT</b><br>Zone: {zone['name']}<br>Risk: {risk_level:.1%}<br>Immediate attention required!<extra></extra>\"\n            ))\n            \n            # Add pulsing border effect\n            fig.add_trace(go.Scatter3d(\n                x=zone_x,\n                y=zone_y,\n                z=zone_z + 3,\n                mode='lines',\n                line=dict(\n                    color='red',\n                    width=border_width + 4,\n                    dash='dash'\n                ),\n                opacity=0.7 + 0.3 * abs(np.sin(blink_cycle * np.pi * 1.5)),  # Faster pulse\n                name=f\"‚ö†Ô∏è {zone['name']} Warning Border\",\n                showlegend=False,\n                hovertemplate=f\"High-Risk Zone Border: {zone['name']}<extra></extra>\"\n            ))\n    \n    def _add_sensor_network(self, fig, sensors):\n        \"\"\"Add simplified, cleaner sensor network visualization\"\"\"\n        # Simplify sensor visualization - show only active sensors and group by status\n        active_sensors = [s for s in sensors if s.get('status') == 'online']\n        warning_sensors = [s for s in sensors if s.get('risk_probability', 0) > 0.7]\n        \n        # Show only active sensors with clean markers\n        if active_sensors:\n            x_coords = [s['coordinates']['x'] for s in active_sensors]\n            y_coords = [s['coordinates']['y'] for s in active_sensors]\n            z_coords = [s['coordinates']['z'] for s in active_sensors]\n            sensor_ids = [s['id'] for s in active_sensors]\n            risk_levels = [s.get('risk_probability', 0) for s in active_sensors]\n            \n            # Color sensors by risk level instead of type for clarity\n            colors = ['red' if risk >= 0.7 else 'orange' if risk >= 0.5 else 'green' for risk in risk_levels]\n            \n            fig.add_trace(go.Scatter3d(\n                x=x_coords,\n                y=y_coords,\n                z=z_coords,\n                mode='markers',\n                marker=dict(\n                    size=6,\n                    color=colors,\n                    symbol='circle',\n                    opacity=0.7,\n                    line=dict(width=1, color='white')\n                ),\n                name=\"Active Sensors\",\n                text=sensor_ids,\n                hovertemplate=\"<b>Sensor: %{text}</b><br>Risk Level: %{customdata:.1%}<br>Status: Online<extra></extra>\",\n                customdata=risk_levels\n            ))\n        \n        # Highlight high-risk sensors with larger markers\n        if warning_sensors:\n            x_warning = [s['coordinates']['x'] for s in warning_sensors]\n            y_warning = [s['coordinates']['y'] for s in warning_sensors]\n            z_warning = [s['coordinates']['z'] + 5 for s in warning_sensors]  # Slightly elevated\n            warning_ids = [s['id'] for s in warning_sensors]\n            warning_risks = [s.get('risk_probability', 0) for s in warning_sensors]\n            \n            fig.add_trace(go.Scatter3d(\n                x=x_warning,\n                y=y_warning,\n                z=z_warning,\n                mode='markers',\n                marker=dict(\n                    size=12,\n                    color='red',\n                    symbol='diamond',\n                    opacity=0.9,\n                    line=dict(width=2, color='yellow')\n                ),\n                name=\"‚ö†Ô∏è High-Risk Sensors\",\n                text=[f\"‚ö†Ô∏è {id}\" for id in warning_ids],\n                hovertemplate=\"<b>‚ö†Ô∏è HIGH RISK SENSOR</b><br>ID: %{text}<br>Risk Level: %{customdata:.1%}<br>Requires immediate attention!<extra></extra>\",\n                customdata=warning_risks\n            ))\n    \n    def _add_mine_infrastructure(self, fig, mine_data):\n        \"\"\"Add mine infrastructure elements\"\"\"\n        # Add access roads (simplified)\n        road_points = [\n            {'start': (100, 100, 1250), 'end': (500, 400, 1200)},\n            {'start': (500, 400, 1200), 'end': (800, 600, 1230)},\n            {'start': (300, 200, 1240), 'end': (600, 500, 1210)},\n        ]\n        \n        for i, road in enumerate(road_points):\n            start, end = road['start'], road['end']\n            fig.add_trace(go.Scatter3d(\n                x=[start[0], end[0]],\n                y=[start[1], end[1]],\n                z=[start[2], end[2]],\n                mode='lines',\n                line=dict(color='black', width=6),\n                name=f\"Access Road {i+1}\" if i == 0 else \"\",\n                showlegend=i == 0,\n                hovertemplate=\"Access Road<extra></extra>\"\n            ))\n        \n        # Add equipment zones\n        equipment_zones = [\n            {'name': 'Crusher', 'pos': (200, 150, 1280), 'color': 'brown'},\n            {'name': 'Processing Plant', 'pos': (750, 650, 1290), 'color': 'gray'},\n            {'name': 'Maintenance', 'pos': (600, 200, 1270), 'color': 'orange'},\n        ]\n        \n        for equipment in equipment_zones:\n            pos = equipment['pos']\n            fig.add_trace(go.Scatter3d(\n                x=[pos[0]],\n                y=[pos[1]],\n                z=[pos[2]],\n                mode='markers+text',\n                marker=dict(\n                    size=15,\n                    color=equipment['color'],\n                    symbol='square',\n                    opacity=0.8\n                ),\n                text=[equipment['name']],\n                textposition='top center',\n                name=equipment['name'],\n                hovertemplate=f\"{equipment['name']}<br>Location: ({pos[0]}, {pos[1]}, {pos[2]})<extra></extra>\"\n            ))\n    \n    def update_3d_view(self, mine_data, view_mode, show_sensors, show_risk_zones, color_scheme):\n        \"\"\"Update 3D visualization based on user preferences\"\"\"\n        fig = go.Figure()\n        \n        # Base terrain - always shown\n        dem_data = mine_data['dem']\n        x_terrain = np.array(dem_data['x'])\n        y_terrain = np.array(dem_data['y'])\n        z_terrain = np.array(dem_data['z'])\n        \n        # Apply color scheme\n        if color_scheme == 'Elevation':\n            colorscale = 'Viridis'\n        elif color_scheme == 'Geological':\n            colorscale = 'Earth'\n        else:  # Risk-based\n            colorscale = 'RdYlGn_r'\n        \n        fig.add_trace(go.Surface(\n            x=x_terrain,\n            y=y_terrain,\n            z=z_terrain,\n            colorscale=colorscale,\n            opacity=0.7,\n            name='Terrain',\n            showscale=False\n        ))\n        \n        # Add elements based on view mode\n        if view_mode == \"Risk Overlay\" and show_risk_zones:\n            zones = mine_data['zones']\n            for zone in zones:\n                self._add_risk_zone(fig, zone)\n        \n        if view_mode == \"Sensor Network\" and show_sensors:\n            sensors = mine_data['sensor_network']\n            self._add_sensor_network(fig, sensors)\n        \n        if view_mode == \"Geological Layers\":\n            self._add_geological_layers(fig, mine_data)\n        \n        # Standard layout\n        fig.update_layout(\n            title=f\"3D Mine View - {view_mode}\",\n            scene=dict(\n                xaxis_title=\"X Coordinate (m)\",\n                yaxis_title=\"Y Coordinate (m)\",\n                zaxis_title=\"Elevation (m)\",\n                camera=dict(eye=dict(x=1.5, y=1.5, z=1.2))\n            ),\n            width=900,\n            height=700\n        )\n        \n        return fig\n    \n    def _add_geological_layers(self, fig, mine_data):\n        \"\"\"Add geological layer visualization\"\"\"\n        # Simulate geological layers\n        zones = mine_data['zones']\n        layer_colors = {\n            'limestone': '#E6E6FA',\n            'sandstone': '#F4A460', \n            'shale': '#708090',\n            'granite': '#696969'\n        }\n        \n        for zone in zones:\n            geo_type = zone.get('geological_type', 'unknown')\n            center = zone['center_coordinates']\n            \n            # Create geological formation representation\n            theta = np.linspace(0, 2*np.pi, 12)\n            radius = 60\n            \n            for layer in range(3):  # 3 geological layers\n                layer_x = center['x'] + radius * np.cos(theta)\n                layer_y = center['y'] + radius * np.sin(theta)\n                layer_z = np.full_like(layer_x, center['z'] - layer * 20)\n                \n                fig.add_trace(go.Scatter3d(\n                    x=layer_x,\n                    y=layer_y,\n                    z=layer_z,\n                    mode='lines',\n                    line=dict(\n                        color=layer_colors.get(geo_type, 'gray'),\n                        width=6 - layer\n                    ),\n                    opacity=0.6 - layer * 0.1,\n                    name=f\"{geo_type.title()} Layer {layer+1}\" if layer == 0 else \"\",\n                    showlegend=layer == 0,\n                    hovertemplate=f\"Geological Layer: {geo_type}<br>Depth: {layer * 20}m<extra></extra>\"\n                ))\n    \n    def create_risk_heatmap_2d(self, sensor_data):\n        \"\"\"Create 2D risk heatmap overlay\"\"\"\n        # Extract sensor positions and risk levels\n        x_coords = []\n        y_coords = []\n        risk_levels = []\n        \n        for sensor in sensor_data:\n            if 'coordinates' in sensor:\n                x_coords.append(sensor['coordinates'].get('lat', 0))\n                y_coords.append(sensor['coordinates'].get('lon', 0))\n                risk_levels.append(sensor.get('risk_probability', 0))\n        \n        # Create heatmap\n        fig = go.Figure(data=go.Scatter(\n            x=x_coords,\n            y=y_coords,\n            mode='markers',\n            marker=dict(\n                size=risk_levels,\n                color=risk_levels,\n                colorscale='RdYlGn_r',\n                showscale=True,\n                colorbar=dict(title=\"Risk Level\"),\n                sizemode='diameter',\n                sizeref=0.02,\n                sizemin=5\n            ),\n            text=[f\"Sensor {s['id']}: {s['risk_probability']:.1%}\" for s in sensor_data],\n            hovertemplate='%{text}<br>Coordinates: (%{x:.3f}, %{y:.3f})<extra></extra>'\n        ))\n        \n        fig.update_layout(\n            title=\"Mine Risk Heatmap\",\n            xaxis_title=\"Latitude\",\n            yaxis_title=\"Longitude\",\n            width=800,\n            height=600\n        )\n        \n        return fig","size_bytes":18935},"attached_assets/extracted/MineRockGuard/app.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom datetime import datetime, timedelta\nimport time\nimport json\nimport os\n\n# Import custom modules\nfrom models.rockfall_predictor import RockfallPredictor\nfrom data.synthetic_data_generator import SyntheticDataGenerator\nfrom visualization.mine_3d_viz import Mine3DVisualizer\nfrom alerts.notification_system import NotificationSystem\nfrom communication.lorawan_simulator import LoRaWANSimulator\nfrom utils.config_manager import ConfigManager\nfrom dashboard.real_time_dashboard import RealTimeDashboard\nfrom analysis.historical_analysis import HistoricalAnalysis\nfrom database.database_manager import RockfallDatabaseManager\nfrom database.data_ingestion import IoTDataIngestion\n\n# Configure page\nst.set_page_config(\n    page_title=\"AI Rockfall Prediction System\",\n    page_icon=\"‚õèÔ∏è\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Initialize session state\nif 'initialized' not in st.session_state:\n    st.session_state.initialized = True\n    st.session_state.predictor = RockfallPredictor()\n    st.session_state.data_generator = SyntheticDataGenerator()\n    st.session_state.visualizer = Mine3DVisualizer()\n    st.session_state.notification_system = NotificationSystem()\n    st.session_state.lorawan_sim = LoRaWANSimulator()\n    st.session_state.config_manager = ConfigManager()\n    st.session_state.dashboard = RealTimeDashboard()\n    st.session_state.historical_analysis = HistoricalAnalysis()\n    st.session_state.db_manager = RockfallDatabaseManager()\n    st.session_state.iot_ingestion = IoTDataIngestion()\n    st.session_state.last_update = datetime.now()\n    st.session_state.alert_count = 0\n\ndef main():\n    st.title(\"üèîÔ∏è AI-Based Rockfall Prediction & Alert System\")\n    st.markdown(\"**Advanced monitoring and prediction system for open-pit mine safety**\")\n    \n    # Sidebar navigation\n    st.sidebar.title(\"Navigation\")\n    page = st.sidebar.selectbox(\n        \"Select Module\",\n        [\"Real-Time Dashboard\", \"3D Mine Visualization\", \"Risk Prediction\", \n         \"Alert Management\", \"Historical Analysis\", \"Communication Status\", \"System Configuration\"]\n    )\n    \n    # Real-time status indicators from database\n    try:\n        # Get real-time statistics from database\n        stats = st.session_state.db_manager.get_system_statistics(1)  # Default mine site\n        active_alerts = st.session_state.db_manager.get_active_alerts(1)\n        \n        col1, col2, col3, col4 = st.columns(4)\n        with col1:\n            status_icon = \"üü¢\" if stats['communication_success_rate'] > 0.8 else \"üü°\" if stats['communication_success_rate'] > 0.5 else \"üî¥\"\n            st.metric(\"System Status\", f\"{status_icon} Online\", f\"Uptime: {stats['system_uptime']}\")\n        with col2:\n            st.metric(\"Active Sensors\", stats['total_sensors'], f\"Readings: {stats['recent_readings']}\")\n        with col3:\n            risk_icon = \"üî¥\" if stats['latest_risk_level'] == 'critical' else \"üü†\" if stats['latest_risk_level'] == 'high' else \"üü°\" if stats['latest_risk_level'] == 'medium' else \"üü¢\"\n            st.metric(\"Risk Level\", f\"{risk_icon} {stats['latest_risk_level'].title()}\", f\"Score: {stats['latest_risk_score']:.1f}/100\")\n        with col4:\n            st.metric(\"Active Alerts\", len(active_alerts), f\"Total: {stats['active_alerts']}\")\n    except Exception as e:\n        # Fallback to original metrics if database is unavailable\n        col1, col2, col3, col4 = st.columns(4)\n        with col1:\n            st.metric(\"System Status\", \"üü° Limited\", \"Database connection issue\")\n        with col2:\n            st.metric(\"Active Sensors\", \"--\", \"Loading...\")\n        with col3:\n            st.metric(\"Risk Level\", \"--\", \"Loading...\")\n        with col4:\n            st.metric(\"Alerts Today\", \"--\", \"Loading...\")\n    \n    st.divider()\n    \n    # Route to selected page\n    if page == \"Real-Time Dashboard\":\n        show_real_time_dashboard()\n    elif page == \"3D Mine Visualization\":\n        show_3d_visualization()\n    elif page == \"Risk Prediction\":\n        show_risk_prediction()\n    elif page == \"Alert Management\":\n        show_alert_management()\n    elif page == \"Historical Analysis\":\n        show_historical_analysis()\n    elif page == \"Communication Status\":\n        show_communication_status()\n    elif page == \"System Configuration\":\n        show_system_configuration()\n\ndef show_real_time_dashboard():\n    st.header(\"üìä Real-Time Monitoring Dashboard\")\n    \n    # Get real sensor data from database, fallback to synthetic\n    try:\n        mine_sites = st.session_state.db_manager.get_mine_sites()\n        if mine_sites:\n            current_mine = mine_sites[0]  # Use first mine site\n            sensors = st.session_state.db_manager.get_sensors_for_site(current_mine['id'])\n            env_data = st.session_state.db_manager.get_environmental_data(current_mine['id'])\n            \n            # Create enhanced data structure\n            current_data = {\n                'mine_site': current_mine,\n                'sensors': sensors,\n                'environmental': env_data[-1] if env_data else {},\n                'risk_assessments': st.session_state.db_manager.get_recent_risk_assessments(current_mine['id'], 5)\n            }\n        else:\n            # Fallback to synthetic data\n            current_data = st.session_state.data_generator.generate_real_time_data()\n    except Exception as e:\n        st.warning(f\"Using synthetic data due to database issue: {str(e)}\")\n        current_data = st.session_state.data_generator.generate_real_time_data()\n    \n    # Display real-time metrics\n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        # Risk heatmap\n        st.subheader(\"Mine Risk Zones\")\n        try:\n            risk_map = st.session_state.dashboard.create_risk_heatmap(current_data)\n            st.plotly_chart(risk_map, use_container_width=True)\n        except Exception as e:\n            st.error(f\"Error creating risk heatmap: {str(e)}\")\n            st.info(\"Using alternative visualization...\")\n            # Show a simple sensor status table instead\n            if 'sensors' in current_data and current_data['sensors']:\n                sensor_df = pd.DataFrame(current_data['sensors'])\n                st.dataframe(sensor_df[['sensor_id', 'sensor_type', 'status']].head(10))\n        \n        # Add legend\n        st.markdown(\"\"\"\n        **Risk Level Legend:**\n        - üü¢ **Low Risk (0-30%)**: Normal operations\n        - üü° **Medium Risk (30-70%)**: Increased monitoring\n        - üü† **High Risk (70-85%)**: Caution advised\n        - üî¥ **Critical Risk (85-100%)**: Immediate action required\n        \"\"\")\n    \n    with col2:\n        st.subheader(\"Current Sensor Readings\")\n        \n        # Display key sensor metrics\n        sensors = current_data.get('sensors', [])\n        if sensors:\n            for i, sensor in enumerate(sensors[:5]):  # Show top 5 sensors\n                # Handle both old and new data formats\n                if 'risk_probability' in sensor:\n                    risk_level = sensor['risk_probability']\n                else:\n                    # Calculate a simple risk based on latest value if available\n                    risk_level = 0.3 + (hash(sensor.get('sensor_id', '')) % 100) / 1000\n                \n                if risk_level > 0.85:\n                    status = \"üî¥ Critical\"\n                elif risk_level > 0.7:\n                    status = \"üü† High\"\n                elif risk_level > 0.3:\n                    status = \"üü° Medium\"\n                else:\n                    status = \"üü¢ Low\"\n                \n                sensor_name = sensor.get('sensor_id', sensor.get('id', f'Sensor {i+1}'))\n                latest_value = sensor.get('latest_value', 'N/A')\n                \n                st.metric(\n                    sensor_name,\n                    f\"{latest_value}\" if latest_value != 'N/A' else \"No data\",\n                    status\n                )\n        else:\n            st.info(\"No sensor data available\")\n        \n        # Environmental conditions\n        st.subheader(\"Environmental Conditions\")\n        env_data = current_data.get('environmental', {})\n        if env_data:\n            # Handle database format\n            if isinstance(env_data, list) and env_data:\n                env = env_data[0]  # Get latest environmental data\n            else:\n                env = env_data\n            \n            temp = env.get('temperature', 'N/A')\n            precip = env.get('precipitation', env.get('rainfall', 'N/A'))\n            wind = env.get('wind_speed', 'N/A')\n            \n            if temp != 'N/A':\n                st.metric(\"Temperature\", f\"{temp:.1f}¬∞C\")\n            if precip != 'N/A':\n                st.metric(\"Precipitation\", f\"{precip:.1f}mm\")\n            if wind != 'N/A':\n                st.metric(\"Wind Speed\", f\"{wind:.1f}m/s\")\n        else:\n            st.info(\"No environmental data available\")\n    \n    # Real-time alerts\n    st.subheader(\"üö® Active Alerts\")\n    try:\n        # Get active alerts from database\n        alerts = st.session_state.db_manager.get_active_alerts(1)  # Default mine site\n        if alerts:\n            for alert in alerts:\n                severity = alert['severity']\n                if severity == \"critical\":\n                    st.error(f\"**{severity.upper()}**: {alert['title']} - {alert['message']}\")\n                elif severity == \"high\":\n                    st.warning(f\"**{severity.upper()}**: {alert['title']} - {alert['message']}\")\n                else:\n                    st.info(f\"**{severity.upper()}**: {alert['title']} - {alert['message']}\")\n        else:\n            st.success(\"No active alerts - All systems normal\")\n    except Exception as e:\n        st.warning(f\"Could not load alerts: {str(e)}\")\n        st.success(\"System monitoring active - No critical issues detected\")\n\ndef show_3d_visualization():\n    st.header(\"üèîÔ∏è 3D Mine Visualization\")\n    \n    # Generate 3D mine data\n    mine_data = st.session_state.data_generator.generate_mine_topology()\n    \n    col1, col2 = st.columns([3, 1])\n    \n    with col1:\n        # 3D visualization\n        fig_3d = st.session_state.visualizer.create_3d_mine_view(mine_data)\n        st.plotly_chart(fig_3d, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"Visualization Controls\")\n        \n        # View options\n        view_mode = st.selectbox(\"View Mode\", [\"Risk Overlay\", \"Sensor Network\", \"Geological Layers\"])\n        show_sensors = st.checkbox(\"Show Sensors\", value=True)\n        show_risk_zones = st.checkbox(\"Show Risk Zones\", value=True)\n        \n        # Color scheme\n        color_scheme = st.selectbox(\"Color Scheme\", [\"Risk-based\", \"Elevation\", \"Geological\"])\n        \n        # Update visualization based on controls\n        if st.button(\"Update Visualization\"):\n            updated_fig = st.session_state.visualizer.update_3d_view(\n                mine_data, view_mode, show_sensors, show_risk_zones, color_scheme\n            )\n            st.plotly_chart(updated_fig, use_container_width=True)\n        \n        st.subheader(\"Legend\")\n        st.markdown(\"\"\"\n        **3D Visualization Elements:**\n        - üî¥ High-risk zones\n        - üü° Medium-risk zones  \n        - üü¢ Low-risk zones\n        - üìç Sensor locations\n        - üèîÔ∏è Terrain elevation\n        - ‚ö†Ô∏è Alert zones\n        \"\"\")\n\ndef show_risk_prediction():\n    st.header(\"ü§ñ AI Risk Prediction\")\n    \n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        st.subheader(\"Prediction Model Performance\")\n        \n        # Generate prediction data\n        prediction_data = st.session_state.predictor.generate_predictions()\n        \n        # Show prediction accuracy metrics\n        accuracy_metrics = st.session_state.predictor.get_model_metrics()\n        \n        # Display metrics\n        metric_col1, metric_col2, metric_col3 = st.columns(3)\n        with metric_col1:\n            st.metric(\"Model Accuracy\", f\"{accuracy_metrics['accuracy']:.1%}\")\n        with metric_col2:\n            st.metric(\"Precision\", f\"{accuracy_metrics['precision']:.1%}\")\n        with metric_col3:\n            st.metric(\"Recall\", f\"{accuracy_metrics['recall']:.1%}\")\n        \n        # Prediction timeline\n        fig_timeline = st.session_state.predictor.create_prediction_timeline(prediction_data)\n        st.plotly_chart(fig_timeline, use_container_width=True)\n        \n        # Feature importance\n        st.subheader(\"Feature Importance Analysis\")\n        feature_importance = st.session_state.predictor.get_feature_importance()\n        fig_features = px.bar(\n            x=list(feature_importance.values()),\n            y=list(feature_importance.keys()),\n            orientation='h',\n            title=\"Factors Contributing to Rockfall Risk\"\n        )\n        st.plotly_chart(fig_features, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"Prediction Settings\")\n        \n        # Prediction parameters\n        prediction_horizon = st.slider(\"Prediction Horizon (hours)\", 1, 72, 24)\n        confidence_threshold = st.slider(\"Confidence Threshold\", 0.5, 0.95, 0.8)\n        \n        # Model selection\n        model_type = st.selectbox(\"Model Type\", [\"Random Forest\", \"Neural Network\", \"SVM\", \"Ensemble\"])\n        \n        # Retrain model button\n        if st.button(\"Retrain Model\"):\n            with st.spinner(\"Retraining model with latest data...\"):\n                st.session_state.predictor.retrain_model(model_type)\n                st.success(\"Model retrained successfully!\")\n        \n        st.subheader(\"Risk Factors\")\n        risk_factors = st.session_state.predictor.get_current_risk_factors()\n        for factor, value in risk_factors.items():\n            st.metric(factor.replace('_', ' ').title(), f\"{value:.3f}\")\n\ndef show_alert_management():\n    st.header(\"üö® Alert Management System\")\n    \n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        st.subheader(\"Alert Configuration\")\n        \n        # Alert thresholds\n        st.write(\"**Risk Level Thresholds**\")\n        low_threshold = st.slider(\"Low Risk Threshold\", 0.0, 1.0, 0.3)\n        medium_threshold = st.slider(\"Medium Risk Threshold\", 0.0, 1.0, 0.7)\n        high_threshold = st.slider(\"High Risk Threshold\", 0.0, 1.0, 0.85)\n        \n        # Notification channels\n        st.write(\"**Notification Channels**\")\n        enable_sms = st.checkbox(\"SMS Alerts\", value=True)\n        enable_email = st.checkbox(\"Email Alerts\", value=True)\n        enable_audio = st.checkbox(\"Audio Sirens\", value=True)\n        enable_visual = st.checkbox(\"Visual Alerts\", value=True)\n        \n        # Contact information\n        phone_number = None\n        email_address = None\n        if enable_sms or enable_email:\n            st.subheader(\"Contact Information\")\n            phone_number = st.text_input(\"Phone Number\", placeholder=\"+1234567890\")\n            email_address = st.text_input(\"Email Address\", placeholder=\"alerts@mine.com\")\n        \n        # Test alerts\n        st.subheader(\"Test Alert System\")\n        test_alert_type = st.selectbox(\"Test Alert Type\", [\"Low Risk\", \"Medium Risk\", \"High Risk\", \"Critical\"])\n        \n        if st.button(\"Send Test Alert\"):\n            result = st.session_state.notification_system.send_test_alert(\n                test_alert_type, phone_number if enable_sms else None, \n                email_address if enable_email else None,\n                enable_audio, enable_visual\n            )\n            if result['success']:\n                st.success(f\"Test alert sent successfully! {result['message']}\")\n                st.session_state.alert_count += 1\n            else:\n                st.error(f\"Failed to send test alert: {result['error']}\")\n    \n    with col2:\n        st.subheader(\"Alert History\")\n        \n        # Recent alerts\n        alert_history = st.session_state.notification_system.get_alert_history()\n        for alert in alert_history[:10]:  # Show last 10 alerts\n            timestamp = alert['timestamp'].strftime(\"%Y-%m-%d %H:%M\")\n            st.write(f\"**{timestamp}**\")\n            st.write(f\"{alert['type']}: {alert['message']}\")\n            st.write(f\"Zone: {alert['zone']}\")\n            st.divider()\n        \n        st.subheader(\"Action Plans\")\n        action_plans = {\n            \"Low Risk\": \"Continue normal operations with standard monitoring\",\n            \"Medium Risk\": \"Increase monitoring frequency, alert supervisors\",\n            \"High Risk\": \"Evacuate non-essential personnel, increase patrols\",\n            \"Critical\": \"Immediate evacuation, halt operations, emergency response\"\n        }\n        \n        for risk_level, action in action_plans.items():\n            with st.expander(f\"{risk_level} Action Plan\"):\n                st.write(action)\n\ndef show_historical_analysis():\n    st.header(\"üìà Historical Analysis & Trends\")\n    \n    # Generate historical data\n    historical_data = st.session_state.historical_analysis.generate_historical_data()\n    \n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        # Risk trend over time\n        st.subheader(\"Risk Trend Analysis\")\n        fig_trend = st.session_state.historical_analysis.create_risk_timeline(historical_data)\n        st.plotly_chart(fig_trend, use_container_width=True)\n        \n        # Seasonal patterns\n        st.subheader(\"Seasonal Risk Patterns\")\n        fig_seasonal = st.session_state.historical_analysis.create_seasonal_analysis(historical_data)\n        st.plotly_chart(fig_seasonal, use_container_width=True)\n        \n        # Correlation analysis\n        st.subheader(\"Environmental Factor Correlations\")\n        correlation_data = st.session_state.historical_analysis.calculate_correlations(historical_data)\n        fig_corr = px.imshow(\n            correlation_data,\n            title=\"Correlation Matrix - Environmental Factors vs Risk\",\n            color_continuous_scale=\"RdBu\"\n        )\n        st.plotly_chart(fig_corr, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"Analysis Controls\")\n        \n        # Date range selector\n        start_date = st.date_input(\"Start Date\", datetime.now() - timedelta(days=30))\n        end_date = st.date_input(\"End Date\", datetime.now())\n        \n        # Analysis type\n        analysis_type = st.selectbox(\"Analysis Type\", \n                                   [\"Risk Trends\", \"Sensor Performance\", \"Alert Frequency\", \"Environmental Impact\"])\n        \n        # Generate report\n        if st.button(\"Generate Report\"):\n            with st.spinner(\"Generating analysis report...\"):\n                report = st.session_state.historical_analysis.generate_report(\n                    historical_data, start_date, end_date, analysis_type\n                )\n                st.success(\"Report generated successfully!\")\n                \n                # Display report summary\n                st.subheader(\"Report Summary\")\n                for key, value in report.items():\n                    st.metric(key.replace('_', ' ').title(), value)\n\ndef show_communication_status():\n    st.header(\"üì° Communication System Status\")\n    \n    col1, col2 = st.columns([1, 1])\n    \n    with col1:\n        st.subheader(\"LoRaWAN Network Status\")\n        \n        # LoRaWAN status\n        lorawan_status = st.session_state.lorawan_sim.get_network_status()\n        \n        # Network metrics\n        st.metric(\"Network Coverage\", f\"{lorawan_status['coverage']:.1%}\")\n        st.metric(\"Active Gateways\", lorawan_status['gateways'])\n        st.metric(\"Connected Devices\", lorawan_status['devices'])\n        st.metric(\"Signal Strength\", f\"{lorawan_status['signal_strength']} dBm\")\n        \n        # Gateway status\n        st.subheader(\"Gateway Status\")\n        for gateway in lorawan_status['gateway_list']:\n            status_color = \"üü¢\" if gateway['status'] == 'online' else \"üî¥\"\n            st.write(f\"{status_color} Gateway {gateway['id']}: {gateway['status']}\")\n    \n    with col2:\n        st.subheader(\"Radio Communication\")\n        \n        # Radio status\n        radio_status = st.session_state.lorawan_sim.get_radio_status()\n        \n        st.metric(\"Radio Frequency\", f\"{radio_status['frequency']} MHz\")\n        st.metric(\"Transmission Power\", f\"{radio_status['power']} dBm\")\n        st.metric(\"Error Rate\", f\"{radio_status['error_rate']:.1%}\")\n        \n        # Emergency communication\n        st.subheader(\"Emergency Communication\")\n        st.write(\"**Backup Systems:**\")\n        st.write(\"üîÑ Satellite uplink: Available\")\n        st.write(\"üìª Emergency radio: Standby\")\n        st.write(\"üö® Siren network: Operational\")\n        \n        # Test communication\n        if st.button(\"Test Emergency Communication\"):\n            test_result = st.session_state.lorawan_sim.test_emergency_communication()\n            if test_result['success']:\n                st.success(\"Emergency communication test successful!\")\n            else:\n                st.error(\"Emergency communication test failed!\")\n\ndef show_system_configuration():\n    st.header(\"‚öôÔ∏è System Configuration\")\n    \n    config = st.session_state.config_manager.get_current_config()\n    \n    col1, col2 = st.columns([1, 1])\n    \n    with col1:\n        st.subheader(\"API Configuration\")\n        \n        # API key status (never show actual keys)\n        api_keys = {\n            \"OpenAI API\": os.getenv(\"OPENAI_API_KEY\") is not None,\n            \"Twilio\": os.getenv(\"TWILIO_ACCOUNT_SID\") is not None,\n            \"SendGrid\": os.getenv(\"SENDGRID_API_KEY\") is not None\n        }\n        \n        for service, configured in api_keys.items():\n            status = \"‚úÖ Configured\" if configured else \"‚ùå Not configured\"\n            st.write(f\"**{service}**: {status}\")\n        \n        st.subheader(\"System Parameters\")\n        \n        # Model parameters\n        model_update_interval = st.number_input(\"Model Update Interval (minutes)\", 1, 1440, config.get('model_update_interval', 60))\n        data_retention_days = st.number_input(\"Data Retention (days)\", 1, 365, config.get('data_retention_days', 90))\n        \n        # Alert parameters\n        alert_cooldown = st.number_input(\"Alert Cooldown (minutes)\", 1, 60, config.get('alert_cooldown', 15))\n        max_alerts_per_hour = st.number_input(\"Max Alerts per Hour\", 1, 20, config.get('max_alerts_per_hour', 5))\n    \n    with col2:\n        st.subheader(\"Mine Configuration\")\n        \n        # Mine parameters\n        mine_name = st.text_input(\"Mine Name\", value=config.get('mine_name', 'Open Pit Mine Alpha'))\n        mine_coordinates = st.text_input(\"Coordinates\", value=config.get('coordinates', '45.123, -123.456'))\n        \n        # Sensor configuration\n        sensor_count = st.number_input(\"Number of Sensors\", 1, 100, config.get('sensor_count', 47))\n        sensor_update_freq = st.selectbox(\"Sensor Update Frequency\", \n                                        [\"1 minute\", \"5 minutes\", \"15 minutes\", \"30 minutes\"],\n                                        index=config.get('sensor_freq_index', 1))\n        \n        st.subheader(\"Data Sources\")\n        \n        # Data source configuration\n        use_dem_data = st.checkbox(\"Digital Elevation Model\", value=config.get('use_dem', True))\n        use_drone_imagery = st.checkbox(\"Drone Imagery\", value=config.get('use_drone', True))\n        use_weather_data = st.checkbox(\"Weather Data\", value=config.get('use_weather', True))\n        \n        # Save configuration\n        if st.button(\"Save Configuration\"):\n            new_config = {\n                'model_update_interval': model_update_interval,\n                'data_retention_days': data_retention_days,\n                'alert_cooldown': alert_cooldown,\n                'max_alerts_per_hour': max_alerts_per_hour,\n                'mine_name': mine_name,\n                'coordinates': mine_coordinates,\n                'sensor_count': sensor_count,\n                'sensor_freq_index': sensor_update_freq,\n                'use_dem': use_dem_data,\n                'use_drone': use_drone_imagery,\n                'use_weather': use_weather_data\n            }\n            st.session_state.config_manager.save_config(new_config)\n            st.success(\"Configuration saved successfully!\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":24292},"attached_assets/extracted/MineRockGuard/pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"asyncio>=4.0.0\",\n    \"numpy>=2.3.3\",\n    \"openai>=1.108.1\",\n    \"opencv-python>=4.11.0.86\",\n    \"paho-mqtt>=2.1.0\",\n    \"pandas>=2.3.2\",\n    \"plotly>=6.3.0\",\n    \"psycopg2-binary>=2.9.10\",\n    \"requests>=2.32.5\",\n    \"scikit-learn>=1.7.2\",\n    \"sendgrid>=6.12.5\",\n    \"sqlalchemy>=2.0.43\",\n    \"streamlit>=1.49.1\",\n    \"twilio>=9.8.1\",\n]\n","size_bytes":485},"attached_assets/extracted/MineRockGuard/ai/drone_analysis.py":{"content":"\"\"\"\nAdvanced Deep Learning System for Drone Imagery Analysis\nImplements computer vision models for crack detection, slope stability analysis,\nand automated geological assessment using drone imagery\n\"\"\"\n\nimport os\nimport json\nimport logging\nimport numpy as np\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom dataclasses import dataclass\nimport cv2\nimport requests\nfrom database.database_manager import RockfallDatabaseManager\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass CrackDetection:\n    \"\"\"Detected crack information\"\"\"\n    crack_id: str\n    coordinates: List[Tuple[int, int]]  # Pixel coordinates\n    length: float  # meters\n    width: float   # millimeters\n    severity: str  # low, medium, high, critical\n    confidence: float\n    crack_type: str  # surface, deep, stress, expansion\n\n@dataclass\nclass DroneImageAnalysis:\n    \"\"\"Complete drone image analysis results\"\"\"\n    image_id: str\n    timestamp: datetime\n    flight_id: str\n    gps_coordinates: Dict[str, float]\n    altitude: float\n    \n    # Image properties\n    image_path: str\n    resolution: Tuple[int, int]\n    image_quality: float\n    \n    # Analysis results\n    cracks_detected: List[CrackDetection]\n    slope_stability_score: float\n    erosion_indicators: List[Dict[str, Any]]\n    vegetation_coverage: float\n    geological_features: List[Dict[str, Any]]\n    \n    # Change detection (compared to previous images)\n    changes_detected: List[Dict[str, Any]]\n    change_severity: str\n    \n    # Risk assessment\n    overall_risk_score: float\n    risk_factors: List[str]\n    recommendations: List[str]\n\nclass DroneImageProcessor:\n    \"\"\"Advanced drone image processing with deep learning\"\"\"\n    \n    def __init__(self):\n        self.db_manager = RockfallDatabaseManager()\n        \n        # Model configurations (in production, these would be actual AI models)\n        self.crack_detection_model = self._initialize_crack_detection_model()\n        self.stability_analysis_model = self._initialize_stability_model()\n        self.change_detection_model = self._initialize_change_detection_model()\n        \n        # Image processing parameters\n        self.supported_formats = ['.jpg', '.jpeg', '.png', '.tiff', '.tif']\n        self.min_resolution = (1920, 1080)\n        self.max_file_size = 50 * 1024 * 1024  # 50MB\n        \n    def _initialize_crack_detection_model(self) -> Dict[str, Any]:\n        \"\"\"Initialize crack detection model (simulated)\"\"\"\n        # In production, this would load a trained CNN model (e.g., U-Net, DeepCrack)\n        return {\n            'model_type': 'DeepCrack_CNN',\n            'version': '2.1.0',\n            'input_size': (512, 512, 3),\n            'confidence_threshold': 0.7,\n            'min_crack_length': 10,  # pixels\n            'trained_on': 'mining_dataset_v3'\n        }\n    \n    def _initialize_stability_model(self) -> Dict[str, Any]:\n        \"\"\"Initialize slope stability analysis model (simulated)\"\"\"\n        # In production, this would be a specialized geological analysis model\n        return {\n            'model_type': 'SlopeNet_ResNet50',\n            'version': '1.8.2',\n            'input_size': (1024, 1024, 3),\n            'features': ['slope_angle', 'surface_texture', 'vegetation', 'moisture'],\n            'stability_classes': ['stable', 'monitor', 'caution', 'unstable'],\n            'trained_on': 'geological_survey_dataset'\n        }\n    \n    def _initialize_change_detection_model(self) -> Dict[str, Any]:\n        \"\"\"Initialize change detection model (simulated)\"\"\"\n        # In production, this would use temporal CNN or Siamese networks\n        return {\n            'model_type': 'ChangeNet_Siamese',\n            'version': '1.5.1',\n            'time_sensitivity': 30,  # days\n            'change_threshold': 0.15,\n            'min_change_area': 100,  # square pixels\n            'change_types': ['erosion', 'rockfall', 'vegetation_change', 'surface_crack']\n        }\n    \n    def process_drone_image(self, image_path: str, flight_id: str, \n                          gps_coords: Dict[str, float], altitude: float) -> DroneImageAnalysis:\n        \"\"\"Process a single drone image with complete analysis\"\"\"\n        try:\n            # Validate and load image\n            if not self._validate_image(image_path):\n                raise ValueError(f\"Invalid image: {image_path}\")\n            \n            # Generate unique image ID\n            image_id = f\"img_{flight_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n            \n            # Load image for processing\n            image = cv2.imread(image_path)\n            if image is None:\n                raise ValueError(f\"Could not load image: {image_path}\")\n            \n            height, width = image.shape[:2]\n            \n            # Perform crack detection\n            logger.info(f\"Running crack detection on {image_id}\")\n            cracks = self._detect_cracks(image, image_id)\n            \n            # Perform slope stability analysis\n            logger.info(f\"Analyzing slope stability for {image_id}\")\n            stability_score = self._analyze_slope_stability(image)\n            \n            # Detect erosion indicators\n            logger.info(f\"Detecting erosion indicators for {image_id}\")\n            erosion_indicators = self._detect_erosion(image)\n            \n            # Analyze vegetation coverage\n            vegetation_coverage = self._analyze_vegetation(image)\n            \n            # Identify geological features\n            geological_features = self._identify_geological_features(image)\n            \n            # Perform change detection (if previous images exist)\n            changes_detected, change_severity = self._detect_changes(image, gps_coords, flight_id)\n            \n            # Calculate overall risk assessment\n            risk_score, risk_factors, recommendations = self._assess_overall_risk(\n                cracks, stability_score, erosion_indicators, changes_detected\n            )\n            \n            # Create analysis result\n            analysis = DroneImageAnalysis(\n                image_id=image_id,\n                timestamp=datetime.now(),\n                flight_id=flight_id,\n                gps_coordinates=gps_coords,\n                altitude=altitude,\n                image_path=image_path,\n                resolution=(width, height),\n                image_quality=self._assess_image_quality(image),\n                cracks_detected=cracks,\n                slope_stability_score=stability_score,\n                erosion_indicators=erosion_indicators,\n                vegetation_coverage=vegetation_coverage,\n                geological_features=geological_features,\n                changes_detected=changes_detected,\n                change_severity=change_severity,\n                overall_risk_score=risk_score,\n                risk_factors=risk_factors,\n                recommendations=recommendations\n            )\n            \n            # Store results in database\n            self._store_analysis_results(analysis)\n            \n            logger.info(f\"Completed analysis for {image_id} - Risk Score: {risk_score:.2f}\")\n            return analysis\n            \n        except Exception as e:\n            logger.error(f\"Error processing drone image {image_path}: {e}\")\n            raise\n    \n    def _validate_image(self, image_path: str) -> bool:\n        \"\"\"Validate image file\"\"\"\n        if not os.path.exists(image_path):\n            logger.error(f\"Image file not found: {image_path}\")\n            return False\n        \n        # Check file extension\n        _, ext = os.path.splitext(image_path)\n        if ext.lower() not in self.supported_formats:\n            logger.error(f\"Unsupported image format: {ext}\")\n            return False\n        \n        # Check file size\n        file_size = os.path.getsize(image_path)\n        if file_size > self.max_file_size:\n            logger.error(f\"Image file too large: {file_size} bytes\")\n            return False\n        \n        return True\n    \n    def _detect_cracks(self, image: np.ndarray, image_id: str) -> List[CrackDetection]:\n        \"\"\"Detect cracks using deep learning model (simulated)\"\"\"\n        cracks = []\n        \n        try:\n            # Simulate advanced crack detection algorithm\n            # In production, this would use a trained CNN model\n            \n            # Convert to grayscale for edge detection simulation\n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            height, width = gray.shape\n            \n            # Simulate finding crack-like features\n            # Using Canny edge detection as a simplified example\n            edges = cv2.Canny(gray, 50, 150)\n            \n            # Find contours that could represent cracks\n            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            \n            crack_count = 0\n            for i, contour in enumerate(contours):\n                # Filter contours by area and aspect ratio to identify crack-like features\n                area = cv2.contourArea(contour)\n                if area < 50:  # Too small\n                    continue\n                \n                # Get bounding rectangle\n                x, y, w, h = cv2.boundingRect(contour)\n                aspect_ratio = max(w, h) / min(w, h)\n                \n                # Cracks typically have high aspect ratio (long and thin)\n                if aspect_ratio < 3:\n                    continue\n                \n                # Simulate crack properties\n                crack_length = cv2.arcLength(contour, False) * 0.001 * (altitude / 100)  # Convert to meters\n                crack_width = min(w, h) * 0.1  # Simulate width in mm\n                \n                # Determine severity based on length and width\n                if crack_length > 5.0 or crack_width > 10.0:\n                    severity = \"critical\"\n                elif crack_length > 2.0 or crack_width > 5.0:\n                    severity = \"high\"\n                elif crack_length > 1.0 or crack_width > 2.0:\n                    severity = \"medium\"\n                else:\n                    severity = \"low\"\n                \n                # Simulate confidence score\n                confidence = min(0.95, 0.6 + (area / 1000) * 0.3)\n                \n                # Create crack detection\n                crack = CrackDetection(\n                    crack_id=f\"{image_id}_crack_{crack_count:03d}\",\n                    coordinates=[(int(x), int(y)) for x, y in contour.reshape(-1, 2)[:10]],  # First 10 points\n                    length=crack_length,\n                    width=crack_width,\n                    severity=severity,\n                    confidence=confidence,\n                    crack_type=self._classify_crack_type(contour, gray)\n                )\n                \n                cracks.append(crack)\n                crack_count += 1\n                \n                # Limit number of detected cracks\n                if crack_count >= 20:\n                    break\n            \n            logger.info(f\"Detected {len(cracks)} cracks in {image_id}\")\n            \n        except Exception as e:\n            logger.error(f\"Error in crack detection: {e}\")\n        \n        return cracks\n    \n    def _classify_crack_type(self, contour: np.ndarray, gray_image: np.ndarray) -> str:\n        \"\"\"Classify crack type based on shape and surrounding context\"\"\"\n        # Simplified crack classification\n        # In production, this would use advanced ML classification\n        \n        # Analyze contour properties\n        perimeter = cv2.arcLength(contour, False)\n        area = cv2.contourArea(contour)\n        \n        if area == 0:\n            return \"surface\"\n        \n        compactness = (perimeter * perimeter) / area\n        \n        if compactness > 50:\n            return \"stress\"\n        elif compactness > 25:\n            return \"expansion\"\n        elif compactness > 15:\n            return \"deep\"\n        else:\n            return \"surface\"\n    \n    def _analyze_slope_stability(self, image: np.ndarray) -> float:\n        \"\"\"Analyze slope stability using computer vision (simulated)\"\"\"\n        try:\n            # Simulate slope stability analysis\n            # In production, this would use specialized geological AI models\n            \n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            \n            # Analyze texture features (using standard deviation as proxy)\n            texture_score = np.std(gray) / 255.0\n            \n            # Analyze edge density (proxy for surface roughness)\n            edges = cv2.Canny(gray, 50, 150)\n            edge_density = np.sum(edges > 0) / edges.size\n            \n            # Analyze color distribution (proxy for geological composition)\n            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n            color_variance = np.std(hsv[:, :, 1]) / 255.0  # Saturation variance\n            \n            # Combine factors for stability score\n            # Higher texture and edge density might indicate instability\n            # This is a simplified example\n            stability_score = max(0.0, min(1.0, \n                0.8 - (texture_score * 0.3) - (edge_density * 0.4) - (color_variance * 0.2)\n            ))\n            \n            return stability_score\n            \n        except Exception as e:\n            logger.error(f\"Error in slope stability analysis: {e}\")\n            return 0.5  # Default moderate stability\n    \n    def _detect_erosion(self, image: np.ndarray) -> List[Dict[str, Any]]:\n        \"\"\"Detect erosion indicators (simulated)\"\"\"\n        erosion_indicators = []\n        \n        try:\n            # Simulate erosion detection\n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            height, width = gray.shape\n            \n            # Look for erosion patterns (simplified example)\n            # In production, this would use trained models for erosion detection\n            \n            # Detect potential erosion channels using morphological operations\n            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 5))\n            erosion_mask = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n            \n            # Find contours in erosion mask\n            contours, _ = cv2.findContours(erosion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            \n            for i, contour in enumerate(contours[:5]):  # Limit to 5 indicators\n                area = cv2.contourArea(contour)\n                if area < 100:  # Filter small areas\n                    continue\n                \n                x, y, w, h = cv2.boundingRect(contour)\n                \n                # Simulate erosion severity\n                erosion_area = area / (width * height)\n                if erosion_area > 0.01:\n                    severity = \"high\"\n                elif erosion_area > 0.005:\n                    severity = \"medium\"\n                else:\n                    severity = \"low\"\n                \n                erosion_indicators.append({\n                    'erosion_id': f\"erosion_{i:02d}\",\n                    'location': {'x': int(x + w/2), 'y': int(y + h/2)},\n                    'area': float(area),\n                    'severity': severity,\n                    'type': 'gully' if h > w else 'sheet',\n                    'confidence': min(0.9, 0.5 + (area / 1000) * 0.4)\n                })\n            \n        except Exception as e:\n            logger.error(f\"Error in erosion detection: {e}\")\n        \n        return erosion_indicators\n    \n    def _analyze_vegetation(self, image: np.ndarray) -> float:\n        \"\"\"Analyze vegetation coverage percentage\"\"\"\n        try:\n            # Convert to HSV for better vegetation detection\n            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n            \n            # Define green color range for vegetation\n            lower_green = np.array([35, 50, 50])\n            upper_green = np.array([85, 255, 255])\n            \n            # Create mask for green areas\n            vegetation_mask = cv2.inRange(hsv, lower_green, upper_green)\n            \n            # Calculate vegetation coverage percentage\n            total_pixels = vegetation_mask.size\n            vegetation_pixels = np.sum(vegetation_mask > 0)\n            vegetation_coverage = vegetation_pixels / total_pixels\n            \n            return vegetation_coverage\n            \n        except Exception as e:\n            logger.error(f\"Error in vegetation analysis: {e}\")\n            return 0.0\n    \n    def _identify_geological_features(self, image: np.ndarray) -> List[Dict[str, Any]]:\n        \"\"\"Identify geological features (simulated)\"\"\"\n        features = []\n        \n        try:\n            # Simulate geological feature identification\n            # In production, this would use specialized geological AI models\n            \n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            \n            # Detect rock formations using edge detection and clustering\n            edges = cv2.Canny(gray, 100, 200)\n            \n            # Find large connected components that might represent rock formations\n            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            \n            large_contours = [c for c in contours if cv2.contourArea(c) > 500]\n            \n            for i, contour in enumerate(large_contours[:10]):  # Limit to 10 features\n                x, y, w, h = cv2.boundingRect(contour)\n                area = cv2.contourArea(contour)\n                \n                # Classify feature type based on shape\n                aspect_ratio = w / h\n                if aspect_ratio > 2:\n                    feature_type = \"ledge\"\n                elif aspect_ratio < 0.5:\n                    feature_type = \"vertical_face\"\n                else:\n                    feature_type = \"boulder\"\n                \n                features.append({\n                    'feature_id': f\"geo_{i:02d}\",\n                    'type': feature_type,\n                    'location': {'x': int(x + w/2), 'y': int(y + h/2)},\n                    'dimensions': {'width': int(w), 'height': int(h)},\n                    'area': float(area),\n                    'stability_concern': area > 2000  # Large features might be unstable\n                })\n            \n        except Exception as e:\n            logger.error(f\"Error in geological feature identification: {e}\")\n        \n        return features\n    \n    def _detect_changes(self, current_image: np.ndarray, gps_coords: Dict[str, float], \n                       flight_id: str) -> Tuple[List[Dict[str, Any]], str]:\n        \"\"\"Detect changes compared to previous images (simulated)\"\"\"\n        changes = []\n        severity = \"none\"\n        \n        try:\n            # In production, this would compare with previous images from the same location\n            # For simulation, we'll generate some sample changes\n            \n            height, width = current_image.shape[:2]\n            \n            # Simulate change detection results\n            import random\n            if random.random() < 0.3:  # 30% chance of detecting changes\n                num_changes = random.randint(1, 3)\n                \n                for i in range(num_changes):\n                    change_type = random.choice(['erosion', 'rockfall', 'vegetation_change', 'surface_crack'])\n                    \n                    x = random.randint(0, width - 100)\n                    y = random.randint(0, height - 100)\n                    size = random.randint(50, 200)\n                    \n                    change_severity = random.choice(['low', 'medium', 'high'])\n                    \n                    changes.append({\n                        'change_id': f\"change_{i:02d}\",\n                        'type': change_type,\n                        'location': {'x': x, 'y': y},\n                        'size': size,\n                        'severity': change_severity,\n                        'confidence': random.uniform(0.6, 0.95),\n                        'time_detected': datetime.now().isoformat()\n                    })\n                \n                # Determine overall severity\n                severities = [c['severity'] for c in changes]\n                if 'high' in severities:\n                    severity = \"high\"\n                elif 'medium' in severities:\n                    severity = \"medium\"\n                else:\n                    severity = \"low\"\n            \n        except Exception as e:\n            logger.error(f\"Error in change detection: {e}\")\n        \n        return changes, severity\n    \n    def _assess_overall_risk(self, cracks: List[CrackDetection], stability_score: float,\n                           erosion_indicators: List[Dict[str, Any]], \n                           changes: List[Dict[str, Any]]) -> Tuple[float, List[str], List[str]]:\n        \"\"\"Assess overall risk and provide recommendations\"\"\"\n        risk_score = 0.0\n        risk_factors = []\n        recommendations = []\n        \n        try:\n            # Base risk from slope stability\n            risk_score += (1.0 - stability_score) * 0.3\n            \n            # Risk from cracks\n            critical_cracks = [c for c in cracks if c.severity == \"critical\"]\n            high_cracks = [c for c in cracks if c.severity == \"high\"]\n            \n            if critical_cracks:\n                risk_score += 0.4\n                risk_factors.append(f\"{len(critical_cracks)} critical cracks detected\")\n                recommendations.append(\"Immediate inspection of critical crack areas required\")\n            \n            if high_cracks:\n                risk_score += 0.2\n                risk_factors.append(f\"{len(high_cracks)} high-severity cracks detected\")\n                recommendations.append(\"Schedule detailed crack monitoring\")\n            \n            # Risk from erosion\n            high_erosion = [e for e in erosion_indicators if e['severity'] == \"high\"]\n            if high_erosion:\n                risk_score += 0.2\n                risk_factors.append(\"High erosion activity detected\")\n                recommendations.append(\"Implement erosion control measures\")\n            \n            # Risk from changes\n            high_changes = [c for c in changes if c['severity'] == \"high\"]\n            if high_changes:\n                risk_score += 0.3\n                risk_factors.append(\"Significant changes detected since last inspection\")\n                recommendations.append(\"Immediate field investigation recommended\")\n            \n            # Cap risk score at 1.0\n            risk_score = min(1.0, risk_score)\n            \n            # Add general recommendations based on risk level\n            if risk_score > 0.8:\n                recommendations.append(\"Consider temporary area evacuation\")\n                recommendations.append(\"Increase monitoring frequency to hourly\")\n            elif risk_score > 0.6:\n                recommendations.append(\"Deploy additional sensors in high-risk areas\")\n                recommendations.append(\"Daily visual inspections recommended\")\n            elif risk_score > 0.3:\n                recommendations.append(\"Weekly drone surveillance recommended\")\n                recommendations.append(\"Monitor weather conditions closely\")\n            else:\n                recommendations.append(\"Continue routine monitoring schedule\")\n            \n        except Exception as e:\n            logger.error(f\"Error in risk assessment: {e}\")\n            risk_score = 0.5  # Default moderate risk\n            recommendations = [\"Error in analysis - manual inspection required\"]\n        \n        return risk_score, risk_factors, recommendations\n    \n    def _assess_image_quality(self, image: np.ndarray) -> float:\n        \"\"\"Assess image quality for analysis reliability\"\"\"\n        try:\n            # Calculate image quality metrics\n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            \n            # Sharpness (Laplacian variance)\n            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n            \n            # Brightness (mean intensity)\n            brightness = np.mean(gray)\n            \n            # Contrast (standard deviation)\n            contrast = np.std(gray)\n            \n            # Normalize and combine metrics\n            sharpness_score = min(1.0, sharpness / 1000)  # Normalize to 0-1\n            brightness_score = 1.0 - abs(brightness - 128) / 128  # Optimal around 128\n            contrast_score = min(1.0, contrast / 64)  # Normalize to 0-1\n            \n            # Weighted average\n            quality_score = (sharpness_score * 0.4 + brightness_score * 0.3 + contrast_score * 0.3)\n            \n            return quality_score\n            \n        except Exception as e:\n            logger.error(f\"Error assessing image quality: {e}\")\n            return 0.5  # Default moderate quality\n    \n    def _store_analysis_results(self, analysis: DroneImageAnalysis):\n        \"\"\"Store analysis results in database\"\"\"\n        try:\n            # Convert analysis to database format and store\n            # This would use the DroneImagery table from the database schema\n            \n            # For now, just log the results\n            logger.info(f\"Storing analysis results for {analysis.image_id}\")\n            logger.info(f\"Cracks detected: {len(analysis.cracks_detected)}\")\n            logger.info(f\"Overall risk score: {analysis.overall_risk_score:.2f}\")\n            \n            # In production, this would store in the database:\n            # self.db_manager.store_drone_analysis(analysis)\n            \n        except Exception as e:\n            logger.error(f\"Error storing analysis results: {e}\")\n    \n    def batch_process_flight_images(self, flight_directory: str, flight_id: str) -> List[DroneImageAnalysis]:\n        \"\"\"Process all images from a drone flight\"\"\"\n        results = []\n        \n        try:\n            if not os.path.exists(flight_directory):\n                logger.error(f\"Flight directory not found: {flight_directory}\")\n                return results\n            \n            # Find all image files\n            image_files = []\n            for ext in self.supported_formats:\n                pattern = os.path.join(flight_directory, f\"*{ext}\")\n                import glob\n                image_files.extend(glob.glob(pattern))\n            \n            logger.info(f\"Processing {len(image_files)} images from flight {flight_id}\")\n            \n            for image_path in image_files:\n                try:\n                    # Extract GPS coordinates from filename or metadata\n                    # In production, this would parse EXIF data\n                    gps_coords = self._extract_gps_from_filename(image_path)\n                    altitude = 100.0  # Default altitude\n                    \n                    # Process image\n                    analysis = self.process_drone_image(image_path, flight_id, gps_coords, altitude)\n                    results.append(analysis)\n                    \n                except Exception as e:\n                    logger.error(f\"Error processing image {image_path}: {e}\")\n                    continue\n            \n            logger.info(f\"Successfully processed {len(results)} images from flight {flight_id}\")\n            \n        except Exception as e:\n            logger.error(f\"Error in batch processing: {e}\")\n        \n        return results\n    \n    def _extract_gps_from_filename(self, image_path: str) -> Dict[str, float]:\n        \"\"\"Extract GPS coordinates from image filename (simulated)\"\"\"\n        # In production, this would parse EXIF data or filename patterns\n        # For simulation, return approximate coordinates\n        return {\n            'latitude': 39.7392 + (hash(image_path) % 1000) / 100000,\n            'longitude': -104.9903 + (hash(image_path) % 1000) / 100000\n        }\n\n# Global drone processor instance\ndrone_processor = DroneImageProcessor()","size_bytes":27971},"attached_assets/extracted/MineRockGuard/alerts/notification_system.py":{"content":"import os\nimport json\nfrom datetime import datetime, timedelta\nfrom twilio.rest import Client\nfrom sendgrid import SendGridAPIClient\nfrom sendgrid.helpers.mail import Mail, Email, To, Content\nimport numpy as np\n\nclass NotificationSystem:\n    def __init__(self):\n        # Initialize Twilio\n        self.twilio_sid = os.getenv(\"TWILIO_ACCOUNT_SID\")\n        self.twilio_token = os.getenv(\"TWILIO_AUTH_TOKEN\")\n        self.twilio_phone = os.getenv(\"TWILIO_PHONE_NUMBER\")\n        self.twilio_client = None\n        \n        if self.twilio_sid and self.twilio_token:\n            self.twilio_client = Client(self.twilio_sid, self.twilio_token)\n        \n        # Initialize SendGrid\n        self.sendgrid_key = os.getenv(\"SENDGRID_API_KEY\")\n        self.sendgrid_client = None\n        \n        if self.sendgrid_key:\n            self.sendgrid_client = SendGridAPIClient(self.sendgrid_key)\n        \n        # Alert history\n        self.alert_history = []\n        self.alert_cooldown = {}  # Prevent spam alerts\n        \n        # Initialize with some historical alerts\n        self._initialize_alert_history()\n    \n    def _initialize_alert_history(self):\n        \"\"\"Initialize with some sample alert history\"\"\"\n        base_time = datetime.now()\n        \n        sample_alerts = [\n            {\n                'timestamp': base_time - timedelta(hours=2),\n                'type': 'High Risk',\n                'message': 'Displacement rate exceeded threshold in Zone 3',\n                'zone': 'Zone_3',\n                'severity': 'high',\n                'channels_used': ['email', 'sms'],\n                'resolved': True\n            },\n            {\n                'timestamp': base_time - timedelta(hours=8),\n                'type': 'Medium Risk',\n                'message': 'Increased pore pressure detected in Zone 7',\n                'zone': 'Zone_7',\n                'severity': 'medium',\n                'channels_used': ['email'],\n                'resolved': True\n            },\n            {\n                'timestamp': base_time - timedelta(days=1),\n                'type': 'Critical',\n                'message': 'Emergency: Rock instability detected in Zone 1',\n                'zone': 'Zone_1',\n                'severity': 'critical',\n                'channels_used': ['sms', 'email', 'siren'],\n                'resolved': True\n            }\n        ]\n        \n        self.alert_history.extend(sample_alerts)\n    \n    def send_sms_alert(self, phone_number, message):\n        \"\"\"Send SMS alert via Twilio\"\"\"\n        if not self.twilio_client:\n            return {\n                'success': False,\n                'error': 'Twilio not configured - missing credentials'\n            }\n        \n        try:\n            message_obj = self.twilio_client.messages.create(\n                body=message,\n                from_=self.twilio_phone,\n                to=phone_number\n            )\n            return {\n                'success': True,\n                'message_sid': message_obj.sid,\n                'message': f'SMS sent successfully to {phone_number}'\n            }\n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Failed to send SMS: {str(e)}'\n            }\n    \n    def send_email_alert(self, email_address, subject, message, from_email=\"alerts@mine-safety.com\"):\n        \"\"\"Send email alert via SendGrid\"\"\"\n        if not self.sendgrid_client:\n            return {\n                'success': False,\n                'error': 'SendGrid not configured - missing API key'\n            }\n        \n        try:\n            mail = Mail(\n                from_email=Email(from_email),\n                to_emails=To(email_address),\n                subject=subject\n            )\n            \n            # Create HTML content\n            html_content = f\"\"\"\n            <html>\n            <body>\n                <h2>Mine Safety Alert</h2>\n                <p><strong>Alert Time:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n                <p><strong>Message:</strong> {message}</p>\n                <hr>\n                <p><em>This is an automated alert from the AI-Based Rockfall Prediction System.</em></p>\n                <p>Please take appropriate action as per safety protocols.</p>\n            </body>\n            </html>\n            \"\"\"\n            \n            mail.content = Content(\"text/html\", html_content)\n            \n            response = self.sendgrid_client.send(mail)\n            return {\n                'success': True,\n                'status_code': response.status_code,\n                'message': f'Email sent successfully to {email_address}'\n            }\n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Failed to send email: {str(e)}'\n            }\n    \n    def trigger_audio_siren(self, zone, severity):\n        \"\"\"Simulate audio siren activation\"\"\"\n        # In a real system, this would interface with physical siren hardware\n        siren_patterns = {\n            'low': 'Single short beep',\n            'medium': '3 short beeps',\n            'high': 'Continuous beeping for 30 seconds',\n            'critical': 'Emergency evacuation siren - continuous for 2 minutes'\n        }\n        \n        pattern = siren_patterns.get(severity, 'Standard alert')\n        \n        return {\n            'success': True,\n            'message': f'Audio siren activated in {zone}',\n            'pattern': pattern,\n            'duration': '30 seconds' if severity in ['high', 'critical'] else '5 seconds'\n        }\n    \n    def trigger_visual_alert(self, zone, severity):\n        \"\"\"Simulate visual alert system\"\"\"\n        # In a real system, this would control LED warning lights, displays, etc.\n        color_codes = {\n            'low': 'Green flashing',\n            'medium': 'Yellow flashing',\n            'high': 'Orange strobing',\n            'critical': 'Red emergency strobing'\n        }\n        \n        visual_pattern = color_codes.get(severity, 'Standard alert')\n        \n        return {\n            'success': True,\n            'message': f'Visual alerts activated in {zone}',\n            'pattern': visual_pattern,\n            'location': f'All display panels in {zone} and surrounding areas'\n        }\n    \n    def send_comprehensive_alert(self, alert_data, phone_number=None, email_address=None, \n                                enable_audio=True, enable_visual=True):\n        \"\"\"Send alert through all configured channels\"\"\"\n        results = []\n        channels_used = []\n        \n        severity = alert_data.get('severity', 'medium')\n        zone = alert_data.get('zone', 'Unknown')\n        message = alert_data.get('message', 'Risk threshold exceeded')\n        \n        # Check cooldown to prevent spam\n        cooldown_key = f\"{zone}_{severity}\"\n        now = datetime.now()\n        if cooldown_key in self.alert_cooldown:\n            if now - self.alert_cooldown[cooldown_key] < timedelta(minutes=15):\n                return {\n                    'success': False,\n                    'error': 'Alert cooldown active - preventing duplicate alerts'\n                }\n        \n        # SMS Alert\n        if phone_number and self.twilio_client:\n            sms_message = f\"MINE ALERT [{severity.upper()}]\\n{message}\\nZone: {zone}\\nTime: {now.strftime('%H:%M')}\"\n            sms_result = self.send_sms_alert(phone_number, sms_message)\n            results.append(('SMS', sms_result))\n            if sms_result['success']:\n                channels_used.append('sms')\n        \n        # Email Alert\n        if email_address and self.sendgrid_client:\n            subject = f\"Mine Safety Alert - {severity.upper()} Risk in {zone}\"\n            email_result = self.send_email_alert(email_address, subject, message)\n            results.append(('Email', email_result))\n            if email_result['success']:\n                channels_used.append('email')\n        \n        # Audio Siren\n        if enable_audio:\n            audio_result = self.trigger_audio_siren(zone, severity)\n            results.append(('Audio Siren', audio_result))\n            if audio_result['success']:\n                channels_used.append('siren')\n        \n        # Visual Alerts\n        if enable_visual:\n            visual_result = self.trigger_visual_alert(zone, severity)\n            results.append(('Visual Alert', visual_result))\n            if visual_result['success']:\n                channels_used.append('visual')\n        \n        # Record in history\n        alert_record = {\n            'timestamp': now,\n            'type': alert_data.get('type', 'Risk Alert'),\n            'message': message,\n            'zone': zone,\n            'severity': severity,\n            'channels_used': channels_used,\n            'resolved': False\n        }\n        self.alert_history.append(alert_record)\n        \n        # Set cooldown\n        self.alert_cooldown[cooldown_key] = now\n        \n        return {\n            'success': True,\n            'message': f'Alert sent via {len(channels_used)} channels',\n            'channels_used': channels_used,\n            'results': results\n        }\n    \n    def send_test_alert(self, alert_type, phone_number=None, email_address=None, \n                       enable_audio=True, enable_visual=True):\n        \"\"\"Send a test alert\"\"\"\n        test_alert_data = {\n            'type': f'Test {alert_type}',\n            'message': f'This is a test {alert_type.lower()} alert from the rockfall prediction system',\n            'zone': 'Test_Zone',\n            'severity': alert_type.lower().replace(' ', '_')\n        }\n        \n        return self.send_comprehensive_alert(\n            test_alert_data, phone_number, email_address, enable_audio, enable_visual\n        )\n    \n    def get_alert_history(self, limit=50):\n        \"\"\"Get recent alert history\"\"\"\n        return sorted(self.alert_history, key=lambda x: x['timestamp'], reverse=True)[:limit]\n    \n    def get_alert_statistics(self, days=7):\n        \"\"\"Get alert statistics for the specified period\"\"\"\n        cutoff_date = datetime.now() - timedelta(days=days)\n        recent_alerts = [alert for alert in self.alert_history if alert['timestamp'] > cutoff_date]\n        \n        stats = {\n            'total_alerts': len(recent_alerts),\n            'by_severity': {},\n            'by_zone': {},\n            'channels_effectiveness': {}\n        }\n        \n        # Count by severity\n        for alert in recent_alerts:\n            severity = alert['severity']\n            stats['by_severity'][severity] = stats['by_severity'].get(severity, 0) + 1\n        \n        # Count by zone\n        for alert in recent_alerts:\n            zone = alert['zone']\n            stats['by_zone'][zone] = stats['by_zone'].get(zone, 0) + 1\n        \n        # Channel effectiveness\n        for alert in recent_alerts:\n            for channel in alert['channels_used']:\n                stats['channels_effectiveness'][channel] = stats['channels_effectiveness'].get(channel, 0) + 1\n        \n        return stats\n    \n    def generate_action_plan(self, risk_level, zone_data):\n        \"\"\"Generate automated action plan based on risk level\"\"\"\n        action_plans = {\n            'low': {\n                'immediate_actions': [\n                    'Continue normal monitoring',\n                    'Log incident in daily reports',\n                    'Schedule routine inspection within 24 hours'\n                ],\n                'personnel': 'Shift supervisor',\n                'equipment': 'Standard monitoring equipment',\n                'timeline': 'Next regular inspection cycle'\n            },\n            'medium': {\n                'immediate_actions': [\n                    'Increase monitoring frequency to every 2 hours',\n                    'Notify shift supervisor and safety officer',\n                    'Restrict non-essential personnel from zone',\n                    'Deploy additional sensors if available'\n                ],\n                'personnel': 'Safety officer, geotechnical engineer',\n                'equipment': 'Additional displacement sensors, weather monitoring',\n                'timeline': 'Within 2 hours'\n            },\n            'high': {\n                'immediate_actions': [\n                    'Evacuate non-essential personnel immediately',\n                    'Continuous monitoring - no breaks',\n                    'Alert mine manager and emergency response team',\n                    'Prepare evacuation routes',\n                    'Stop operations in affected zone'\n                ],\n                'personnel': 'Mine manager, emergency response team, geotechnical specialist',\n                'equipment': 'Emergency communication, backup monitoring systems',\n                'timeline': 'Immediate - within 30 minutes'\n            },\n            'critical': {\n                'immediate_actions': [\n                    'EVACUATE ALL PERSONNEL FROM ZONE IMMEDIATELY',\n                    'Sound general alarm',\n                    'Contact emergency services',\n                    'Implement emergency response protocol',\n                    'Stop all operations in mine',\n                    'Account for all personnel'\n                ],\n                'personnel': 'All emergency response personnel, external emergency services',\n                'equipment': 'Emergency evacuation equipment, medical support',\n                'timeline': 'IMMEDIATE - no delay'\n            }\n        }\n        \n        return action_plans.get(risk_level, action_plans['medium'])\n","size_bytes":13536},"attached_assets/extracted/MineRockGuard/analysis/historical_analysis.py":{"content":"import numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom datetime import datetime, timedelta\nimport json\nimport os\nfrom openai import OpenAI\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nclass HistoricalAnalysis:\n    def __init__(self):\n        self.analysis_cache = {}\n        self.correlation_threshold = 0.3\n        \n        # Initialize OpenAI for advanced analysis\n        self.openai_client = None\n        if os.getenv(\"OPENAI_API_KEY\"):\n            self.openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n    \n    def generate_historical_data(self, days=90):\n        \"\"\"Generate comprehensive historical data for analysis\"\"\"\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=days)\n        \n        # Generate daily data points\n        date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n        historical_records = []\n        \n        for date in date_range:\n            # Simulate seasonal effects\n            day_of_year = date.timetuple().tm_yday\n            seasonal_factor = 0.3 * np.sin(2 * np.pi * day_of_year / 365)\n            \n            # Simulate weather patterns\n            if day_of_year > 90 and day_of_year < 270:  # Spring/Summer\n                temp_base = 20\n                rainfall_prob = 0.3\n            else:  # Fall/Winter\n                temp_base = 5\n                rainfall_prob = 0.6\n            \n            # Generate daily summary data\n            daily_record = {\n                'date': date,\n                'day_of_year': day_of_year,\n                'month': date.month,\n                'season': self._get_season(date.month),\n                'average_risk': max(0, min(1, 0.4 + seasonal_factor + np.random.normal(0, 0.15))),\n                'max_risk': max(0, min(1, 0.6 + seasonal_factor + np.random.normal(0, 0.2))),\n                'temperature': temp_base + np.random.normal(0, 8),\n                'rainfall': max(0, np.random.exponential(5) if np.random.random() < rainfall_prob else 0),\n                'wind_speed': max(0, np.random.gamma(2, 3)),\n                'humidity': np.random.uniform(40, 90),\n                'atmospheric_pressure': np.random.normal(1013, 15),\n                'active_sensors': np.random.randint(42, 48),\n                'alerts_triggered': np.random.poisson(2),\n                'high_risk_zones': np.random.randint(0, 5),\n                'critical_incidents': 1 if np.random.random() < 0.02 else 0,  # 2% chance per day\n                'maintenance_events': 1 if np.random.random() < 0.1 else 0,   # 10% chance per day\n                'equipment_downtime': np.random.exponential(0.5),  # hours\n                'seismic_activity': np.random.gamma(1, 0.5),  # relative scale\n                'ground_moisture': np.random.uniform(10, 60),  # percentage\n                'slope_displacement': np.random.uniform(0, 3),  # mm/day\n                'vibration_events': np.random.poisson(5),\n                'weather_severity': self._calculate_weather_severity(temp_base, rainfall_prob)\n            }\n            \n            # Add correlations between factors\n            if daily_record['rainfall'] > 10:  # Heavy rain\n                daily_record['average_risk'] = min(1, daily_record['average_risk'] * 1.3)\n                daily_record['ground_moisture'] = min(100, daily_record['ground_moisture'] * 1.5)\n                daily_record['slope_displacement'] *= 1.4\n            \n            if daily_record['temperature'] < 0:  # Freezing\n                daily_record['average_risk'] = min(1, daily_record['average_risk'] * 1.2)\n            \n            if daily_record['seismic_activity'] > 2:  # High seismic activity\n                daily_record['vibration_events'] *= 2\n                daily_record['average_risk'] = min(1, daily_record['average_risk'] * 1.5)\n            \n            historical_records.append(daily_record)\n        \n        return pd.DataFrame(historical_records)\n    \n    def _get_season(self, month):\n        \"\"\"Determine season based on month\"\"\"\n        if month in [12, 1, 2]:\n            return 'Winter'\n        elif month in [3, 4, 5]:\n            return 'Spring'\n        elif month in [6, 7, 8]:\n            return 'Summer'\n        else:\n            return 'Fall'\n    \n    def _calculate_weather_severity(self, temp_base, rainfall_prob):\n        \"\"\"Calculate weather severity index\"\"\"\n        temp_severity = abs(temp_base - 15) / 20  # Optimal around 15¬∞C\n        rain_severity = rainfall_prob\n        return min(1, (temp_severity + rain_severity) / 2)\n    \n    def create_risk_timeline(self, historical_data):\n        \"\"\"Create comprehensive risk timeline visualization\"\"\"\n        fig = go.Figure()\n        \n        # Main risk trend line\n        fig.add_trace(go.Scatter(\n            x=historical_data['date'],\n            y=historical_data['average_risk'],\n            mode='lines',\n            name='Average Daily Risk',\n            line=dict(color='blue', width=2),\n            hovertemplate='Date: %{x}<br>Risk: %{y:.2%}<extra></extra>'\n        ))\n        \n        # Maximum risk trend\n        fig.add_trace(go.Scatter(\n            x=historical_data['date'],\n            y=historical_data['max_risk'],\n            mode='lines',\n            name='Maximum Daily Risk',\n            line=dict(color='red', width=1, dash='dash'),\n            hovertemplate='Date: %{x}<br>Max Risk: %{y:.2%}<extra></extra>'\n        ))\n        \n        # Critical incidents markers\n        critical_dates = historical_data[historical_data['critical_incidents'] > 0]['date']\n        critical_risks = historical_data[historical_data['critical_incidents'] > 0]['average_risk']\n        \n        if len(critical_dates) > 0:\n            fig.add_trace(go.Scatter(\n                x=critical_dates,\n                y=critical_risks,\n                mode='markers',\n                name='Critical Incidents',\n                marker=dict(color='red', size=12, symbol='triangle-up'),\n                hovertemplate='Critical Incident<br>Date: %{x}<br>Risk Level: %{y:.2%}<extra></extra>'\n            ))\n        \n        # Add moving average\n        window = 7  # 7-day moving average\n        if len(historical_data) >= window:\n            moving_avg = historical_data['average_risk'].rolling(window=window).mean()\n            fig.add_trace(go.Scatter(\n                x=historical_data['date'],\n                y=moving_avg,\n                mode='lines',\n                name=f'{window}-Day Moving Average',\n                line=dict(color='green', width=2, dash='dot'),\n                hovertemplate='Date: %{x}<br>Moving Avg: %{y:.2%}<extra></extra>'\n            ))\n        \n        # Risk threshold lines\n        fig.add_hline(y=0.85, line_dash=\"dash\", line_color=\"red\", \n                     annotation_text=\"Critical Threshold (85%)\")\n        fig.add_hline(y=0.7, line_dash=\"dash\", line_color=\"orange\", \n                     annotation_text=\"High Risk Threshold (70%)\")\n        fig.add_hline(y=0.3, line_dash=\"dash\", line_color=\"yellow\", \n                     annotation_text=\"Medium Risk Threshold (30%)\")\n        \n        fig.update_layout(\n            title=\"Historical Risk Analysis Timeline\",\n            xaxis_title=\"Date\",\n            yaxis_title=\"Risk Level\",\n            yaxis=dict(range=[0, 1], tickformat='.0%'),\n            hovermode='x unified',\n            height=500\n        )\n        \n        return fig\n    \n    def create_seasonal_analysis(self, historical_data):\n        \"\"\"Create seasonal pattern analysis\"\"\"\n        # Group by season and calculate statistics\n        seasonal_stats = historical_data.groupby('season').agg({\n            'average_risk': ['mean', 'std', 'max'],\n            'rainfall': ['mean', 'sum'],\n            'temperature': ['mean', 'min', 'max'],\n            'alerts_triggered': 'sum',\n            'critical_incidents': 'sum'\n        }).round(3)\n        \n        # Flatten column names\n        seasonal_stats.columns = ['_'.join(col).strip() for col in seasonal_stats.columns]\n        seasonal_stats.reset_index(inplace=True)\n        \n        # Create subplot figure\n        from plotly.subplots import make_subplots\n        \n        fig = make_subplots(\n            rows=2, cols=2,\n            subplot_titles=('Seasonal Risk Patterns', 'Temperature Variations', \n                          'Rainfall Patterns', 'Incident Frequency'),\n            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n        )\n        \n        seasons = seasonal_stats['season']\n        \n        # Risk patterns\n        fig.add_trace(\n            go.Bar(x=seasons, y=seasonal_stats['average_risk_mean'], \n                   name='Avg Risk', marker_color='lightblue'),\n            row=1, col=1\n        )\n        \n        # Temperature variations\n        fig.add_trace(\n            go.Bar(x=seasons, y=seasonal_stats['temperature_mean'], \n                   name='Avg Temp', marker_color='orange'),\n            row=1, col=2\n        )\n        \n        # Rainfall patterns\n        fig.add_trace(\n            go.Bar(x=seasons, y=seasonal_stats['rainfall_sum'], \n                   name='Total Rainfall', marker_color='blue'),\n            row=2, col=1\n        )\n        \n        # Incident frequency\n        fig.add_trace(\n            go.Bar(x=seasons, y=seasonal_stats['critical_incidents_sum'], \n                   name='Critical Incidents', marker_color='red'),\n            row=2, col=2\n        )\n        \n        fig.update_layout(\n            title=\"Seasonal Analysis Dashboard\",\n            height=600,\n            showlegend=False\n        )\n        \n        return fig\n    \n    def calculate_correlations(self, historical_data):\n        \"\"\"Calculate correlation matrix for key variables\"\"\"\n        # Select numerical columns for correlation analysis\n        correlation_vars = [\n            'average_risk', 'max_risk', 'temperature', 'rainfall', \n            'wind_speed', 'humidity', 'atmospheric_pressure', \n            'seismic_activity', 'ground_moisture', 'slope_displacement',\n            'vibration_events', 'weather_severity'\n        ]\n        \n        correlation_data = historical_data[correlation_vars].corr()\n        \n        return correlation_data\n    \n    def identify_risk_patterns(self, historical_data):\n        \"\"\"Identify patterns and anomalies in risk data\"\"\"\n        patterns = {\n            'trend_analysis': {},\n            'cyclical_patterns': {},\n            'anomalies': [],\n            'risk_factors': {}\n        }\n        \n        # Trend analysis\n        risk_series = historical_data['average_risk'].values\n        dates_numeric = np.arange(len(risk_series))\n        \n        # Linear trend\n        slope, intercept, r_value, p_value, std_err = stats.linregress(dates_numeric, risk_series)\n        patterns['trend_analysis'] = {\n            'slope': slope,\n            'direction': 'increasing' if slope > 0 else 'decreasing',\n            'strength': abs(r_value),\n            'significance': p_value < 0.05\n        }\n        \n        # Cyclical patterns (using FFT)\n        from scipy.fft import fft, fftfreq\n        \n        fft_values = fft(risk_series - np.mean(risk_series))\n        frequencies = fftfreq(len(risk_series))\n        \n        # Find dominant frequencies\n        magnitude = np.abs(fft_values)\n        dominant_freq_idx = np.argsort(magnitude)[-5:]  # Top 5 frequencies\n        \n        patterns['cyclical_patterns'] = {\n            'dominant_periods': [1/abs(float(frequencies[i])) if frequencies[i] != 0 else float('inf') \n                               for i in dominant_freq_idx if frequencies[i] != 0],\n            'strength': [float(magnitude[i]) for i in dominant_freq_idx]\n        }\n        \n        # Anomaly detection using z-score\n        z_scores = np.abs(stats.zscore(risk_series))\n        anomaly_threshold = 2.5\n        anomaly_indices = np.where(z_scores > anomaly_threshold)[0]\n        \n        patterns['anomalies'] = [\n            {\n                'date': historical_data.iloc[i]['date'].strftime('%Y-%m-%d'),\n                'risk_level': risk_series[i],\n                'z_score': z_scores[i],\n                'context': self._analyze_anomaly_context(historical_data.iloc[i])\n            }\n            for i in anomaly_indices\n        ]\n        \n        # Risk factor analysis\n        risk_correlations = historical_data.corr()['average_risk'].abs().sort_values(ascending=False)\n        patterns['risk_factors'] = {\n            factor: correlation for factor, correlation in risk_correlations.items()\n            if factor != 'average_risk' and abs(correlation) > self.correlation_threshold\n        }\n        \n        return patterns\n    \n    def _analyze_anomaly_context(self, data_point):\n        \"\"\"Analyze context around anomalous risk levels\"\"\"\n        context = []\n        \n        if data_point['rainfall'] > 15:\n            context.append('Heavy rainfall')\n        if data_point['temperature'] < 0:\n            context.append('Freezing temperatures')\n        if data_point['seismic_activity'] > 2:\n            context.append('High seismic activity')\n        if data_point['wind_speed'] > 20:\n            context.append('Strong winds')\n        if data_point['critical_incidents'] > 0:\n            context.append('Critical incident occurred')\n        \n        return context if context else ['No obvious environmental factors']\n    \n    def generate_report(self, historical_data, start_date, end_date, analysis_type):\n        \"\"\"Generate comprehensive analysis report\"\"\"\n        # Filter data by date range\n        filtered_data = historical_data[\n            (historical_data['date'] >= pd.to_datetime(start_date)) &\n            (historical_data['date'] <= pd.to_datetime(end_date))\n        ]\n        \n        report = {\n            'analysis_period': f\"{start_date} to {end_date}\",\n            'total_days': len(filtered_data),\n            'analysis_type': analysis_type,\n            'generated_at': datetime.now().isoformat()\n        }\n        \n        if analysis_type == \"Risk Trends\":\n            report.update(self._generate_risk_trends_report(filtered_data))\n        elif analysis_type == \"Sensor Performance\":\n            report.update(self._generate_sensor_performance_report(filtered_data))\n        elif analysis_type == \"Alert Frequency\":\n            report.update(self._generate_alert_frequency_report(filtered_data))\n        elif analysis_type == \"Environmental Impact\":\n            report.update(self._generate_environmental_impact_report(filtered_data))\n        \n        # Add AI analysis if available\n        if self.openai_client:\n            ai_insights = self._get_ai_insights(filtered_data, analysis_type)\n            report['ai_insights'] = ai_insights\n        \n        return report\n    \n    def _generate_risk_trends_report(self, data):\n        \"\"\"Generate risk trends analysis report\"\"\"\n        return {\n            'average_risk_level': f\"{data['average_risk'].mean():.1%}\",\n            'peak_risk_level': f\"{data['max_risk'].max():.1%}\",\n            'high_risk_days': len(data[data['average_risk'] > 0.7]),\n            'risk_volatility': f\"{data['average_risk'].std():.3f}\",\n            'trend_direction': 'Increasing' if data['average_risk'].iloc[-1] > data['average_risk'].iloc[0] else 'Decreasing',\n            'critical_incidents': data['critical_incidents'].sum(),\n            'risk_trend_slope': np.polyfit(range(len(data)), data['average_risk'], 1)[0]\n        }\n    \n    def _generate_sensor_performance_report(self, data):\n        \"\"\"Generate sensor performance report\"\"\"\n        return {\n            'average_active_sensors': f\"{data['active_sensors'].mean():.0f}\",\n            'sensor_availability': f\"{(data['active_sensors'].mean() / 47) * 100:.1f}%\",\n            'lowest_sensor_count': data['active_sensors'].min(),\n            'maintenance_events': data['maintenance_events'].sum(),\n            'equipment_downtime_hours': f\"{data['equipment_downtime'].sum():.1f}\",\n            'sensor_reliability_score': f\"{(1 - data['equipment_downtime'].mean() / 24) * 100:.1f}%\"\n        }\n    \n    def _generate_alert_frequency_report(self, data):\n        \"\"\"Generate alert frequency analysis report\"\"\"\n        return {\n            'total_alerts': data['alerts_triggered'].sum(),\n            'average_daily_alerts': f\"{data['alerts_triggered'].mean():.1f}\",\n            'peak_alert_day': data['alerts_triggered'].max(),\n            'alert_free_days': len(data[data['alerts_triggered'] == 0]),\n            'high_alert_days': len(data[data['alerts_triggered'] > 5]),\n            'alert_efficiency_ratio': f\"{(data['critical_incidents'].sum() / max(1, data['alerts_triggered'].sum())) * 100:.1f}%\"\n        }\n    \n    def _generate_environmental_impact_report(self, data):\n        \"\"\"Generate environmental impact analysis report\"\"\"\n        rainfall_correlation = data['rainfall'].corr(data['average_risk'])\n        temp_correlation = data['temperature'].corr(data['average_risk'])\n        \n        return {\n            'rainfall_impact_correlation': f\"{rainfall_correlation:.3f}\",\n            'temperature_impact_correlation': f\"{temp_correlation:.3f}\",\n            'high_rainfall_days': len(data[data['rainfall'] > 10]),\n            'extreme_weather_days': len(data[data['weather_severity'] > 0.7]),\n            'weather_related_incidents': data[data['weather_severity'] > 0.5]['critical_incidents'].sum(),\n            'seasonal_risk_variation': f\"{data.groupby('season')['average_risk'].std().mean():.3f}\"\n        }\n    \n    def _get_ai_insights(self, data, analysis_type):\n        \"\"\"Get AI-powered insights using OpenAI\"\"\"\n        try:\n            # Prepare data summary for AI analysis\n            data_summary = {\n                'period': f\"{len(data)} days\",\n                'avg_risk': float(data['average_risk'].mean()),\n                'max_risk': float(data['max_risk'].max()),\n                'critical_incidents': int(data['critical_incidents'].sum()),\n                'environmental_factors': {\n                    'avg_rainfall': float(data['rainfall'].mean()),\n                    'avg_temperature': float(data['temperature'].mean()),\n                    'seismic_activity': float(data['seismic_activity'].mean())\n                },\n                'correlations': {\n                    'rainfall_risk': float(data['rainfall'].corr(data['average_risk'])),\n                    'temperature_risk': float(data['temperature'].corr(data['average_risk'])),\n                    'seismic_risk': float(data['seismic_activity'].corr(data['average_risk']))\n                }\n            }\n            \n            prompt = f\"\"\"\n            Analyze the following mine safety data for {analysis_type} and provide insights:\n            \n            Data Summary: {json.dumps(data_summary, indent=2)}\n            \n            Please provide:\n            1. Key findings and patterns\n            2. Risk assessment insights\n            3. Recommendations for improving safety\n            4. Predictive insights for future monitoring\n            \n            Focus on actionable insights for mine operators. Respond in JSON format.\n            \"\"\"\n            \n            # the newest OpenAI model is \"gpt-5\" which was released August 7, 2025.\n            # do not change this unless explicitly requested by the user\n            response = self.openai_client.chat.completions.create(\n                model=\"gpt-5\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                response_format={\"type\": \"json_object\"}\n            )\n            \n            content = response.choices[0].message.content\n            if content:\n                return json.loads(content)\n            else:\n                return {\"error\": \"Empty response from AI analysis\"}\n            \n        except Exception as e:\n            return {\"error\": f\"AI analysis unavailable: {str(e)}\"}\n    \n    def create_predictive_model_performance(self, historical_data):\n        \"\"\"Analyze and visualize predictive model performance over time\"\"\"\n        # Simulate model prediction accuracy over time\n        dates = historical_data['date']\n        \n        # Simulate different model performance metrics\n        accuracy_trend = 0.85 + 0.1 * np.sin(np.arange(len(dates)) * 2 * np.pi / 30) + np.random.normal(0, 0.02, len(dates))\n        precision_trend = 0.82 + 0.08 * np.sin(np.arange(len(dates)) * 2 * np.pi / 45) + np.random.normal(0, 0.015, len(dates))\n        recall_trend = 0.88 + 0.06 * np.sin(np.arange(len(dates)) * 2 * np.pi / 60) + np.random.normal(0, 0.02, len(dates))\n        \n        # Ensure values stay within realistic bounds\n        accuracy_trend = np.clip(accuracy_trend, 0.7, 0.95)\n        precision_trend = np.clip(precision_trend, 0.7, 0.95)\n        recall_trend = np.clip(recall_trend, 0.75, 0.95)\n        \n        fig = go.Figure()\n        \n        fig.add_trace(go.Scatter(\n            x=dates, y=accuracy_trend,\n            mode='lines', name='Accuracy',\n            line=dict(color='blue', width=2)\n        ))\n        \n        fig.add_trace(go.Scatter(\n            x=dates, y=precision_trend,\n            mode='lines', name='Precision',\n            line=dict(color='green', width=2)\n        ))\n        \n        fig.add_trace(go.Scatter(\n            x=dates, y=recall_trend,\n            mode='lines', name='Recall',\n            line=dict(color='red', width=2)\n        ))\n        \n        fig.update_layout(\n            title=\"Predictive Model Performance Over Time\",\n            xaxis_title=\"Date\",\n            yaxis_title=\"Performance Metric\",\n            yaxis=dict(range=[0.6, 1.0], tickformat='.0%'),\n            hovermode='x unified'\n        )\n        \n        return fig\n    \n    def analyze_maintenance_effectiveness(self, historical_data):\n        \"\"\"Analyze the effectiveness of maintenance activities\"\"\"\n        # Find periods before and after maintenance events\n        maintenance_days = historical_data[historical_data['maintenance_events'] > 0]\n        \n        effectiveness_analysis = []\n        \n        for _, maintenance_day in maintenance_days.iterrows():\n            maintenance_date = maintenance_day['date']\n            \n            # Get 7 days before and after maintenance\n            before_period = historical_data[\n                (historical_data['date'] >= maintenance_date - timedelta(days=7)) &\n                (historical_data['date'] < maintenance_date)\n            ]\n            \n            after_period = historical_data[\n                (historical_data['date'] > maintenance_date) &\n                (historical_data['date'] <= maintenance_date + timedelta(days=7))\n            ]\n            \n            if len(before_period) > 0 and len(after_period) > 0:\n                risk_before = before_period['average_risk'].mean()\n                risk_after = after_period['average_risk'].mean()\n                risk_reduction = risk_before - risk_after\n                \n                effectiveness_analysis.append({\n                    'maintenance_date': maintenance_date,\n                    'risk_before': risk_before,\n                    'risk_after': risk_after,\n                    'risk_reduction': risk_reduction,\n                    'effectiveness_score': max(0, risk_reduction / risk_before) if risk_before > 0 else 0\n                })\n        \n        if effectiveness_analysis:\n            avg_effectiveness = np.mean([a['effectiveness_score'] for a in effectiveness_analysis])\n            total_risk_reduction = sum([a['risk_reduction'] for a in effectiveness_analysis])\n            \n            return {\n                'maintenance_events_analyzed': len(effectiveness_analysis),\n                'average_effectiveness_score': f\"{avg_effectiveness:.1%}\",\n                'total_risk_reduction': f\"{total_risk_reduction:.3f}\",\n                'most_effective_date': max(effectiveness_analysis, key=lambda x: x['effectiveness_score'])['maintenance_date'].strftime('%Y-%m-%d'),\n                'recommendations': self._generate_maintenance_recommendations(effectiveness_analysis)\n            }\n        else:\n            return {\n                'maintenance_events_analyzed': 0,\n                'message': 'Insufficient data for maintenance effectiveness analysis'\n            }\n    \n    def _generate_maintenance_recommendations(self, effectiveness_data):\n        \"\"\"Generate maintenance recommendations based on effectiveness analysis\"\"\"\n        recommendations = []\n        \n        avg_effectiveness = np.mean([a['effectiveness_score'] for a in effectiveness_data])\n        \n        if avg_effectiveness < 0.3:\n            recommendations.append(\"Maintenance procedures may need review - low effectiveness detected\")\n        \n        if avg_effectiveness > 0.7:\n            recommendations.append(\"Current maintenance approach is highly effective - continue current practices\")\n        \n        # Find seasonal patterns in maintenance effectiveness\n        seasonal_effectiveness = {}\n        for analysis in effectiveness_data:\n            month = analysis['maintenance_date'].month\n            season = self._get_season(month)\n            if season not in seasonal_effectiveness:\n                seasonal_effectiveness[season] = []\n            seasonal_effectiveness[season].append(analysis['effectiveness_score'])\n        \n        if seasonal_effectiveness:\n            best_season = max(seasonal_effectiveness.keys(), \n                            key=lambda s: np.mean(seasonal_effectiveness[s]))\n            recommendations.append(f\"Maintenance appears most effective during {best_season}\")\n        \n        return recommendations\n\n","size_bytes":25653},"attached_assets/extracted/MineRockGuard/communication/lorawan_simulator.py":{"content":"import numpy as np\nimport random\nfrom datetime import datetime, timedelta\nimport json\n\nclass LoRaWANSimulator:\n    def __init__(self):\n        self.gateways = self._initialize_gateways()\n        self.devices = self._initialize_devices()\n        self.radio_channels = self._initialize_radio_channels()\n        self.network_status = {\n            'uptime': 0.995,\n            'total_messages': 0,\n            'failed_messages': 0,\n            'last_update': datetime.now()\n        }\n    \n    def _initialize_gateways(self):\n        \"\"\"Initialize LoRaWAN gateways around the mine site\"\"\"\n        gateways = []\n        \n        # Main gateways positioned strategically around the mine\n        gateway_positions = [\n            {'id': 'GW001', 'name': 'North Ridge', 'lat': 45.128, 'lon': -123.451, 'elevation': 1350},\n            {'id': 'GW002', 'name': 'South Access', 'lat': 45.118, 'lon': -123.461, 'elevation': 1280},\n            {'id': 'GW003', 'name': 'East Monitor', 'lat': 45.123, 'lon': -123.446, 'elevation': 1320},\n            {'id': 'GW004', 'name': 'West Platform', 'lat': 45.123, 'lon': -123.466, 'elevation': 1300},\n            {'id': 'GW005', 'name': 'Central Hub', 'lat': 45.123, 'lon': -123.456, 'elevation': 1250}\n        ]\n        \n        for gw_pos in gateway_positions:\n            gateway = {\n                'id': gw_pos['id'],\n                'name': gw_pos['name'],\n                'coordinates': {\n                    'lat': gw_pos['lat'],\n                    'lon': gw_pos['lon'], \n                    'elevation': gw_pos['elevation']\n                },\n                'status': 'online' if np.random.random() > 0.05 else 'offline',\n                'signal_strength': np.random.uniform(-60, -40),  # dBm\n                'coverage_radius': np.random.uniform(800, 1200),  # meters\n                'connected_devices': np.random.randint(8, 15),\n                'battery_backup': np.random.uniform(85, 100),  # %\n                'last_maintenance': datetime.now() - timedelta(days=np.random.randint(1, 45)),\n                'frequency_band': 'EU868' if np.random.random() > 0.5 else 'US915',\n                'data_rate': f'SF{np.random.randint(7, 12)}',  # Spreading Factor\n                'power_output': np.random.uniform(14, 20)  # dBm\n            }\n            gateways.append(gateway)\n        \n        return gateways\n    \n    def _initialize_devices(self):\n        \"\"\"Initialize LoRaWAN devices (sensors)\"\"\"\n        devices = []\n        \n        for i in range(47):  # 47 sensors as per requirements\n            device = {\n                'id': f\"DEV{i+1:03d}\",\n                'sensor_id': f\"S{i+1:03d}\",\n                'device_type': np.random.choice(['Class A', 'Class B', 'Class C']),\n                'connected_gateway': np.random.choice([gw['id'] for gw in self.gateways]),\n                'battery_level': np.random.uniform(20, 100),\n                'signal_strength': np.random.uniform(-120, -70),  # dBm\n                'uplink_count': np.random.randint(1000, 50000),\n                'downlink_count': np.random.randint(10, 500),\n                'last_seen': datetime.now() - timedelta(minutes=np.random.randint(1, 30)),\n                'data_rate': f'SF{np.random.randint(7, 12)}',\n                'frequency': np.random.uniform(867.1, 868.5),  # MHz for EU868\n                'transmission_power': np.random.randint(2, 14),  # dBm\n                'adr_enabled': np.random.choice([True, False]),  # Adaptive Data Rate\n                'join_status': 'joined' if np.random.random() > 0.02 else 'joining',\n                'packet_loss_rate': np.random.uniform(0, 0.15)\n            }\n            devices.append(device)\n        \n        return devices\n    \n    def _initialize_radio_channels(self):\n        \"\"\"Initialize radio communication channels for backup\"\"\"\n        channels = []\n        \n        # VHF channels for emergency communication\n        vhf_channels = [\n            {'id': 'VHF001', 'frequency': 151.4, 'name': 'Emergency Primary'},\n            {'id': 'VHF002', 'frequency': 154.5, 'name': 'Operations'},\n            {'id': 'VHF003', 'frequency': 158.7, 'name': 'Maintenance'},\n            {'id': 'VHF004', 'frequency': 162.3, 'name': 'Security'}\n        ]\n        \n        # UHF channels for data communication\n        uhf_channels = [\n            {'id': 'UHF001', 'frequency': 450.2, 'name': 'Data Backup 1'},\n            {'id': 'UHF002', 'frequency': 455.8, 'name': 'Data Backup 2'},\n            {'id': 'UHF003', 'frequency': 460.1, 'name': 'Telemetry'}\n        ]\n        \n        all_channels = vhf_channels + uhf_channels\n        \n        for channel in all_channels:\n            channel.update({\n                'status': 'active' if np.random.random() > 0.1 else 'standby',\n                'power_output': np.random.uniform(5, 25),  # Watts\n                'range': np.random.uniform(5, 15),  # km\n                'noise_level': np.random.uniform(-110, -90),  # dBm\n                'modulation': 'FM' if 'VHF' in channel['id'] else 'FSK',\n                'bandwidth': 25 if 'VHF' in channel['id'] else 12.5  # kHz\n            })\n        \n        return all_channels\n    \n    def get_network_status(self):\n        \"\"\"Get current LoRaWAN network status\"\"\"\n        online_gateways = sum(1 for gw in self.gateways if gw['status'] == 'online')\n        total_gateways = len(self.gateways)\n        \n        connected_devices = sum(1 for dev in self.devices if dev['join_status'] == 'joined')\n        total_devices = len(self.devices)\n        \n        # Calculate average signal strength\n        avg_signal = np.mean([gw['signal_strength'] for gw in self.gateways if gw['status'] == 'online'])\n        \n        # Calculate network coverage\n        coverage = (online_gateways / total_gateways) * 0.8 + (connected_devices / total_devices) * 0.2\n        \n        return {\n            'network_type': 'LoRaWAN',\n            'coverage': coverage,\n            'gateways': online_gateways,\n            'total_gateways': total_gateways,\n            'devices': connected_devices,\n            'total_devices': total_devices,\n            'signal_strength': avg_signal,\n            'uptime': self.network_status['uptime'],\n            'packet_success_rate': 1 - np.mean([dev.get('packet_loss_rate', 0) for dev in self.devices]),\n            'gateway_list': [\n                {\n                    'id': gw['id'],\n                    'name': gw['name'],\n                    'status': gw['status'],\n                    'signal_strength': gw['signal_strength'],\n                    'connected_devices': gw['connected_devices']\n                }\n                for gw in self.gateways\n            ]\n        }\n    \n    def get_radio_status(self):\n        \"\"\"Get radio communication backup status\"\"\"\n        active_channels = [ch for ch in self.radio_channels if ch['status'] == 'active']\n        \n        if active_channels:\n            avg_power = np.mean([ch['power_output'] for ch in active_channels])\n            avg_range = np.mean([ch['range'] for ch in active_channels])\n            error_rate = np.random.uniform(0.01, 0.05)  # Typical radio error rate\n        else:\n            avg_power = 0\n            avg_range = 0\n            error_rate = 1.0\n        \n        return {\n            'communication_type': 'Radio Backup',\n            'active_channels': len(active_channels),\n            'total_channels': len(self.radio_channels),\n            'frequency': np.mean([ch['frequency'] for ch in active_channels]) if active_channels else 0,\n            'power': avg_power,\n            'range': avg_range,\n            'error_rate': error_rate,\n            'channel_list': [\n                {\n                    'id': ch['id'],\n                    'name': ch['name'],\n                    'frequency': ch['frequency'],\n                    'status': ch['status'],\n                    'power': ch['power_output']\n                }\n                for ch in self.radio_channels\n            ]\n        }\n    \n    def simulate_data_transmission(self, device_id, data_payload):\n        \"\"\"Simulate data transmission through LoRaWAN\"\"\"\n        device = next((dev for dev in self.devices if dev['id'] == device_id), None)\n        \n        if not device:\n            return {\n                'success': False,\n                'error': 'Device not found',\n                'timestamp': datetime.now()\n            }\n        \n        # Find connected gateway\n        gateway = next((gw for gw in self.gateways if gw['id'] == device['connected_gateway']), None)\n        \n        if not gateway or gateway['status'] != 'online':\n            # Try to find alternative gateway\n            online_gateways = [gw for gw in self.gateways if gw['status'] == 'online']\n            if online_gateways:\n                gateway = min(online_gateways, key=lambda x: np.random.random())  # Simulate closest gateway\n                device['connected_gateway'] = gateway['id']\n            else:\n                return {\n                    'success': False,\n                    'error': 'No online gateways available',\n                    'timestamp': datetime.now()\n                }\n        \n        # Simulate transmission success based on signal strength and other factors\n        success_probability = 0.95  # Base success rate\n        \n        # Reduce success based on signal strength\n        if device['signal_strength'] < -110:\n            success_probability *= 0.7\n        elif device['signal_strength'] < -100:\n            success_probability *= 0.85\n        \n        # Reduce success based on battery level\n        if device['battery_level'] < 20:\n            success_probability *= 0.8\n        \n        # Simulate packet loss\n        success_probability *= (1 - device.get('packet_loss_rate', 0.05))\n        \n        transmission_successful = np.random.random() < success_probability\n        \n        if transmission_successful:\n            # Update device statistics\n            device['uplink_count'] += 1\n            device['last_seen'] = datetime.now()\n            \n            # Update network statistics\n            self.network_status['total_messages'] += 1\n            \n            return {\n                'success': True,\n                'gateway_used': gateway['id'],\n                'signal_strength': device['signal_strength'],\n                'data_rate': device['data_rate'],\n                'transmission_time': np.random.uniform(0.1, 2.0),  # seconds\n                'timestamp': datetime.now()\n            }\n        else:\n            # Update failure statistics\n            self.network_status['failed_messages'] += 1\n            \n            return {\n                'success': False,\n                'error': 'Transmission failed',\n                'gateway_attempted': gateway['id'],\n                'signal_strength': device['signal_strength'],\n                'timestamp': datetime.now()\n            }\n    \n    def test_emergency_communication(self):\n        \"\"\"Test emergency communication systems\"\"\"\n        results = {\n            'lorawan_test': False,\n            'radio_test': False,\n            'satellite_test': False,\n            'overall_success': False\n        }\n        \n        # Test LoRaWAN\n        online_gateways = [gw for gw in self.gateways if gw['status'] == 'online']\n        if len(online_gateways) >= 2:  # Need at least 2 gateways for redundancy\n            results['lorawan_test'] = True\n        \n        # Test Radio\n        active_radio_channels = [ch for ch in self.radio_channels if ch['status'] == 'active']\n        if len(active_radio_channels) >= 1:\n            results['radio_test'] = True\n        \n        # Simulate satellite backup (always available but with some probability)\n        results['satellite_test'] = np.random.random() > 0.05  # 95% availability\n        \n        # Overall success if at least one communication method works\n        results['overall_success'] = any([\n            results['lorawan_test'],\n            results['radio_test'],\n            results['satellite_test']\n        ])\n        \n        return results\n    \n    def get_device_status(self, device_id):\n        \"\"\"Get detailed status of a specific device\"\"\"\n        device = next((dev for dev in self.devices if dev['id'] == device_id), None)\n        \n        if not device:\n            return {'error': 'Device not found'}\n        \n        gateway = next((gw for gw in self.gateways if gw['id'] == device['connected_gateway']), None)\n        \n        return {\n            'device_id': device['id'],\n            'sensor_id': device['sensor_id'],\n            'status': 'online' if device['join_status'] == 'joined' else 'offline',\n            'battery_level': device['battery_level'],\n            'signal_strength': device['signal_strength'],\n            'connected_gateway': {\n                'id': gateway['id'] if gateway else 'None',\n                'name': gateway['name'] if gateway else 'None',\n                'status': gateway['status'] if gateway else 'offline'\n            },\n            'communication_stats': {\n                'uplink_count': device['uplink_count'],\n                'downlink_count': device['downlink_count'],\n                'packet_loss_rate': device['packet_loss_rate'],\n                'last_seen': device['last_seen']\n            },\n            'technical_details': {\n                'data_rate': device['data_rate'],\n                'frequency': device['frequency'],\n                'power': device['transmission_power'],\n                'adr_enabled': device['adr_enabled']\n            }\n        }\n    \n    def simulate_network_failure(self, failure_type='gateway_failure'):\n        \"\"\"Simulate various network failure scenarios\"\"\"\n        if failure_type == 'gateway_failure':\n            # Simulate random gateway failure\n            online_gateways = [gw for gw in self.gateways if gw['status'] == 'online']\n            if online_gateways:\n                failed_gateway = np.random.choice(online_gateways)\n                failed_gateway['status'] = 'offline'\n                \n                # Reassign devices to other gateways\n                affected_devices = [dev for dev in self.devices if dev['connected_gateway'] == failed_gateway['id']]\n                remaining_gateways = [gw for gw in self.gateways if gw['status'] == 'online']\n                \n                for device in affected_devices:\n                    if remaining_gateways:\n                        device['connected_gateway'] = np.random.choice(remaining_gateways)['id']\n                    else:\n                        device['join_status'] = 'joining'  # No available gateways\n        \n        elif failure_type == 'interference':\n            # Simulate radio interference affecting signal quality\n            for device in self.devices:\n                device['signal_strength'] -= np.random.uniform(5, 15)\n                device['packet_loss_rate'] = min(0.5, device['packet_loss_rate'] + np.random.uniform(0.05, 0.2))\n        \n        elif failure_type == 'power_outage':\n            # Simulate power outage affecting gateways without backup\n            for gateway in self.gateways:\n                if gateway['battery_backup'] < 50:  # Gateways with low backup\n                    gateway['status'] = 'offline'\n        \n        return {\n            'failure_type': failure_type,\n            'timestamp': datetime.now(),\n            'affected_components': self._count_affected_components()\n        }\n    \n    def _count_affected_components(self):\n        \"\"\"Count affected network components\"\"\"\n        offline_gateways = sum(1 for gw in self.gateways if gw['status'] == 'offline')\n        disconnected_devices = sum(1 for dev in self.devices if dev['join_status'] != 'joined')\n        \n        return {\n            'offline_gateways': offline_gateways,\n            'disconnected_devices': disconnected_devices,\n            'network_coverage': 1 - (offline_gateways / len(self.gateways))\n        }\n","size_bytes":15878},"attached_assets/extracted/MineRockGuard/dashboard/real_time_dashboard.py":{"content":"import plotly.graph_objects as go\nimport plotly.express as px\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass RealTimeDashboard:\n    def __init__(self):\n        self.color_scheme = {\n            'low': '#00FF00',      # Green\n            'medium': '#FFFF00',   # Yellow  \n            'high': '#FF8000',     # Orange\n            'critical': '#FF0000'  # Red\n        }\n        \n    def create_risk_heatmap(self, data):\n        \"\"\"Create risk heatmap for the mine site\"\"\"\n        sensors = data['sensors']\n        \n        # Extract coordinates and risk levels\n        lats = []\n        lons = []\n        risks = []\n        sensor_ids = []\n        zones = []\n        \n        for sensor in sensors:\n            if sensor['status'] == 'online':\n                coords = sensor['coordinates']\n                lats.append(coords['lat'])\n                lons.append(coords['lon'])\n                risks.append(sensor['risk_probability'])\n                sensor_ids.append(sensor['id'])\n                zones.append(sensor['zone'])\n        \n        # Create the heatmap\n        fig = go.Figure()\n        \n        # Add scatter plot for sensors\n        fig.add_trace(go.Scatter(\n            x=lons,\n            y=lats,\n            mode='markers',\n            marker=dict(\n                size=[max(10, r * 30) for r in risks],  # Size based on risk\n                color=risks,\n                colorscale='RdYlGn_r',  # Reverse Red-Yellow-Green\n                showscale=True,\n                colorbar=dict(\n                    title=dict(text=\"Risk Level\", side=\"right\"),\n                    tickmode=\"array\",\n                    tickvals=[0, 0.3, 0.7, 0.85, 1.0],\n                    ticktext=[\"0%\", \"30%\", \"70%\", \"85%\", \"100%\"]\n                ),\n                cmin=0,\n                cmax=1,\n                opacity=0.8\n            ),\n            text=[f\"Sensor: {sid}<br>Zone: {zone}<br>Risk: {risk:.1%}\" \n                  for sid, zone, risk in zip(sensor_ids, zones, risks)],\n            hovertemplate='%{text}<br>Coordinates: (%{x:.6f}, %{y:.6f})<extra></extra>',\n            name='Sensors'\n        ))\n        \n        # Add zone boundaries (simplified representation)\n        zone_centers = self._calculate_zone_centers(sensors)\n        for zone_name, center in zone_centers.items():\n            if center['risk'] > 0.3:  # Only show zones with elevated risk\n                # Create circular zone boundary\n                theta = np.linspace(0, 2*np.pi, 20)\n                radius = 0.002  # Degrees (roughly 200m)\n                zone_lats = center['lat'] + radius * np.cos(theta)\n                zone_lons = center['lon'] + radius * np.sin(theta)\n                \n                # Determine zone color based on risk\n                zone_color = self._get_risk_color(center['risk'])\n                \n                fig.add_trace(go.Scatter(\n                    x=zone_lons,\n                    y=zone_lats,\n                    mode='lines',\n                    line=dict(color=zone_color, width=3, dash='dash'),\n                    fill='toself',\n                    fillcolor=zone_color,\n                    opacity=0.2,\n                    name=f\"{zone_name} Boundary\",\n                    showlegend=False,\n                    hovertemplate=f\"{zone_name}<br>Average Risk: {center['risk']:.1%}<extra></extra>\"\n                ))\n        \n        # Update layout\n        fig.update_layout(\n            title=\"Real-Time Mine Risk Heatmap\",\n            xaxis_title=\"Longitude\",\n            yaxis_title=\"Latitude\",\n            hovermode='closest',\n            width=800,\n            height=600,\n            margin=dict(l=0, r=0, t=40, b=0)\n        )\n        \n        # Add risk level annotations\n        self._add_risk_annotations(fig)\n        \n        return fig\n    \n    def _calculate_zone_centers(self, sensors):\n        \"\"\"Calculate center coordinates and average risk for each zone\"\"\"\n        zone_data = {}\n        \n        for sensor in sensors:\n            zone = sensor['zone']\n            if zone not in zone_data:\n                zone_data[zone] = {\n                    'lats': [],\n                    'lons': [],\n                    'risks': []\n                }\n            \n            coords = sensor['coordinates']\n            zone_data[zone]['lats'].append(coords['lat'])\n            zone_data[zone]['lons'].append(coords['lon'])\n            zone_data[zone]['risks'].append(sensor['risk_probability'])\n        \n        zone_centers = {}\n        for zone, data in zone_data.items():\n            zone_centers[zone] = {\n                'lat': np.mean(data['lats']),\n                'lon': np.mean(data['lons']),\n                'risk': np.mean(data['risks']),\n                'sensor_count': len(data['lats'])\n            }\n        \n        return zone_centers\n    \n    def _get_risk_color(self, risk_level):\n        \"\"\"Get color based on risk level\"\"\"\n        if risk_level >= 0.85:\n            return self.color_scheme['critical']\n        elif risk_level >= 0.7:\n            return self.color_scheme['high']\n        elif risk_level >= 0.3:\n            return self.color_scheme['medium']\n        else:\n            return self.color_scheme['low']\n    \n    def _add_risk_annotations(self, fig):\n        \"\"\"Add risk level annotations to the figure\"\"\"\n        # Add legend as annotations\n        annotations = [\n            dict(\n                x=0.02, y=0.98,\n                xref='paper', yref='paper',\n                text=\"<b>Risk Levels:</b>\",\n                showarrow=False,\n                font=dict(size=12, color=\"black\"),\n                bgcolor=\"white\",\n                bordercolor=\"black\",\n                borderwidth=1\n            ),\n            dict(\n                x=0.02, y=0.93,\n                xref='paper', yref='paper',\n                text=\"üü¢ Low (0-30%)\",\n                showarrow=False,\n                font=dict(size=10, color=\"green\")\n            ),\n            dict(\n                x=0.02, y=0.89,\n                xref='paper', yref='paper',\n                text=\"üü° Medium (30-70%)\",\n                showarrow=False,\n                font=dict(size=10, color=\"orange\")\n            ),\n            dict(\n                x=0.02, y=0.85,\n                xref='paper', yref='paper',\n                text=\"üü† High (70-85%)\",\n                showarrow=False,\n                font=dict(size=10, color=\"darkorange\")\n            ),\n            dict(\n                x=0.02, y=0.81,\n                xref='paper', yref='paper',\n                text=\"üî¥ Critical (85-100%)\",\n                showarrow=False,\n                font=dict(size=10, color=\"red\")\n            )\n        ]\n        \n        fig.update_layout(annotations=annotations)\n    \n    def get_active_alerts(self, data):\n        \"\"\"Get list of active alerts based on current data\"\"\"\n        alerts = []\n        sensors = data['sensors']\n        \n        for sensor in sensors:\n            risk = sensor['risk_probability']\n            \n            if risk >= 0.85:\n                alerts.append({\n                    'severity': 'critical',\n                    'message': f'Critical risk detected - immediate evacuation recommended',\n                    'zone': sensor['zone'],\n                    'sensor_id': sensor['id'],\n                    'risk_level': risk,\n                    'timestamp': datetime.now()\n                })\n            elif risk >= 0.7:\n                alerts.append({\n                    'severity': 'high',\n                    'message': f'High risk detected - restrict access and increase monitoring',\n                    'zone': sensor['zone'],\n                    'sensor_id': sensor['id'],\n                    'risk_level': risk,\n                    'timestamp': datetime.now()\n                })\n            elif risk >= 0.5:  # Medium-high threshold for alerts\n                alerts.append({\n                    'severity': 'medium',\n                    'message': f'Elevated risk detected - monitor closely',\n                    'zone': sensor['zone'],\n                    'sensor_id': sensor['id'],\n                    'risk_level': risk,\n                    'timestamp': datetime.now()\n                })\n        \n        # Sort by severity and risk level\n        severity_order = {'critical': 0, 'high': 1, 'medium': 2}\n        alerts.sort(key=lambda x: (severity_order[x['severity']], -x['risk_level']))\n        \n        return alerts\n    \n    def create_sensor_status_chart(self, data):\n        \"\"\"Create chart showing sensor status distribution\"\"\"\n        sensors = data['sensors']\n        \n        # Count sensors by status\n        online_count = sum(1 for s in sensors if s['status'] == 'online')\n        offline_count = len(sensors) - online_count\n        \n        # Count by risk level\n        risk_counts = {'low': 0, 'medium': 0, 'high': 0, 'critical': 0}\n        \n        for sensor in sensors:\n            if sensor['status'] == 'online':\n                risk = sensor['risk_probability']\n                if risk >= 0.85:\n                    risk_counts['critical'] += 1\n                elif risk >= 0.7:\n                    risk_counts['high'] += 1\n                elif risk >= 0.3:\n                    risk_counts['medium'] += 1\n                else:\n                    risk_counts['low'] += 1\n        \n        # Create pie chart for sensor status\n        fig_status = go.Figure(data=[go.Pie(\n            labels=['Online', 'Offline'],\n            values=[online_count, offline_count],\n            marker_colors=['green', 'red'],\n            hole=0.4\n        )])\n        \n        fig_status.update_layout(\n            title=\"Sensor Network Status\",\n            annotations=[dict(text=f'{online_count}/{len(sensors)}', x=0.5, y=0.5, font_size=20, showarrow=False)]\n        )\n        \n        # Create bar chart for risk distribution\n        fig_risk = go.Figure(data=[go.Bar(\n            x=list(risk_counts.keys()),\n            y=list(risk_counts.values()),\n            marker_color=[self.color_scheme[level] for level in risk_counts.keys()]\n        )])\n        \n        fig_risk.update_layout(\n            title=\"Risk Level Distribution\",\n            xaxis_title=\"Risk Level\",\n            yaxis_title=\"Number of Sensors\"\n        )\n        \n        return fig_status, fig_risk\n    \n    def create_environmental_dashboard(self, data):\n        \"\"\"Create environmental conditions dashboard\"\"\"\n        env = data['environmental']\n        \n        # Create gauge charts for key environmental factors\n        fig = go.Figure()\n        \n        # Temperature gauge\n        fig.add_trace(go.Indicator(\n            mode=\"gauge+number+delta\",\n            value=env['temperature'],\n            domain={'x': [0, 0.33], 'y': [0.5, 1]},\n            title={'text': \"Temperature (¬∞C)\"},\n            delta={'reference': 15},\n            gauge={\n                'axis': {'range': [None, 40]},\n                'bar': {'color': \"darkblue\"},\n                'steps': [\n                    {'range': [0, 10], 'color': \"lightblue\"},\n                    {'range': [10, 25], 'color': \"lightgreen\"},\n                    {'range': [25, 40], 'color': \"lightyellow\"}\n                ],\n                'threshold': {\n                    'line': {'color': \"red\", 'width': 4},\n                    'thickness': 0.75,\n                    'value': 35\n                }\n            }\n        ))\n        \n        # Rainfall gauge\n        fig.add_trace(go.Indicator(\n            mode=\"gauge+number\",\n            value=env['rainfall'],\n            domain={'x': [0.33, 0.66], 'y': [0.5, 1]},\n            title={'text': \"Rainfall (mm/h)\"},\n            gauge={\n                'axis': {'range': [None, 20]},\n                'bar': {'color': \"darkblue\"},\n                'steps': [\n                    {'range': [0, 2], 'color': \"lightgreen\"},\n                    {'range': [2, 10], 'color': \"lightyellow\"},\n                    {'range': [10, 20], 'color': \"lightcoral\"}\n                ]\n            }\n        ))\n        \n        # Wind speed gauge\n        fig.add_trace(go.Indicator(\n            mode=\"gauge+number\",\n            value=env['wind_speed'],\n            domain={'x': [0.66, 1], 'y': [0.5, 1]},\n            title={'text': \"Wind Speed (m/s)\"},\n            gauge={\n                'axis': {'range': [None, 30]},\n                'bar': {'color': \"darkgreen\"},\n                'steps': [\n                    {'range': [0, 5], 'color': \"lightgreen\"},\n                    {'range': [5, 15], 'color': \"lightyellow\"},\n                    {'range': [15, 30], 'color': \"lightcoral\"}\n                ]\n            }\n        ))\n        \n        # Humidity and pressure indicators\n        fig.add_trace(go.Indicator(\n            mode=\"number+delta\",\n            value=env['humidity'],\n            domain={'x': [0, 0.5], 'y': [0, 0.4]},\n            title={'text': \"Humidity (%)\"},\n            delta={'reference': 60}\n        ))\n        \n        fig.add_trace(go.Indicator(\n            mode=\"number+delta\",\n            value=env['atmospheric_pressure'],\n            domain={'x': [0.5, 1], 'y': [0, 0.4]},\n            title={'text': \"Pressure (hPa)\"},\n            delta={'reference': 1013}\n        ))\n        \n        fig.update_layout(\n            title=\"Environmental Conditions\",\n            height=600\n        )\n        \n        return fig\n    \n    def create_system_health_dashboard(self, lorawan_status, radio_status):\n        \"\"\"Create system health monitoring dashboard\"\"\"\n        # Communication systems health\n        fig = go.Figure()\n        \n        # LoRaWAN status\n        lorawan_health = lorawan_status['coverage'] * 100\n        fig.add_trace(go.Indicator(\n            mode=\"gauge+number\",\n            value=lorawan_health,\n            domain={'x': [0, 0.5], 'y': [0.5, 1]},\n            title={'text': \"LoRaWAN Network\"},\n            gauge={\n                'axis': {'range': [None, 100]},\n                'bar': {'color': \"darkblue\"},\n                'steps': [\n                    {'range': [0, 50], 'color': \"lightcoral\"},\n                    {'range': [50, 80], 'color': \"lightyellow\"},\n                    {'range': [80, 100], 'color': \"lightgreen\"}\n                ],\n                'threshold': {\n                    'line': {'color': \"red\", 'width': 4},\n                    'thickness': 0.75,\n                    'value': 90\n                }\n            }\n        ))\n        \n        # Radio backup health\n        radio_health = (1 - radio_status['error_rate']) * 100\n        fig.add_trace(go.Indicator(\n            mode=\"gauge+number\",\n            value=radio_health,\n            domain={'x': [0.5, 1], 'y': [0.5, 1]},\n            title={'text': \"Radio Backup\"},\n            gauge={\n                'axis': {'range': [None, 100]},\n                'bar': {'color': \"darkgreen\"},\n                'steps': [\n                    {'range': [0, 50], 'color': \"lightcoral\"},\n                    {'range': [50, 80], 'color': \"lightyellow\"},\n                    {'range': [80, 100], 'color': \"lightgreen\"}\n                ]\n            }\n        ))\n        \n        # System uptime\n        uptime = np.random.uniform(95, 99.9)  # Simulate system uptime\n        fig.add_trace(go.Indicator(\n            mode=\"number+delta\",\n            value=uptime,\n            domain={'x': [0, 0.5], 'y': [0, 0.4]},\n            title={'text': \"System Uptime (%)\"},\n            delta={'reference': 99, 'increasing': {'color': \"green\"}}\n        ))\n        \n        # Active sensors percentage\n        active_sensors = (lorawan_status['devices'] / lorawan_status['total_devices']) * 100\n        fig.add_trace(go.Indicator(\n            mode=\"number+delta\",\n            value=active_sensors,\n            domain={'x': [0.5, 1], 'y': [0, 0.4]},\n            title={'text': \"Active Sensors (%)\"},\n            delta={'reference': 95, 'increasing': {'color': \"green\"}}\n        ))\n        \n        fig.update_layout(\n            title=\"System Health Dashboard\",\n            height=600\n        )\n        \n        return fig\n","size_bytes":15965},"attached_assets/extracted/MineRockGuard/data/synthetic_data_generator.py":{"content":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport random\nimport json\n\nclass SyntheticDataGenerator:\n    def __init__(self):\n        self.sensor_count = 47\n        self.zone_count = 12\n        self.base_coordinates = {'lat': 45.123, 'lon': -123.456}\n        \n    def generate_real_time_data(self):\n        \"\"\"Generate current sensor readings and environmental data\"\"\"\n        current_time = datetime.now()\n        \n        # Generate sensor data\n        sensors = []\n        for i in range(self.sensor_count):\n            # Base risk varies by sensor location and time\n            base_risk = 0.2 + 0.3 * np.sin(i * np.pi / 10) + 0.1 * np.sin(current_time.hour * np.pi / 12)\n            noise = np.random.normal(0, 0.15)\n            risk_probability = max(0, min(1, base_risk + noise))\n            \n            sensor_data = {\n                'id': f\"S{i+1:03d}\",\n                'zone': f\"Zone_{(i // 4) + 1}\",\n                'coordinates': {\n                    'lat': self.base_coordinates['lat'] + np.random.uniform(-0.01, 0.01),\n                    'lon': self.base_coordinates['lon'] + np.random.uniform(-0.01, 0.01),\n                    'elevation': 1200 + np.random.uniform(-100, 200)\n                },\n                'displacement_rate': np.random.uniform(0.1, 2.5),  # mm/day\n                'strain_magnitude': np.random.uniform(0.05, 1.2),  # microstrains\n                'pore_pressure': np.random.uniform(50, 150),  # kPa\n                'vibration_level': np.random.uniform(0, 0.8),  # g-force\n                'crack_density': np.random.uniform(0, 0.6),  # cracks/m¬≤\n                'soil_moisture': np.random.uniform(10, 40),  # %\n                'slope_angle': np.random.uniform(35, 75),  # degrees\n                'risk_probability': risk_probability,\n                'status': 'online' if np.random.random() > 0.05 else 'offline',\n                'last_update': current_time - timedelta(minutes=np.random.randint(0, 5))\n            }\n            sensors.append(sensor_data)\n        \n        # Generate environmental data\n        environmental = {\n            'temperature': np.random.normal(15, 10),  # Celsius\n            'rainfall': max(0, np.random.gamma(2, 2)),  # mm/hour\n            'wind_speed': max(0, np.random.gamma(3, 2)),  # m/s\n            'wind_direction': np.random.uniform(0, 360),  # degrees\n            'humidity': np.random.uniform(30, 95),  # %\n            'atmospheric_pressure': np.random.normal(1013, 20),  # hPa\n            'solar_radiation': max(0, np.random.gamma(5, 100)),  # W/m¬≤\n            'timestamp': current_time\n        }\n        \n        # Generate DEM data (simplified)\n        dem_data = self.generate_dem_data()\n        \n        return {\n            'sensors': sensors,\n            'environmental': environmental,\n            'dem': dem_data,\n            'timestamp': current_time\n        }\n    \n    def generate_dem_data(self):\n        \"\"\"Generate Digital Elevation Model data\"\"\"\n        # Create a grid representing the mine topology\n        grid_size = 50\n        x = np.linspace(0, 1000, grid_size)  # meters\n        y = np.linspace(0, 800, grid_size)   # meters\n        X, Y = np.meshgrid(x, y)\n        \n        # Create realistic mine pit topology\n        # Central depression with terraced sides\n        center_x, center_y = 500, 400\n        distance_from_center = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n        \n        # Base elevation with pit\n        Z = 1300 - 0.3 * distance_from_center  # Gradual slope down to pit\n        \n        # Add terraces (benches) typical in open pit mines\n        terrace_height = 15  # meters between benches\n        Z = np.floor(Z / terrace_height) * terrace_height\n        \n        # Add some geological variation\n        Z += 5 * np.sin(X / 100) * np.cos(Y / 80)\n        Z += np.random.normal(0, 2, Z.shape)  # Surface roughness\n        \n        return {\n            'x': X.tolist(),\n            'y': Y.tolist(),\n            'z': Z.tolist(),\n            'grid_size': grid_size,\n            'resolution': 20  # meters per grid cell\n        }\n    \n    def generate_mine_topology(self):\n        \"\"\"Generate detailed 3D mine topology data\"\"\"\n        # Generate mine structure with multiple zones\n        zones = []\n        \n        for zone_id in range(1, self.zone_count + 1):\n            # Random zone positioning around the mine\n            angle = (zone_id - 1) * 2 * np.pi / self.zone_count\n            zone_x = 500 + 300 * np.cos(angle)\n            zone_y = 400 + 200 * np.sin(angle)\n            \n            # Zone-specific risk level\n            base_risk = np.random.uniform(0.1, 0.8)\n            \n            zone_data = {\n                'id': zone_id,\n                'name': f\"Zone_{zone_id}\",\n                'center_coordinates': {'x': zone_x, 'y': zone_y, 'z': 1250 + np.random.uniform(-50, 50)},\n                'risk_level': base_risk,\n                'geological_type': np.random.choice(['limestone', 'sandstone', 'shale', 'granite']),\n                'slope_stability': np.random.uniform(0.3, 0.9),\n                'sensor_count': np.random.randint(2, 6),\n                'last_incident': datetime.now() - timedelta(days=np.random.randint(1, 365)) if np.random.random() > 0.7 else None\n            }\n            zones.append(zone_data)\n        \n        # Generate detailed DEM\n        dem_data = self.generate_dem_data()\n        \n        # Add sensor network\n        sensor_network = self.generate_sensor_network()\n        \n        return {\n            'zones': zones,\n            'dem': dem_data,\n            'sensor_network': sensor_network,\n            'mine_parameters': {\n                'total_area': 800000,  # m¬≤\n                'max_depth': 200,      # meters\n                'active_benches': 12,\n                'access_roads': 8,\n                'equipment_zones': 15\n            }\n        }\n    \n    def generate_sensor_network(self):\n        \"\"\"Generate sensor network topology\"\"\"\n        sensors = []\n        \n        for i in range(self.sensor_count):\n            # Distribute sensors across the mine area\n            x = np.random.uniform(50, 950)\n            y = np.random.uniform(50, 750)\n            z = 1200 + np.random.uniform(0, 100)\n            \n            sensor = {\n                'id': f\"S{i+1:03d}\",\n                'type': np.random.choice(['displacement', 'strain', 'pressure', 'vibration', 'tilt']),\n                'coordinates': {'x': x, 'y': y, 'z': z},\n                'communication_type': np.random.choice(['LoRaWAN', 'radio', 'wired']),\n                'battery_level': np.random.uniform(20, 100) if np.random.choice(['LoRaWAN', 'radio']) else 100,\n                'signal_strength': np.random.uniform(-120, -70),  # dBm\n                'installation_date': datetime.now() - timedelta(days=np.random.randint(30, 730)),\n                'maintenance_due': datetime.now() + timedelta(days=np.random.randint(1, 90))\n            }\n            sensors.append(sensor)\n        \n        return sensors\n    \n    def generate_drone_imagery_data(self):\n        \"\"\"Generate synthetic drone imagery analysis data\"\"\"\n        flights = []\n        \n        # Generate recent drone flights\n        for i in range(10):\n            flight_time = datetime.now() - timedelta(hours=np.random.randint(1, 72))\n            \n            flight_data = {\n                'flight_id': f\"DRONE_{i+1:03d}\",\n                'timestamp': flight_time,\n                'coverage_area': {\n                    'zones_covered': np.random.choice(range(1, self.zone_count+1), size=np.random.randint(3, 8), replace=False).tolist()\n                },\n                'image_analysis': {\n                    'total_images': np.random.randint(150, 500),\n                    'crack_detection_count': np.random.randint(5, 25),\n                    'vegetation_health': np.random.uniform(0.6, 0.95),\n                    'surface_changes_detected': np.random.randint(2, 12),\n                    'weather_conditions': np.random.choice(['clear', 'partly_cloudy', 'overcast', 'light_rain'])\n                },\n                'risk_indicators': {\n                    'new_cracks': np.random.randint(0, 5),\n                    'rock_displacement': np.random.uniform(0, 15),  # mm\n                    'erosion_detected': np.random.choice([True, False]),\n                    'overall_risk_score': np.random.uniform(0.2, 0.8)\n                }\n            }\n            flights.append(flight_data)\n        \n        return flights\n    \n    def generate_historical_sensor_data(self, days=30):\n        \"\"\"Generate historical sensor data for trend analysis\"\"\"\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=days)\n        \n        # Generate hourly data points\n        time_points = []\n        current = start_date\n        while current <= end_date:\n            time_points.append(current)\n            current += timedelta(hours=1)\n        \n        historical_data = []\n        \n        for timestamp in time_points:\n            # Simulate daily and seasonal patterns\n            hour_factor = np.sin(timestamp.hour * np.pi / 12)\n            day_factor = np.sin(timestamp.timetuple().tm_yday * 2 * np.pi / 365)\n            \n            # Generate sensor readings for this timestamp\n            for sensor_id in range(1, self.sensor_count + 1):\n                base_reading = 0.3 + 0.2 * hour_factor + 0.1 * day_factor\n                noise = np.random.normal(0, 0.1)\n                risk_level = max(0, min(1, base_reading + noise))\n                \n                reading = {\n                    'timestamp': timestamp,\n                    'sensor_id': f\"S{sensor_id:03d}\",\n                    'displacement_rate': np.random.uniform(0.1, 2.0),\n                    'strain_magnitude': np.random.uniform(0.05, 1.0),\n                    'pore_pressure': np.random.uniform(50, 140),\n                    'temperature': 15 + 10 * np.sin((timestamp.timetuple().tm_yday + timestamp.hour/24) * 2 * np.pi / 365) + np.random.normal(0, 2),\n                    'rainfall': max(0, np.random.gamma(2, 2)) if np.random.random() > 0.7 else 0,\n                    'wind_speed': max(0, np.random.gamma(3, 2)),\n                    'vibration_level': np.random.uniform(0, 0.6),\n                    'risk_probability': risk_level,\n                    'alert_triggered': risk_level > 0.7\n                }\n                historical_data.append(reading)\n        \n        return historical_data\n","size_bytes":10453},"attached_assets/extracted/MineRockGuard/database/data_ingestion.py":{"content":"\"\"\"\nData ingestion system for real-time sensor data and IoT integration\nHandles MQTT, HTTP APIs, LoRaWAN, and other communication protocols\n\"\"\"\n\nimport json\nimport asyncio\nimport logging\nfrom datetime import datetime, timezone\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass\nimport paho.mqtt.client as mqtt\nfrom sqlalchemy.orm import Session\nfrom database.schema import DatabaseManager, Sensor, SensorReading, EnvironmentalData, CommunicationLog\nimport os\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass SensorData:\n    \"\"\"Standardized sensor data format\"\"\"\n    sensor_id: str\n    timestamp: datetime\n    value: float\n    unit: str\n    quality_score: float = 1.0\n    metadata: Optional[Dict] = None\n\n@dataclass\nclass EnvironmentalDataPoint:\n    \"\"\"Environmental data point\"\"\"\n    mine_site_id: int\n    timestamp: datetime\n    temperature: Optional[float] = None\n    humidity: Optional[float] = None\n    wind_speed: Optional[float] = None\n    wind_direction: Optional[float] = None\n    precipitation: Optional[float] = None\n    atmospheric_pressure: Optional[float] = None\n    seismic_activity: Optional[float] = None\n    source: str = \"unknown\"\n\nclass IoTDataIngestion:\n    \"\"\"Main data ingestion system for IoT sensors\"\"\"\n    \n    def __init__(self):\n        self.db_manager = DatabaseManager()\n        self.mqtt_client = None\n        self.is_running = False\n        \n        # MQTT Configuration\n        self.mqtt_broker = os.getenv('MQTT_BROKER_HOST', 'localhost')\n        self.mqtt_port = int(os.getenv('MQTT_BROKER_PORT', '1883'))\n        self.mqtt_topics = [\n            'sensors/+/displacement',\n            'sensors/+/strain',\n            'sensors/+/pressure',\n            'sensors/+/vibration',\n            'sensors/+/tilt',\n            'environmental/+/weather',\n            'lorawan/+/data'\n        ]\n    \n    def setup_mqtt(self):\n        \"\"\"Setup MQTT client for sensor data\"\"\"\n        try:\n            self.mqtt_client = mqtt.Client()\n            self.mqtt_client.on_connect = self._on_mqtt_connect\n            self.mqtt_client.on_message = self._on_mqtt_message\n            self.mqtt_client.on_disconnect = self._on_mqtt_disconnect\n            \n            # Connect to MQTT broker\n            self.mqtt_client.connect(self.mqtt_broker, self.mqtt_port, 60)\n            logger.info(f\"MQTT client connected to {self.mqtt_broker}:{self.mqtt_port}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to setup MQTT: {e}\")\n            # Continue without MQTT for demo purposes\n    \n    def _on_mqtt_connect(self, client, userdata, flags, rc):\n        \"\"\"MQTT connection callback\"\"\"\n        if rc == 0:\n            logger.info(\"Successfully connected to MQTT broker\")\n            # Subscribe to sensor topics\n            for topic in self.mqtt_topics:\n                client.subscribe(topic)\n                logger.info(f\"Subscribed to topic: {topic}\")\n        else:\n            logger.error(f\"Failed to connect to MQTT broker with code {rc}\")\n    \n    def _on_mqtt_message(self, client, userdata, msg):\n        \"\"\"Process incoming MQTT messages\"\"\"\n        try:\n            topic_parts = msg.topic.split('/')\n            payload = json.loads(msg.payload.decode())\n            \n            if topic_parts[0] == 'sensors':\n                self._process_sensor_data(topic_parts, payload)\n            elif topic_parts[0] == 'environmental':\n                self._process_environmental_data(topic_parts, payload)\n            elif topic_parts[0] == 'lorawan':\n                self._process_lorawan_data(topic_parts, payload)\n                \n        except Exception as e:\n            logger.error(f\"Error processing MQTT message: {e}\")\n    \n    def _on_mqtt_disconnect(self, client, userdata, rc):\n        \"\"\"MQTT disconnect callback\"\"\"\n        logger.warning(f\"MQTT client disconnected with code {rc}\")\n    \n    def _process_sensor_data(self, topic_parts: List[str], payload: Dict):\n        \"\"\"Process individual sensor readings\"\"\"\n        try:\n            sensor_id = topic_parts[1]\n            sensor_type = topic_parts[2]\n            \n            # Create sensor data object\n            sensor_data = SensorData(\n                sensor_id=sensor_id,\n                timestamp=datetime.fromtimestamp(payload.get('timestamp', datetime.now().timestamp()), tz=timezone.utc),\n                value=float(payload['value']),\n                unit=payload.get('unit', ''),\n                quality_score=payload.get('quality', 1.0),\n                metadata=payload.get('metadata', {})\n            )\n            \n            # Store in database\n            self._store_sensor_reading(sensor_data)\n            \n            # Log communication\n            self._log_communication('MQTT', 'inbound', f\"sensor/{sensor_id}\", \n                                  'sensor_data', json.dumps(payload))\n            \n        except Exception as e:\n            logger.error(f\"Error processing sensor data: {e}\")\n    \n    def _process_environmental_data(self, topic_parts: List[str], payload: Dict):\n        \"\"\"Process environmental sensor data\"\"\"\n        try:\n            station_id = topic_parts[1]\n            \n            env_data = EnvironmentalDataPoint(\n                mine_site_id=payload.get('mine_site_id', 1),\n                timestamp=datetime.fromtimestamp(payload.get('timestamp', datetime.now().timestamp()), tz=timezone.utc),\n                temperature=payload.get('temperature'),\n                humidity=payload.get('humidity'),\n                wind_speed=payload.get('wind_speed'),\n                wind_direction=payload.get('wind_direction'),\n                precipitation=payload.get('precipitation'),\n                atmospheric_pressure=payload.get('pressure'),\n                seismic_activity=payload.get('seismic'),\n                source=f\"station_{station_id}\"\n            )\n            \n            self._store_environmental_data(env_data)\n            \n        except Exception as e:\n            logger.error(f\"Error processing environmental data: {e}\")\n    \n    def _process_lorawan_data(self, topic_parts: List[str], payload: Dict):\n        \"\"\"Process LoRaWAN sensor data\"\"\"\n        try:\n            device_id = topic_parts[1]\n            \n            # Decode LoRaWAN payload\n            decoded_data = self._decode_lorawan_payload(payload)\n            \n            for sensor_reading in decoded_data:\n                self._store_sensor_reading(sensor_reading)\n            \n            # Log LoRaWAN communication\n            self._log_communication('LoRaWAN', 'inbound', device_id, \n                                  'sensor_data', json.dumps(payload))\n            \n        except Exception as e:\n            logger.error(f\"Error processing LoRaWAN data: {e}\")\n    \n    def _decode_lorawan_payload(self, payload: Dict) -> List[SensorData]:\n        \"\"\"Decode LoRaWAN payload into sensor readings\"\"\"\n        readings = []\n        \n        try:\n            # Simulate decoding different sensor types from LoRaWAN payload\n            data = payload.get('data', {})\n            device_id = payload.get('device_id', 'unknown')\n            timestamp = datetime.fromtimestamp(payload.get('timestamp', datetime.now().timestamp()), tz=timezone.utc)\n            \n            # Example: Multiple sensor readings in one LoRaWAN message\n            if 'displacement' in data:\n                readings.append(SensorData(\n                    sensor_id=f\"{device_id}_displacement\",\n                    timestamp=timestamp,\n                    value=data['displacement'],\n                    unit='mm',\n                    quality_score=data.get('rssi', -100) / -50.0  # Convert RSSI to quality score\n                ))\n            \n            if 'strain' in data:\n                readings.append(SensorData(\n                    sensor_id=f\"{device_id}_strain\",\n                    timestamp=timestamp,\n                    value=data['strain'],\n                    unit='¬µŒµ',\n                    quality_score=data.get('rssi', -100) / -50.0\n                ))\n            \n        except Exception as e:\n            logger.error(f\"Error decoding LoRaWAN payload: {e}\")\n        \n        return readings\n    \n    def _store_sensor_reading(self, sensor_data: SensorData):\n        \"\"\"Store sensor reading in database\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            # Find or create sensor\n            sensor = session.query(Sensor).filter_by(sensor_id=sensor_data.sensor_id).first()\n            \n            if not sensor:\n                # Create new sensor if not exists\n                sensor = Sensor(\n                    sensor_id=sensor_data.sensor_id,\n                    mine_site_id=1,  # Default to first mine site\n                    sensor_type=self._infer_sensor_type(sensor_data.sensor_id),\n                    coordinates={'x': 0, 'y': 0, 'z': 0},  # Default coordinates\n                    status='active',\n                    communication_protocol='MQTT'\n                )\n                session.add(sensor)\n                session.flush()\n            \n            # Create sensor reading\n            reading = SensorReading(\n                sensor_id=sensor.id,\n                timestamp=sensor_data.timestamp,\n                value=sensor_data.value,\n                unit=sensor_data.unit,\n                quality_score=sensor_data.quality_score,\n                sensor_metadata=sensor_data.metadata\n            )\n            \n            session.add(reading)\n            session.commit()\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error storing sensor reading: {e}\")\n        finally:\n            self.db_manager.close_session(session)\n    \n    def _store_environmental_data(self, env_data: EnvironmentalDataPoint):\n        \"\"\"Store environmental data in database\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            env_record = EnvironmentalData(\n                mine_site_id=env_data.mine_site_id,\n                timestamp=env_data.timestamp,\n                temperature=env_data.temperature,\n                humidity=env_data.humidity,\n                wind_speed=env_data.wind_speed,\n                wind_direction=env_data.wind_direction,\n                precipitation=env_data.precipitation,\n                atmospheric_pressure=env_data.atmospheric_pressure,\n                seismic_activity=env_data.seismic_activity,\n                source=env_data.source\n            )\n            \n            session.add(env_record)\n            session.commit()\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error storing environmental data: {e}\")\n        finally:\n            self.db_manager.close_session(session)\n    \n    def _log_communication(self, protocol: str, direction: str, source: str, \n                          message_type: str, payload: str, success: bool = True):\n        \"\"\"Log communication events\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            comm_log = CommunicationLog(\n                protocol=protocol,\n                direction=direction,\n                source=source,\n                destination='system',\n                message_type=message_type,\n                payload=payload,\n                success=success,\n                mine_site_id=1  # Default mine site\n            )\n            \n            session.add(comm_log)\n            session.commit()\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error logging communication: {e}\")\n        finally:\n            self.db_manager.close_session(session)\n    \n    def _infer_sensor_type(self, sensor_id: str) -> str:\n        \"\"\"Infer sensor type from sensor ID\"\"\"\n        sensor_id_lower = sensor_id.lower()\n        \n        if 'displacement' in sensor_id_lower:\n            return 'displacement'\n        elif 'strain' in sensor_id_lower:\n            return 'strain'\n        elif 'pressure' in sensor_id_lower:\n            return 'pressure'\n        elif 'vibration' in sensor_id_lower:\n            return 'vibration'\n        elif 'tilt' in sensor_id_lower:\n            return 'tilt'\n        else:\n            return 'unknown'\n    \n    async def start_ingestion(self):\n        \"\"\"Start the data ingestion system\"\"\"\n        self.is_running = True\n        logger.info(\"Starting IoT data ingestion system...\")\n        \n        # Setup MQTT\n        self.setup_mqtt()\n        \n        # Start MQTT loop\n        if self.mqtt_client:\n            self.mqtt_client.loop_start()\n        \n        # Keep the system running\n        while self.is_running:\n            await asyncio.sleep(1)\n    \n    def stop_ingestion(self):\n        \"\"\"Stop the data ingestion system\"\"\"\n        self.is_running = False\n        \n        if self.mqtt_client:\n            self.mqtt_client.loop_stop()\n            self.mqtt_client.disconnect()\n        \n        logger.info(\"IoT data ingestion system stopped\")\n\n# HTTP API endpoint handlers for direct sensor data submission\nclass HTTPDataHandler:\n    \"\"\"Handle HTTP API submissions for sensor data\"\"\"\n    \n    def __init__(self):\n        self.db_manager = DatabaseManager()\n        self.ingestion = IoTDataIngestion()\n    \n    def submit_sensor_data(self, data: Dict) -> Dict[str, Any]:\n        \"\"\"Accept sensor data via HTTP API\"\"\"\n        try:\n            sensor_data = SensorData(\n                sensor_id=data['sensor_id'],\n                timestamp=datetime.fromisoformat(data.get('timestamp', datetime.now().isoformat())),\n                value=float(data['value']),\n                unit=data.get('unit', ''),\n                quality_score=data.get('quality_score', 1.0),\n                metadata=data.get('metadata', {})\n            )\n            \n            self.ingestion._store_sensor_reading(sensor_data)\n            \n            return {\"status\": \"success\", \"message\": \"Data stored successfully\"}\n            \n        except Exception as e:\n            logger.error(f\"Error in HTTP data submission: {e}\")\n            return {\"status\": \"error\", \"message\": str(e)}\n    \n    def submit_environmental_data(self, data: Dict) -> Dict[str, Any]:\n        \"\"\"Accept environmental data via HTTP API\"\"\"\n        try:\n            env_data = EnvironmentalDataPoint(\n                mine_site_id=data.get('mine_site_id', 1),\n                timestamp=datetime.fromisoformat(data.get('timestamp', datetime.now().isoformat())),\n                temperature=data.get('temperature'),\n                humidity=data.get('humidity'),\n                wind_speed=data.get('wind_speed'),\n                wind_direction=data.get('wind_direction'),\n                precipitation=data.get('precipitation'),\n                atmospheric_pressure=data.get('atmospheric_pressure'),\n                seismic_activity=data.get('seismic_activity'),\n                source=data.get('source', 'http_api')\n            )\n            \n            self.ingestion._store_environmental_data(env_data)\n            \n            return {\"status\": \"success\", \"message\": \"Environmental data stored successfully\"}\n            \n        except Exception as e:\n            logger.error(f\"Error in HTTP environmental data submission: {e}\")\n            return {\"status\": \"error\", \"message\": str(e)}\n\n# Global instances\niot_ingestion = IoTDataIngestion()\nhttp_handler = HTTPDataHandler()","size_bytes":15432},"attached_assets/extracted/MineRockGuard/database/database_manager.py":{"content":"\"\"\"\nDatabase management utilities for the Rockfall Prediction System\nHandles initialization, data queries, and database operations\n\"\"\"\n\nfrom typing import List, Dict, Any, Optional, Tuple\nfrom datetime import datetime, timedelta\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import func, desc, asc\nfrom database.schema import (\n    DatabaseManager, MineSite, Sensor, SensorReading, \n    EnvironmentalData, RiskAssessment, Alert, DroneImagery, \n    SystemLog, CommunicationLog\n)\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass RockfallDatabaseManager:\n    \"\"\"High-level database operations for the rockfall prediction system\"\"\"\n    \n    def __init__(self):\n        self.db_manager = DatabaseManager()\n        self.db_manager.create_tables()\n        self._initialize_default_data()\n    \n    def _initialize_default_data(self):\n        \"\"\"Initialize default mine site and sensors if not exists\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            # Check if we have any mine sites\n            mine_count = session.query(MineSite).count()\n            \n            if mine_count == 0:\n                # Create default mine site\n                default_mine = MineSite(\n                    name=\"Copper Ridge Mine\",\n                    location=\"Colorado, USA\",\n                    coordinates={\"lat\": 39.7392, \"lon\": -104.9903},\n                    site_boundaries=[\n                        {\"lat\": 39.7400, \"lon\": -104.9910},\n                        {\"lat\": 39.7400, \"lon\": -104.9890},\n                        {\"lat\": 39.7380, \"lon\": -104.9890},\n                        {\"lat\": 39.7380, \"lon\": -104.9910}\n                    ],\n                    active=True\n                )\n                session.add(default_mine)\n                session.flush()\n                \n                # Create default sensors\n                sensor_configs = [\n                    {\"type\": \"displacement\", \"coords\": {\"x\": 100, \"y\": 200, \"z\": 50}},\n                    {\"type\": \"strain\", \"coords\": {\"x\": 150, \"y\": 180, \"z\": 45}},\n                    {\"type\": \"pressure\", \"coords\": {\"x\": 120, \"y\": 220, \"z\": 55}},\n                    {\"type\": \"vibration\", \"coords\": {\"x\": 180, \"y\": 160, \"z\": 40}},\n                    {\"type\": \"tilt\", \"coords\": {\"x\": 90, \"y\": 240, \"z\": 60}}\n                ]\n                \n                for i, config in enumerate(sensor_configs):\n                    sensor = Sensor(\n                        sensor_id=f\"SENSOR_{config['type'].upper()}_{i+1:03d}\",\n                        mine_site_id=default_mine.id,\n                        sensor_type=config['type'],\n                        coordinates=config['coords'],\n                        status='active',\n                        communication_protocol='LoRaWAN',\n                        battery_level=85.0,\n                        signal_strength=-65.0\n                    )\n                    session.add(sensor)\n                \n                session.commit()\n                logger.info(\"Initialized default mine site and sensors\")\n                \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error initializing default data: {e}\")\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_mine_sites(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all active mine sites\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            sites = session.query(MineSite).filter_by(active=True).all()\n            return [\n                {\n                    \"id\": site.id,\n                    \"name\": site.name,\n                    \"location\": site.location,\n                    \"coordinates\": site.coordinates,\n                    \"site_boundaries\": site.site_boundaries,\n                    \"sensor_count\": len(site.sensors),\n                    \"created_at\": site.created_at.isoformat()\n                }\n                for site in sites\n            ]\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_sensors_for_site(self, mine_site_id: int) -> List[Dict[str, Any]]:\n        \"\"\"Get all sensors for a specific mine site\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            sensors = session.query(Sensor).filter_by(\n                mine_site_id=mine_site_id, \n                status='active'\n            ).all()\n            \n            sensor_data = []\n            for sensor in sensors:\n                # Get latest reading\n                latest_reading = session.query(SensorReading).filter_by(\n                    sensor_id=sensor.id\n                ).order_by(desc(SensorReading.timestamp)).first()\n                \n                sensor_data.append({\n                    \"id\": sensor.id,\n                    \"sensor_id\": sensor.sensor_id,\n                    \"sensor_type\": sensor.sensor_type,\n                    \"coordinates\": sensor.coordinates,\n                    \"status\": sensor.status,\n                    \"communication_protocol\": sensor.communication_protocol,\n                    \"battery_level\": sensor.battery_level,\n                    \"signal_strength\": sensor.signal_strength,\n                    \"latest_value\": latest_reading.value if latest_reading else None,\n                    \"latest_timestamp\": latest_reading.timestamp.isoformat() if latest_reading else None,\n                    \"installation_date\": sensor.installation_date.isoformat() if sensor.installation_date else None\n                })\n            \n            return sensor_data\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_sensor_readings(self, sensor_id: int, hours: int = 24) -> List[Dict[str, Any]]:\n        \"\"\"Get recent sensor readings for a specific sensor\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            cutoff_time = datetime.now() - timedelta(hours=hours)\n            \n            readings = session.query(SensorReading).filter(\n                SensorReading.sensor_id == sensor_id,\n                SensorReading.timestamp >= cutoff_time\n            ).order_by(asc(SensorReading.timestamp)).all()\n            \n            return [\n                {\n                    \"timestamp\": reading.timestamp.isoformat(),\n                    \"value\": reading.value,\n                    \"unit\": reading.unit,\n                    \"quality_score\": reading.quality_score,\n                    \"anomaly_detected\": reading.anomaly_detected\n                }\n                for reading in readings\n            ]\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_environmental_data(self, mine_site_id: int, hours: int = 24) -> List[Dict[str, Any]]:\n        \"\"\"Get recent environmental data for a mine site\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            cutoff_time = datetime.now() - timedelta(hours=hours)\n            \n            env_data = session.query(EnvironmentalData).filter(\n                EnvironmentalData.mine_site_id == mine_site_id,\n                EnvironmentalData.timestamp >= cutoff_time\n            ).order_by(asc(EnvironmentalData.timestamp)).all()\n            \n            return [\n                {\n                    \"timestamp\": data.timestamp.isoformat(),\n                    \"temperature\": data.temperature,\n                    \"humidity\": data.humidity,\n                    \"wind_speed\": data.wind_speed,\n                    \"wind_direction\": data.wind_direction,\n                    \"precipitation\": data.precipitation,\n                    \"atmospheric_pressure\": data.atmospheric_pressure,\n                    \"seismic_activity\": data.seismic_activity,\n                    \"source\": data.source\n                }\n                for data in env_data\n            ]\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def store_risk_assessment(self, mine_site_id: int, risk_level: str, \n                            risk_score: float, affected_zones: List[Dict],\n                            contributing_factors: Dict, model_version: str,\n                            confidence_score: float, timeframe: str,\n                            recommendations: str) -> int:\n        \"\"\"Store a new risk assessment\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            assessment = RiskAssessment(\n                mine_site_id=mine_site_id,\n                risk_level=risk_level,\n                risk_score=risk_score,\n                affected_zones=affected_zones,\n                contributing_factors=contributing_factors,\n                model_version=model_version,\n                confidence_score=confidence_score,\n                predicted_timeframe=timeframe,\n                recommendations=recommendations\n            )\n            \n            session.add(assessment)\n            session.commit()\n            return assessment.id\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error storing risk assessment: {e}\")\n            raise\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_recent_risk_assessments(self, mine_site_id: int, limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"Get recent risk assessments for a mine site\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            assessments = session.query(RiskAssessment).filter_by(\n                mine_site_id=mine_site_id\n            ).order_by(desc(RiskAssessment.timestamp)).limit(limit).all()\n            \n            return [\n                {\n                    \"id\": assessment.id,\n                    \"timestamp\": assessment.timestamp.isoformat(),\n                    \"risk_level\": assessment.risk_level,\n                    \"risk_score\": assessment.risk_score,\n                    \"affected_zones\": assessment.affected_zones,\n                    \"contributing_factors\": assessment.contributing_factors,\n                    \"confidence_score\": assessment.confidence_score,\n                    \"predicted_timeframe\": assessment.predicted_timeframe,\n                    \"recommendations\": assessment.recommendations\n                }\n                for assessment in assessments\n            ]\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def create_alert(self, mine_site_id: int, alert_type: str, severity: str,\n                    title: str, message: str, location: Optional[Dict] = None,\n                    triggered_by: Optional[str] = None) -> int:\n        \"\"\"Create a new alert\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            alert = Alert(\n                mine_site_id=mine_site_id,\n                alert_type=alert_type,\n                severity=severity,\n                title=title,\n                message=message,\n                location=location,\n                triggered_by=triggered_by\n            )\n            \n            session.add(alert)\n            session.commit()\n            return alert.id\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error creating alert: {e}\")\n            raise\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_active_alerts(self, mine_site_id: Optional[int] = None) -> List[Dict[str, Any]]:\n        \"\"\"Get active (unresolved) alerts\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            query = session.query(Alert).filter_by(resolved=False)\n            \n            if mine_site_id:\n                query = query.filter_by(mine_site_id=mine_site_id)\n            \n            alerts = query.order_by(desc(Alert.timestamp)).all()\n            \n            return [\n                {\n                    \"id\": alert.id,\n                    \"mine_site_id\": alert.mine_site_id,\n                    \"alert_type\": alert.alert_type,\n                    \"severity\": alert.severity,\n                    \"title\": alert.title,\n                    \"message\": alert.message,\n                    \"location\": alert.location,\n                    \"timestamp\": alert.timestamp.isoformat(),\n                    \"acknowledged\": alert.acknowledged,\n                    \"acknowledged_by\": alert.acknowledged_by,\n                    \"sms_sent\": alert.sms_sent,\n                    \"email_sent\": alert.email_sent,\n                    \"siren_activated\": alert.siren_activated\n                }\n                for alert in alerts\n            ]\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def acknowledge_alert(self, alert_id: int, acknowledged_by: str) -> bool:\n        \"\"\"Acknowledge an alert\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            alert = session.query(Alert).get(alert_id)\n            if alert:\n                alert.acknowledged = True\n                alert.acknowledged_by = acknowledged_by\n                alert.acknowledged_at = datetime.now()\n                session.commit()\n                return True\n            return False\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error acknowledging alert: {e}\")\n            return False\n        finally:\n            self.db_manager.close_session(session)\n    \n    def resolve_alert(self, alert_id: int, resolved_by: str, actions_taken: str) -> bool:\n        \"\"\"Resolve an alert\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            alert = session.query(Alert).get(alert_id)\n            if alert:\n                alert.resolved = True\n                alert.resolved_by = resolved_by\n                alert.resolved_at = datetime.now()\n                alert.actions_taken = actions_taken\n                session.commit()\n                return True\n            return False\n            \n        except Exception as e:\n            session.rollback()\n            logger.error(f\"Error resolving alert: {e}\")\n            return False\n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_system_statistics(self, mine_site_id: int) -> Dict[str, Any]:\n        \"\"\"Get system statistics for a mine site\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            # Sensor statistics\n            total_sensors = session.query(Sensor).filter_by(\n                mine_site_id=mine_site_id, status='active'\n            ).count()\n            \n            # Recent readings count (last 24 hours)\n            cutoff_time = datetime.now() - timedelta(hours=24)\n            recent_readings = session.query(SensorReading).join(Sensor).filter(\n                Sensor.mine_site_id == mine_site_id,\n                SensorReading.timestamp >= cutoff_time\n            ).count()\n            \n            # Active alerts\n            active_alerts = session.query(Alert).filter_by(\n                mine_site_id=mine_site_id, resolved=False\n            ).count()\n            \n            # Latest risk assessment\n            latest_risk = session.query(RiskAssessment).filter_by(\n                mine_site_id=mine_site_id\n            ).order_by(desc(RiskAssessment.timestamp)).first()\n            \n            # Communication statistics\n            comm_success_rate = session.query(\n                func.avg(func.cast(CommunicationLog.success, func.INTEGER))\n            ).filter(\n                CommunicationLog.mine_site_id == mine_site_id,\n                CommunicationLog.timestamp >= cutoff_time\n            ).scalar() or 0\n            \n            return {\n                \"total_sensors\": total_sensors,\n                \"recent_readings\": recent_readings,\n                \"active_alerts\": active_alerts,\n                \"latest_risk_level\": latest_risk.risk_level if latest_risk else \"unknown\",\n                \"latest_risk_score\": latest_risk.risk_score if latest_risk else 0,\n                \"communication_success_rate\": float(comm_success_rate),\n                \"system_uptime\": \"99.2%\",  # This would come from system monitoring\n                \"last_updated\": datetime.now().isoformat()\n            }\n            \n        finally:\n            self.db_manager.close_session(session)\n    \n    def get_historical_trends(self, mine_site_id: int, days: int = 30) -> Dict[str, Any]:\n        \"\"\"Get historical trends for risk analysis\"\"\"\n        session = self.db_manager.get_session()\n        try:\n            cutoff_time = datetime.now() - timedelta(days=days)\n            \n            # Risk score trends\n            risk_assessments = session.query(RiskAssessment).filter(\n                RiskAssessment.mine_site_id == mine_site_id,\n                RiskAssessment.timestamp >= cutoff_time\n            ).order_by(asc(RiskAssessment.timestamp)).all()\n            \n            # Alert frequency trends\n            alerts_by_day = session.query(\n                func.date(Alert.timestamp).label('date'),\n                func.count(Alert.id).label('count')\n            ).filter(\n                Alert.mine_site_id == mine_site_id,\n                Alert.timestamp >= cutoff_time\n            ).group_by(func.date(Alert.timestamp)).all()\n            \n            return {\n                \"risk_trends\": [\n                    {\n                        \"timestamp\": assessment.timestamp.isoformat(),\n                        \"risk_score\": assessment.risk_score,\n                        \"risk_level\": assessment.risk_level\n                    }\n                    for assessment in risk_assessments\n                ],\n                \"alert_frequency\": [\n                    {\n                        \"date\": alert_day.date.isoformat(),\n                        \"count\": alert_day.count\n                    }\n                    for alert_day in alerts_by_day\n                ]\n            }\n            \n        finally:\n            self.db_manager.close_session(session)\n\n# Global database manager instance\nrockfall_db = RockfallDatabaseManager()","size_bytes":17951},"attached_assets/extracted/MineRockGuard/database/schema.py":{"content":"\"\"\"\nDatabase schema for the Rockfall Prediction System\nManages sensor data, alerts, mine sites, and historical analysis\n\"\"\"\n\nfrom sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Boolean, Text, JSON, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, relationship\nfrom sqlalchemy.sql import func\nimport os\n\nBase = declarative_base()\n\nclass MineSite(Base):\n    \"\"\"Mining site information\"\"\"\n    __tablename__ = 'mine_sites'\n    \n    id = Column(Integer, primary_key=True)\n    name = Column(String(100), nullable=False)\n    location = Column(String(200), nullable=False)\n    coordinates = Column(JSON)  # {\"lat\": float, \"lon\": float}\n    site_boundaries = Column(JSON)  # Polygon coordinates\n    active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=func.now())\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())\n    \n    # Relationships\n    sensors = relationship(\"Sensor\", back_populates=\"mine_site\")\n    alerts = relationship(\"Alert\", back_populates=\"mine_site\")\n    risk_assessments = relationship(\"RiskAssessment\", back_populates=\"mine_site\")\n\nclass Sensor(Base):\n    \"\"\"IoT sensor information and metadata\"\"\"\n    __tablename__ = 'sensors'\n    \n    id = Column(Integer, primary_key=True)\n    sensor_id = Column(String(50), unique=True, nullable=False)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    sensor_type = Column(String(50), nullable=False)  # displacement, strain, pressure, etc.\n    coordinates = Column(JSON)  # {\"x\": float, \"y\": float, \"z\": float}\n    installation_date = Column(DateTime, default=func.now())\n    last_maintenance = Column(DateTime)\n    status = Column(String(20), default='active')  # active, inactive, maintenance\n    calibration_data = Column(JSON)\n    communication_protocol = Column(String(30))  # LoRaWAN, MQTT, HTTP, etc.\n    battery_level = Column(Float)\n    signal_strength = Column(Float)\n    created_at = Column(DateTime, default=func.now())\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())\n    \n    # Relationships\n    mine_site = relationship(\"MineSite\", back_populates=\"sensors\")\n    readings = relationship(\"SensorReading\", back_populates=\"sensor\")\n\nclass SensorReading(Base):\n    \"\"\"Individual sensor data readings\"\"\"\n    __tablename__ = 'sensor_readings'\n    \n    id = Column(Integer, primary_key=True)\n    sensor_id = Column(Integer, ForeignKey('sensors.id'), nullable=False)\n    timestamp = Column(DateTime, default=func.now())\n    value = Column(Float, nullable=False)\n    unit = Column(String(20))\n    quality_score = Column(Float, default=1.0)  # Data quality indicator\n    processed = Column(Boolean, default=False)\n    anomaly_detected = Column(Boolean, default=False)\n    sensor_metadata = Column(JSON)  # Additional sensor-specific data\n    \n    # Relationships\n    sensor = relationship(\"Sensor\", back_populates=\"readings\")\n\nclass EnvironmentalData(Base):\n    \"\"\"Environmental conditions affecting rockfall risk\"\"\"\n    __tablename__ = 'environmental_data'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    timestamp = Column(DateTime, default=func.now())\n    temperature = Column(Float)\n    humidity = Column(Float)\n    wind_speed = Column(Float)\n    wind_direction = Column(Float)\n    precipitation = Column(Float)\n    atmospheric_pressure = Column(Float)\n    seismic_activity = Column(Float)\n    source = Column(String(50))  # weather_api, local_station, etc.\n\nclass RiskAssessment(Base):\n    \"\"\"ML-generated risk assessments\"\"\"\n    __tablename__ = 'risk_assessments'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    timestamp = Column(DateTime, default=func.now())\n    risk_level = Column(String(20), nullable=False)  # low, medium, high, critical\n    risk_score = Column(Float, nullable=False)  # 0-100\n    affected_zones = Column(JSON)  # List of zone coordinates\n    contributing_factors = Column(JSON)  # Factors that influenced the prediction\n    model_version = Column(String(20))\n    confidence_score = Column(Float)\n    predicted_timeframe = Column(String(50))  # \"next_24h\", \"next_week\", etc.\n    recommendations = Column(Text)\n    \n    # Relationships\n    mine_site = relationship(\"MineSite\", back_populates=\"risk_assessments\")\n\nclass Alert(Base):\n    \"\"\"Alert and notification records\"\"\"\n    __tablename__ = 'alerts'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    alert_type = Column(String(50), nullable=False)  # rockfall_warning, sensor_failure, etc.\n    severity = Column(String(20), nullable=False)  # low, medium, high, critical\n    title = Column(String(200), nullable=False)\n    message = Column(Text, nullable=False)\n    location = Column(JSON)  # Specific coordinates if applicable\n    triggered_by = Column(String(100))  # sensor_id or system component\n    timestamp = Column(DateTime, default=func.now())\n    acknowledged = Column(Boolean, default=False)\n    acknowledged_by = Column(String(100))\n    acknowledged_at = Column(DateTime)\n    resolved = Column(Boolean, default=False)\n    resolved_by = Column(String(100))\n    resolved_at = Column(DateTime)\n    actions_taken = Column(Text)\n    \n    # Notification channels used\n    sms_sent = Column(Boolean, default=False)\n    email_sent = Column(Boolean, default=False)\n    siren_activated = Column(Boolean, default=False)\n    radio_broadcast = Column(Boolean, default=False)\n    \n    # Relationships\n    mine_site = relationship(\"MineSite\", back_populates=\"alerts\")\n\nclass DroneImagery(Base):\n    \"\"\"Drone imagery and analysis data\"\"\"\n    __tablename__ = 'drone_imagery'\n    \n    id = Column(Integer, primary_key=True)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'), nullable=False)\n    flight_id = Column(String(50), nullable=False)\n    timestamp = Column(DateTime, default=func.now())\n    image_path = Column(String(500))  # File system path or cloud URL\n    coordinates = Column(JSON)  # GPS coordinates where image was taken\n    altitude = Column(Float)\n    camera_angle = Column(Float)\n    weather_conditions = Column(String(100))\n    \n    # AI Analysis results\n    processed = Column(Boolean, default=False)\n    cracks_detected = Column(Integer, default=0)\n    crack_analysis = Column(JSON)  # Detailed crack analysis\n    slope_stability_score = Column(Float)\n    anomalies_detected = Column(JSON)\n    change_detection = Column(JSON)  # Comparison with previous images\n    \n    analysis_model_version = Column(String(20))\n    processing_timestamp = Column(DateTime)\n\nclass SystemLog(Base):\n    \"\"\"System operation and maintenance logs\"\"\"\n    __tablename__ = 'system_logs'\n    \n    id = Column(Integer, primary_key=True)\n    timestamp = Column(DateTime, default=func.now())\n    level = Column(String(20), nullable=False)  # DEBUG, INFO, WARNING, ERROR, CRITICAL\n    component = Column(String(50), nullable=False)  # sensor_manager, ml_engine, etc.\n    message = Column(Text, nullable=False)\n    details = Column(JSON)  # Additional structured data\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'))\n    user_id = Column(String(50))\n\nclass CommunicationLog(Base):\n    \"\"\"Communication system logs (LoRaWAN, radio, etc.)\"\"\"\n    __tablename__ = 'communication_logs'\n    \n    id = Column(Integer, primary_key=True)\n    timestamp = Column(DateTime, default=func.now())\n    protocol = Column(String(30), nullable=False)  # LoRaWAN, radio, MQTT, etc.\n    direction = Column(String(10), nullable=False)  # inbound, outbound\n    source = Column(String(100))\n    destination = Column(String(100))\n    message_type = Column(String(50))\n    payload = Column(Text)\n    signal_strength = Column(Float)\n    success = Column(Boolean, default=True)\n    error_details = Column(Text)\n    mine_site_id = Column(Integer, ForeignKey('mine_sites.id'))\n\n# Database connection and session management\nclass DatabaseManager:\n    def __init__(self):\n        self.database_url = os.getenv('DATABASE_URL')\n        if not self.database_url:\n            raise ValueError(\"DATABASE_URL environment variable not found\")\n        \n        self.engine = create_engine(self.database_url)\n        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)\n    \n    def create_tables(self):\n        \"\"\"Create all database tables\"\"\"\n        Base.metadata.create_all(bind=self.engine)\n    \n    def get_session(self):\n        \"\"\"Get a database session\"\"\"\n        return self.SessionLocal()\n    \n    def close_session(self, session):\n        \"\"\"Close a database session\"\"\"\n        session.close()\n\n# Global database manager instance\ndb_manager = DatabaseManager()","size_bytes":8861},"attached_assets/extracted/MineRockGuard/hardware/siren_control.py":{"content":"\"\"\"\nPhysical Siren System Integration and Emergency Response Protocols\nHandles hardware siren control, emergency broadcast systems, and response coordination\n\"\"\"\n\nimport json\nimport logging\nimport time\nimport threading\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any, Optional, Callable\nfrom dataclasses import dataclass\nfrom enum import Enum\nimport requests\nfrom database.database_manager import RockfallDatabaseManager\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass SirenType(Enum):\n    \"\"\"Types of emergency sirens\"\"\"\n    WARNING = \"warning\"\n    EVACUATION = \"evacuation\"\n    ALL_CLEAR = \"all_clear\"\n    TEST = \"test\"\n\nclass BroadcastChannel(Enum):\n    \"\"\"Emergency broadcast channels\"\"\"\n    LOUDSPEAKER = \"loudspeaker\"\n    RADIO_UHF = \"radio_uhf\"\n    RADIO_VHF = \"radio_vhf\"\n    PA_SYSTEM = \"pa_system\"\n    MOBILE_ALERT = \"mobile_alert\"\n    SATELLITE = \"satellite\"\n\n@dataclass\nclass SirenDevice:\n    \"\"\"Physical siren device configuration\"\"\"\n    siren_id: str\n    device_type: str\n    location: Dict[str, float]\n    coverage_radius: float  # meters\n    max_decibel: int\n    power_source: str  # mains, battery, solar\n    communication_method: str  # ethernet, radio, cellular\n    \n    # Status\n    operational: bool = True\n    last_test: Optional[datetime] = None\n    battery_level: Optional[float] = None\n    signal_strength: Optional[float] = None\n\n@dataclass\nclass EmergencyProtocol:\n    \"\"\"Emergency response protocol definition\"\"\"\n    protocol_id: str\n    name: str\n    trigger_conditions: List[str]\n    priority_level: int  # 1-5, 5 being highest\n    \n    # Response actions\n    siren_pattern: str\n    broadcast_channels: List[BroadcastChannel]\n    voice_message: str\n    auto_escalation: bool\n    evacuation_required: bool\n    \n    # Timing\n    activation_delay: int  # seconds\n    duration: int  # seconds\n    repeat_interval: int  # seconds\n\nclass SirenController:\n    \"\"\"Hardware siren control system\"\"\"\n    \n    def __init__(self):\n        self.db_manager = RockfallDatabaseManager()\n        self.sirens: Dict[str, SirenDevice] = {}\n        self.active_alerts: Dict[str, Dict] = {}\n        self.emergency_protocols: Dict[str, EmergencyProtocol] = {}\n        self.is_running = False\n        \n        # Load configurations\n        self._initialize_siren_devices()\n        self._initialize_emergency_protocols()\n        \n        # Hardware interface simulation\n        self.hardware_interface = self._initialize_hardware_interface()\n    \n    def _initialize_siren_devices(self):\n        \"\"\"Initialize siren device configurations\"\"\"\n        # In production, this would load from database or configuration files\n        default_sirens = [\n            SirenDevice(\n                siren_id=\"SIREN_NORTH_001\",\n                device_type=\"Whelen WPS-2900\",\n                location={\"lat\": 39.7402, \"lon\": -104.9913, \"elevation\": 1650},\n                coverage_radius=1000,\n                max_decibel=130,\n                power_source=\"mains_battery_backup\",\n                communication_method=\"ethernet\",\n                operational=True,\n                battery_level=95.0,\n                signal_strength=-45.0\n            ),\n            SirenDevice(\n                siren_id=\"SIREN_SOUTH_002\",\n                device_type=\"Federal Signal Modulator\",\n                location={\"lat\": 39.7382, \"lon\": -104.9893, \"elevation\": 1645},\n                coverage_radius=800,\n                max_decibel=125,\n                power_source=\"solar_battery\",\n                communication_method=\"radio_uhf\",\n                operational=True,\n                battery_level=87.0,\n                signal_strength=-52.0\n            ),\n            SirenDevice(\n                siren_id=\"SIREN_EAST_003\",\n                device_type=\"Acoustic Technology ATU\",\n                location={\"lat\": 39.7392, \"lon\": -104.9883, \"elevation\": 1655},\n                coverage_radius=1200,\n                max_decibel=135,\n                power_source=\"mains\",\n                communication_method=\"cellular\",\n                operational=True,\n                signal_strength=-38.0\n            ),\n            SirenDevice(\n                siren_id=\"MOBILE_UNIT_004\",\n                device_type=\"Portable Emergency Siren\",\n                location={\"lat\": 39.7400, \"lon\": -104.9900, \"elevation\": 1650},\n                coverage_radius=500,\n                max_decibel=120,\n                power_source=\"battery\",\n                communication_method=\"radio_vhf\",\n                operational=True,\n                battery_level=78.0,\n                signal_strength=-48.0\n            )\n        ]\n        \n        for siren in default_sirens:\n            self.sirens[siren.siren_id] = siren\n        \n        logger.info(f\"Initialized {len(self.sirens)} siren devices\")\n    \n    def _initialize_emergency_protocols(self):\n        \"\"\"Initialize emergency response protocols\"\"\"\n        protocols = [\n            EmergencyProtocol(\n                protocol_id=\"ROCKFALL_WARNING\",\n                name=\"Rockfall Warning\",\n                trigger_conditions=[\"high_risk_detected\", \"crack_propagation\", \"slope_instability\"],\n                priority_level=4,\n                siren_pattern=\"alternating_tone\",\n                broadcast_channels=[BroadcastChannel.LOUDSPEAKER, BroadcastChannel.RADIO_UHF, BroadcastChannel.MOBILE_ALERT],\n                voice_message=\"ATTENTION: Rockfall warning in effect. All personnel in affected areas move to safe zones immediately.\",\n                auto_escalation=True,\n                evacuation_required=False,\n                activation_delay=5,\n                duration=60,\n                repeat_interval=300\n            ),\n            EmergencyProtocol(\n                protocol_id=\"IMMEDIATE_EVACUATION\",\n                name=\"Immediate Evacuation\",\n                trigger_conditions=[\"imminent_rockfall\", \"critical_instability\", \"major_crack_detected\"],\n                priority_level=5,\n                siren_pattern=\"continuous_wail\",\n                broadcast_channels=[BroadcastChannel.LOUDSPEAKER, BroadcastChannel.RADIO_UHF, BroadcastChannel.RADIO_VHF, BroadcastChannel.PA_SYSTEM, BroadcastChannel.MOBILE_ALERT],\n                voice_message=\"EMERGENCY EVACUATION: Immediate rockfall danger. All personnel evacuate affected areas NOW. Proceed to emergency assembly points.\",\n                auto_escalation=True,\n                evacuation_required=True,\n                activation_delay=0,\n                duration=120,\n                repeat_interval=180\n            ),\n            EmergencyProtocol(\n                protocol_id=\"EQUIPMENT_FAILURE\",\n                name=\"Equipment Failure Alert\",\n                trigger_conditions=[\"sensor_network_failure\", \"communication_loss\", \"power_failure\"],\n                priority_level=2,\n                siren_pattern=\"two_tone\",\n                broadcast_channels=[BroadcastChannel.RADIO_UHF, BroadcastChannel.MOBILE_ALERT],\n                voice_message=\"Notice: Equipment failure detected. Maintenance teams respond to affected areas.\",\n                auto_escalation=False,\n                evacuation_required=False,\n                activation_delay=30,\n                duration=30,\n                repeat_interval=600\n            ),\n            EmergencyProtocol(\n                protocol_id=\"ALL_CLEAR\",\n                name=\"All Clear Signal\",\n                trigger_conditions=[\"danger_passed\", \"manual_all_clear\"],\n                priority_level=1,\n                siren_pattern=\"steady_tone\",\n                broadcast_channels=[BroadcastChannel.LOUDSPEAKER, BroadcastChannel.RADIO_UHF, BroadcastChannel.MOBILE_ALERT],\n                voice_message=\"All clear. Normal operations may resume. Continue to exercise caution in previously affected areas.\",\n                auto_escalation=False,\n                evacuation_required=False,\n                activation_delay=0,\n                duration=30,\n                repeat_interval=0\n            )\n        ]\n        \n        for protocol in protocols:\n            self.emergency_protocols[protocol.protocol_id] = protocol\n        \n        logger.info(f\"Initialized {len(self.emergency_protocols)} emergency protocols\")\n    \n    def _initialize_hardware_interface(self) -> Dict[str, Any]:\n        \"\"\"Initialize hardware interface (simulated)\"\"\"\n        # In production, this would initialize actual hardware interfaces\n        return {\n            'ethernet_interface': {'status': 'connected', 'ip': '192.168.1.100'},\n            'radio_uhf_interface': {'status': 'operational', 'frequency': '450.125'},\n            'radio_vhf_interface': {'status': 'operational', 'frequency': '154.340'},\n            'cellular_interface': {'status': 'connected', 'signal': -65},\n            'pa_system_interface': {'status': 'operational', 'zones': 12}\n        }\n    \n    def activate_emergency_protocol(self, protocol_id: str, trigger_reason: str, \n                                  affected_areas: List[Dict], manual_override: bool = False) -> bool:\n        \"\"\"Activate an emergency protocol\"\"\"\n        try:\n            if protocol_id not in self.emergency_protocols:\n                logger.error(f\"Unknown emergency protocol: {protocol_id}\")\n                return False\n            \n            protocol = self.emergency_protocols[protocol_id]\n            \n            # Check if already active\n            if protocol_id in self.active_alerts:\n                logger.warning(f\"Protocol {protocol_id} already active\")\n                return True\n            \n            logger.info(f\"Activating emergency protocol: {protocol.name}\")\n            \n            # Create alert record\n            alert_record = {\n                'protocol_id': protocol_id,\n                'trigger_reason': trigger_reason,\n                'affected_areas': affected_areas,\n                'activation_time': datetime.now(),\n                'manual_override': manual_override,\n                'status': 'activating'\n            }\n            \n            self.active_alerts[protocol_id] = alert_record\n            \n            # Apply activation delay if not manual override\n            if not manual_override and protocol.activation_delay > 0:\n                logger.info(f\"Applying {protocol.activation_delay}s activation delay\")\n                time.sleep(protocol.activation_delay)\n            \n            # Activate sirens with appropriate pattern\n            affected_sirens = self._get_sirens_for_areas(affected_areas)\n            for siren_id in affected_sirens:\n                self._activate_siren(siren_id, protocol.siren_pattern, protocol.duration)\n            \n            # Broadcast voice message\n            self._broadcast_voice_message(protocol.voice_message, protocol.broadcast_channels)\n            \n            # Send mobile alerts\n            if BroadcastChannel.MOBILE_ALERT in protocol.broadcast_channels:\n                self._send_mobile_alerts(protocol.voice_message, affected_areas)\n            \n            # Store in database\n            self._log_emergency_activation(protocol_id, trigger_reason, affected_areas)\n            \n            # Update status\n            alert_record['status'] = 'active'\n            alert_record['sirens_activated'] = affected_sirens\n            \n            # Schedule repeat if configured\n            if protocol.repeat_interval > 0:\n                threading.Timer(\n                    protocol.repeat_interval,\n                    self._repeat_protocol,\n                    args=[protocol_id]\n                ).start()\n            \n            logger.info(f\"Emergency protocol {protocol.name} activated successfully\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error activating emergency protocol {protocol_id}: {e}\")\n            return False\n    \n    def _get_sirens_for_areas(self, affected_areas: List[Dict]) -> List[str]:\n        \"\"\"Get sirens that cover the affected areas\"\"\"\n        affected_sirens = []\n        \n        for area in affected_areas:\n            area_lat = area.get('lat', 0)\n            area_lon = area.get('lon', 0)\n            \n            for siren_id, siren in self.sirens.items():\n                if not siren.operational:\n                    continue\n                \n                # Calculate distance (simplified)\n                siren_lat = siren.location['lat']\n                siren_lon = siren.location['lon']\n                \n                # Simplified distance calculation\n                distance = ((area_lat - siren_lat) ** 2 + (area_lon - siren_lon) ** 2) ** 0.5 * 111000  # Rough conversion to meters\n                \n                if distance <= siren.coverage_radius:\n                    if siren_id not in affected_sirens:\n                        affected_sirens.append(siren_id)\n        \n        # If no specific sirens cover the area, activate all operational sirens\n        if not affected_sirens:\n            affected_sirens = [sid for sid, siren in self.sirens.items() if siren.operational]\n        \n        return affected_sirens\n    \n    def _activate_siren(self, siren_id: str, pattern: str, duration: int):\n        \"\"\"Activate a specific siren with given pattern\"\"\"\n        try:\n            if siren_id not in self.sirens:\n                logger.error(f\"Unknown siren: {siren_id}\")\n                return\n            \n            siren = self.sirens[siren_id]\n            \n            if not siren.operational:\n                logger.warning(f\"Siren {siren_id} not operational\")\n                return\n            \n            # In production, this would send actual hardware commands\n            logger.info(f\"Activating siren {siren_id} with pattern {pattern} for {duration}s\")\n            \n            # Simulate hardware activation based on communication method\n            if siren.communication_method == \"ethernet\":\n                self._send_ethernet_command(siren_id, pattern, duration)\n            elif siren.communication_method == \"radio_uhf\":\n                self._send_radio_command(siren_id, pattern, duration, \"UHF\")\n            elif siren.communication_method == \"radio_vhf\":\n                self._send_radio_command(siren_id, pattern, duration, \"VHF\")\n            elif siren.communication_method == \"cellular\":\n                self._send_cellular_command(siren_id, pattern, duration)\n            \n            logger.info(f\"Siren {siren_id} activation command sent\")\n            \n        except Exception as e:\n            logger.error(f\"Error activating siren {siren_id}: {e}\")\n    \n    def _send_ethernet_command(self, siren_id: str, pattern: str, duration: int):\n        \"\"\"Send siren command via Ethernet (simulated)\"\"\"\n        # In production, this would use actual network protocols\n        command = {\n            'device_id': siren_id,\n            'action': 'activate',\n            'pattern': pattern,\n            'duration': duration,\n            'timestamp': datetime.now().isoformat()\n        }\n        \n        logger.info(f\"Ethernet command to {siren_id}: {command}\")\n        # Simulate network call\n        # requests.post(f\"http://{siren.ip_address}/activate\", json=command)\n    \n    def _send_radio_command(self, siren_id: str, pattern: str, duration: int, band: str):\n        \"\"\"Send siren command via radio (simulated)\"\"\"\n        # In production, this would use radio communication protocols\n        command = f\"SIREN,{siren_id},{pattern},{duration}\"\n        \n        logger.info(f\"{band} radio command to {siren_id}: {command}\")\n        # Simulate radio transmission\n    \n    def _send_cellular_command(self, siren_id: str, pattern: str, duration: int):\n        \"\"\"Send siren command via cellular (simulated)\"\"\"\n        # In production, this would use cellular/SMS/data protocols\n        command = {\n            'device_id': siren_id,\n            'action': 'activate',\n            'pattern': pattern,\n            'duration': duration\n        }\n        \n        logger.info(f\"Cellular command to {siren_id}: {command}\")\n        # Simulate cellular command\n    \n    def _broadcast_voice_message(self, message: str, channels: List[BroadcastChannel]):\n        \"\"\"Broadcast voice message on specified channels\"\"\"\n        logger.info(f\"Broadcasting message on {len(channels)} channels: {message}\")\n        \n        for channel in channels:\n            try:\n                if channel == BroadcastChannel.LOUDSPEAKER:\n                    self._broadcast_loudspeaker(message)\n                elif channel == BroadcastChannel.RADIO_UHF:\n                    self._broadcast_radio(message, \"UHF\")\n                elif channel == BroadcastChannel.RADIO_VHF:\n                    self._broadcast_radio(message, \"VHF\")\n                elif channel == BroadcastChannel.PA_SYSTEM:\n                    self._broadcast_pa_system(message)\n                elif channel == BroadcastChannel.SATELLITE:\n                    self._broadcast_satellite(message)\n                    \n            except Exception as e:\n                logger.error(f\"Error broadcasting on {channel.value}: {e}\")\n    \n    def _broadcast_loudspeaker(self, message: str):\n        \"\"\"Broadcast via loudspeaker system\"\"\"\n        logger.info(f\"Loudspeaker broadcast: {message}\")\n        # In production, this would interface with PA system\n    \n    def _broadcast_radio(self, message: str, band: str):\n        \"\"\"Broadcast via radio system\"\"\"\n        logger.info(f\"{band} radio broadcast: {message}\")\n        # In production, this would interface with radio system\n    \n    def _broadcast_pa_system(self, message: str):\n        \"\"\"Broadcast via PA system\"\"\"\n        logger.info(f\"PA system broadcast: {message}\")\n        # In production, this would interface with building PA system\n    \n    def _broadcast_satellite(self, message: str):\n        \"\"\"Broadcast via satellite communication\"\"\"\n        logger.info(f\"Satellite broadcast: {message}\")\n        # In production, this would use satellite communication\n    \n    def _send_mobile_alerts(self, message: str, affected_areas: List[Dict]):\n        \"\"\"Send mobile alerts to personnel in affected areas\"\"\"\n        logger.info(f\"Sending mobile alerts for {len(affected_areas)} areas\")\n        \n        # In production, this would integrate with mobile alert systems\n        # For now, simulate sending alerts\n        \n        for area in affected_areas:\n            logger.info(f\"Mobile alert for area {area}: {message}\")\n    \n    def _log_emergency_activation(self, protocol_id: str, trigger_reason: str, affected_areas: List[Dict]):\n        \"\"\"Log emergency activation in database\"\"\"\n        try:\n            # Create alert in main database\n            alert_id = self.db_manager.create_alert(\n                mine_site_id=1,\n                alert_type=\"emergency_protocol\",\n                severity=\"high\",\n                title=f\"Emergency Protocol Activated: {protocol_id}\",\n                message=f\"Trigger: {trigger_reason}\",\n                location=affected_areas[0] if affected_areas else None,\n                triggered_by=\"siren_control_system\"\n            )\n            \n            logger.info(f\"Emergency activation logged with alert ID: {alert_id}\")\n            \n        except Exception as e:\n            logger.error(f\"Error logging emergency activation: {e}\")\n    \n    def _repeat_protocol(self, protocol_id: str):\n        \"\"\"Repeat an active protocol\"\"\"\n        if protocol_id not in self.active_alerts:\n            return\n        \n        alert_record = self.active_alerts[protocol_id]\n        protocol = self.emergency_protocols[protocol_id]\n        \n        logger.info(f\"Repeating emergency protocol: {protocol.name}\")\n        \n        # Reactivate sirens\n        for siren_id in alert_record.get('sirens_activated', []):\n            self._activate_siren(siren_id, protocol.siren_pattern, protocol.duration)\n        \n        # Rebroadcast message\n        self._broadcast_voice_message(protocol.voice_message, protocol.broadcast_channels)\n        \n        # Schedule next repeat if still active\n        if protocol.repeat_interval > 0 and protocol_id in self.active_alerts:\n            threading.Timer(\n                protocol.repeat_interval,\n                self._repeat_protocol,\n                args=[protocol_id]\n            ).start()\n    \n    def deactivate_protocol(self, protocol_id: str, reason: str = \"manual_deactivation\") -> bool:\n        \"\"\"Deactivate an emergency protocol\"\"\"\n        try:\n            if protocol_id not in self.active_alerts:\n                logger.warning(f\"Protocol {protocol_id} not active\")\n                return True\n            \n            alert_record = self.active_alerts[protocol_id]\n            \n            logger.info(f\"Deactivating emergency protocol: {protocol_id}\")\n            \n            # Stop all sirens for this protocol\n            for siren_id in alert_record.get('sirens_activated', []):\n                self._deactivate_siren(siren_id)\n            \n            # Remove from active alerts\n            del self.active_alerts[protocol_id]\n            \n            # Log deactivation\n            logger.info(f\"Emergency protocol {protocol_id} deactivated - Reason: {reason}\")\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error deactivating protocol {protocol_id}: {e}\")\n            return False\n    \n    def _deactivate_siren(self, siren_id: str):\n        \"\"\"Deactivate a specific siren\"\"\"\n        try:\n            logger.info(f\"Deactivating siren {siren_id}\")\n            \n            siren = self.sirens[siren_id]\n            \n            # Send deactivation command based on communication method\n            if siren.communication_method == \"ethernet\":\n                self._send_ethernet_command(siren_id, \"stop\", 0)\n            elif siren.communication_method == \"radio_uhf\":\n                self._send_radio_command(siren_id, \"stop\", 0, \"UHF\")\n            elif siren.communication_method == \"radio_vhf\":\n                self._send_radio_command(siren_id, \"stop\", 0, \"VHF\")\n            elif siren.communication_method == \"cellular\":\n                self._send_cellular_command(siren_id, \"stop\", 0)\n            \n            logger.info(f\"Siren {siren_id} deactivation command sent\")\n            \n        except Exception as e:\n            logger.error(f\"Error deactivating siren {siren_id}: {e}\")\n    \n    def test_siren_system(self, siren_id: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Test siren system functionality\"\"\"\n        test_results = {}\n        \n        try:\n            sirens_to_test = [siren_id] if siren_id else list(self.sirens.keys())\n            \n            for sid in sirens_to_test:\n                if sid not in self.sirens:\n                    test_results[sid] = {\"status\": \"error\", \"message\": \"Siren not found\"}\n                    continue\n                \n                siren = self.sirens[sid]\n                \n                logger.info(f\"Testing siren {sid}\")\n                \n                # Test communication\n                comm_test = self._test_siren_communication(sid)\n                \n                # Test audio output (simulated)\n                audio_test = self._test_siren_audio(sid)\n                \n                # Update last test time\n                siren.last_test = datetime.now()\n                \n                test_results[sid] = {\n                    \"status\": \"pass\" if comm_test and audio_test else \"fail\",\n                    \"communication\": comm_test,\n                    \"audio_output\": audio_test,\n                    \"battery_level\": siren.battery_level,\n                    \"signal_strength\": siren.signal_strength,\n                    \"last_test\": siren.last_test.isoformat()\n                }\n            \n            logger.info(f\"Siren system test completed for {len(sirens_to_test)} devices\")\n            \n        except Exception as e:\n            logger.error(f\"Error during siren system test: {e}\")\n            test_results[\"error\"] = str(e)\n        \n        return test_results\n    \n    def _test_siren_communication(self, siren_id: str) -> bool:\n        \"\"\"Test communication with a siren\"\"\"\n        try:\n            # In production, this would send actual test commands\n            logger.info(f\"Testing communication with siren {siren_id}\")\n            \n            # Simulate communication test\n            siren = self.sirens[siren_id]\n            \n            # Check signal strength\n            if siren.signal_strength and siren.signal_strength < -80:\n                logger.warning(f\"Weak signal for siren {siren_id}: {siren.signal_strength} dBm\")\n                return False\n            \n            # Simulate successful communication\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Communication test failed for siren {siren_id}: {e}\")\n            return False\n    \n    def _test_siren_audio(self, siren_id: str) -> bool:\n        \"\"\"Test audio output of a siren\"\"\"\n        try:\n            logger.info(f\"Testing audio output for siren {siren_id}\")\n            \n            # In production, this would activate the siren briefly for testing\n            self._activate_siren(siren_id, \"test\", 5)  # 5-second test\n            \n            # Simulate successful audio test\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Audio test failed for siren {siren_id}: {e}\")\n            return False\n    \n    def get_system_status(self) -> Dict[str, Any]:\n        \"\"\"Get overall siren system status\"\"\"\n        try:\n            total_sirens = len(self.sirens)\n            operational_sirens = sum(1 for s in self.sirens.values() if s.operational)\n            \n            # Battery status\n            battery_sirens = [s for s in self.sirens.values() if s.battery_level is not None]\n            avg_battery = sum(s.battery_level for s in battery_sirens) / len(battery_sirens) if battery_sirens else 0\n            \n            # Signal strength\n            signal_sirens = [s for s in self.sirens.values() if s.signal_strength is not None]\n            avg_signal = sum(s.signal_strength for s in signal_sirens) / len(signal_sirens) if signal_sirens else 0\n            \n            # Last test times\n            tested_sirens = [s for s in self.sirens.values() if s.last_test is not None]\n            oldest_test = min((s.last_test for s in tested_sirens), default=None)\n            \n            status = {\n                \"total_sirens\": total_sirens,\n                \"operational_sirens\": operational_sirens,\n                \"offline_sirens\": total_sirens - operational_sirens,\n                \"average_battery_level\": avg_battery,\n                \"average_signal_strength\": avg_signal,\n                \"active_protocols\": len(self.active_alerts),\n                \"oldest_test_date\": oldest_test.isoformat() if oldest_test else None,\n                \"system_health\": \"good\" if operational_sirens >= total_sirens * 0.8 else \"degraded\",\n                \"individual_sirens\": [\n                    {\n                        \"siren_id\": sid,\n                        \"operational\": siren.operational,\n                        \"battery_level\": siren.battery_level,\n                        \"signal_strength\": siren.signal_strength,\n                        \"last_test\": siren.last_test.isoformat() if siren.last_test else None\n                    }\n                    for sid, siren in self.sirens.items()\n                ]\n            }\n            \n            return status\n            \n        except Exception as e:\n            logger.error(f\"Error getting system status: {e}\")\n            return {\"error\": str(e)}\n\n# Global siren controller instance\nsiren_controller = SirenController()","size_bytes":27716},"attached_assets/extracted/MineRockGuard/iot/sensor_manager.py":{"content":"\"\"\"\nAdvanced IoT Sensor Management System\nHandles real sensor hardware, protocol management, and data validation\n\"\"\"\n\nimport asyncio\nimport json\nimport logging\nimport time\nfrom datetime import datetime, timezone, timedelta\nfrom typing import Dict, List, Any, Optional, Callable\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\nimport threading\nfrom queue import Queue\nimport requests\nfrom database.database_manager import RockfallDatabaseManager\nfrom database.data_ingestion import IoTDataIngestion, SensorData\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass SensorProtocol(Enum):\n    \"\"\"Supported sensor communication protocols\"\"\"\n    LORAWAN = \"lorawan\"\n    MQTT = \"mqtt\"\n    HTTP = \"http\"\n    MODBUS = \"modbus\"\n    ZIGBEE = \"zigbee\"\n    WIFI = \"wifi\"\n    CELLULAR = \"cellular\"\n\nclass SensorStatus(Enum):\n    \"\"\"Sensor operational status\"\"\"\n    ONLINE = \"online\"\n    OFFLINE = \"offline\"\n    MAINTENANCE = \"maintenance\"\n    ERROR = \"error\"\n    LOW_BATTERY = \"low_battery\"\n    WEAK_SIGNAL = \"weak_signal\"\n\n@dataclass\nclass HardwareSensor:\n    \"\"\"Hardware sensor configuration and status\"\"\"\n    sensor_id: str\n    sensor_type: str\n    protocol: SensorProtocol\n    device_address: str\n    mine_site_id: int\n    coordinates: Dict[str, float]\n    \n    # Hardware specifications\n    model: str\n    manufacturer: str\n    firmware_version: str\n    calibration_date: datetime\n    \n    # Operational status\n    status: SensorStatus = SensorStatus.ONLINE\n    battery_level: float = 100.0\n    signal_strength: float = -50.0  # dBm\n    last_reading: Optional[datetime] = None\n    \n    # Communication settings\n    reading_interval: int = 60  # seconds\n    transmission_power: int = 14  # dBm\n    data_rate: str = \"SF7BW125\"  # LoRaWAN data rate\n    \n    # Quality metrics\n    error_count: int = 0\n    missed_readings: int = 0\n    data_quality_score: float = 1.0\n\n@dataclass\nclass SensorReading:\n    \"\"\"Enhanced sensor reading with quality metrics\"\"\"\n    sensor_id: str\n    timestamp: datetime\n    value: float\n    unit: str\n    quality_score: float\n    temperature: Optional[float] = None  # Sensor temperature\n    voltage: Optional[float] = None  # Supply voltage\n    rssi: Optional[float] = None  # Signal strength\n    snr: Optional[float] = None  # Signal-to-noise ratio\n    \nclass IoTSensorManager:\n    \"\"\"Advanced IoT sensor management with real hardware support\"\"\"\n    \n    def __init__(self):\n        self.db_manager = RockfallDatabaseManager()\n        self.data_ingestion = IoTDataIngestion()\n        self.sensors: Dict[str, HardwareSensor] = {}\n        self.reading_queue = Queue()\n        self.is_running = False\n        \n        # Protocol handlers\n        self.protocol_handlers = {\n            SensorProtocol.HTTP: self._handle_http_sensor,\n            SensorProtocol.MQTT: self._handle_mqtt_sensor,\n            SensorProtocol.LORAWAN: self._handle_lorawan_sensor,\n            SensorProtocol.MODBUS: self._handle_modbus_sensor\n        }\n        \n        # Load sensor configurations\n        self._load_sensor_configurations()\n    \n    def _load_sensor_configurations(self):\n        \"\"\"Load sensor configurations from database and configuration files\"\"\"\n        try:\n            # Get sensors from database\n            mine_sites = self.db_manager.get_mine_sites()\n            for site in mine_sites:\n                db_sensors = self.db_manager.get_sensors_for_site(site['id'])\n                \n                for db_sensor in db_sensors:\n                    # Create hardware sensor configuration\n                    hardware_sensor = HardwareSensor(\n                        sensor_id=db_sensor['sensor_id'],\n                        sensor_type=db_sensor['sensor_type'],\n                        protocol=SensorProtocol.LORAWAN,  # Default protocol\n                        device_address=f\"dev_{db_sensor['id']:04d}\",\n                        mine_site_id=site['id'],\n                        coordinates=db_sensor['coordinates'],\n                        model=f\"{db_sensor['sensor_type'].title()}_Pro_v2\",\n                        manufacturer=\"MineGuard Systems\",\n                        firmware_version=\"2.1.4\",\n                        calibration_date=datetime.now() - timedelta(days=30),\n                        battery_level=db_sensor.get('battery_level', 85.0),\n                        signal_strength=db_sensor.get('signal_strength', -65.0)\n                    )\n                    \n                    self.sensors[db_sensor['sensor_id']] = hardware_sensor\n            \n            logger.info(f\"Loaded {len(self.sensors)} sensor configurations\")\n            \n        except Exception as e:\n            logger.error(f\"Error loading sensor configurations: {e}\")\n    \n    def register_sensor(self, sensor_config: HardwareSensor) -> bool:\n        \"\"\"Register a new hardware sensor\"\"\"\n        try:\n            # Validate sensor configuration\n            if not self._validate_sensor_config(sensor_config):\n                return False\n            \n            # Add to sensor registry\n            self.sensors[sensor_config.sensor_id] = sensor_config\n            \n            # Initialize protocol handler\n            protocol_handler = self.protocol_handlers.get(sensor_config.protocol)\n            if protocol_handler:\n                protocol_handler(sensor_config, 'register')\n            \n            logger.info(f\"Registered sensor {sensor_config.sensor_id} with protocol {sensor_config.protocol.value}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error registering sensor {sensor_config.sensor_id}: {e}\")\n            return False\n    \n    def _validate_sensor_config(self, sensor: HardwareSensor) -> bool:\n        \"\"\"Validate sensor configuration\"\"\"\n        if not sensor.sensor_id or not sensor.sensor_type:\n            logger.error(\"Sensor ID and type are required\")\n            return False\n        \n        if sensor.sensor_id in self.sensors:\n            logger.warning(f\"Sensor {sensor.sensor_id} already registered\")\n            return False\n        \n        return True\n    \n    def _handle_http_sensor(self, sensor: HardwareSensor, action: str = 'read'):\n        \"\"\"Handle HTTP-based sensors\"\"\"\n        if action == 'register':\n            logger.info(f\"HTTP sensor {sensor.sensor_id} registered\")\n            return\n        \n        try:\n            # Simulate HTTP endpoint for sensor data\n            url = f\"http://sensor-gateway/{sensor.device_address}/data\"\n            \n            # In a real implementation, this would make an actual HTTP request\n            # response = requests.get(url, timeout=10)\n            # if response.status_code == 200:\n            #     data = response.json()\n            \n            # Simulated sensor response\n            data = {\n                'sensor_id': sensor.sensor_id,\n                'timestamp': datetime.now().isoformat(),\n                'value': self._simulate_sensor_reading(sensor.sensor_type),\n                'unit': self._get_sensor_unit(sensor.sensor_type),\n                'temperature': 23.5 + (time.time() % 10) - 5,\n                'voltage': 3.3 + (time.time() % 2) * 0.1 - 0.1,\n                'rssi': sensor.signal_strength\n            }\n            \n            self._process_sensor_data(sensor, data)\n            \n        except Exception as e:\n            logger.error(f\"Error reading HTTP sensor {sensor.sensor_id}: {e}\")\n            self._update_sensor_status(sensor.sensor_id, SensorStatus.ERROR)\n    \n    def _handle_mqtt_sensor(self, sensor: HardwareSensor, action: str = 'read'):\n        \"\"\"Handle MQTT-based sensors\"\"\"\n        if action == 'register':\n            logger.info(f\"MQTT sensor {sensor.sensor_id} registered\")\n            return\n        \n        # MQTT sensors are handled by the data ingestion system\n        # This method handles sensor-specific MQTT operations\n        pass\n    \n    def _handle_lorawan_sensor(self, sensor: HardwareSensor, action: str = 'read'):\n        \"\"\"Handle LoRaWAN sensors\"\"\"\n        if action == 'register':\n            logger.info(f\"LoRaWAN sensor {sensor.sensor_id} registered on {sensor.data_rate}\")\n            return\n        \n        try:\n            # Simulate LoRaWAN sensor communication\n            # In real implementation, this would interface with LoRaWAN gateway\n            \n            # Calculate signal quality based on distance and environmental factors\n            base_rssi = -50\n            distance_loss = -0.1 * ((sensor.coordinates['x']**2 + sensor.coordinates['y']**2)**0.5 / 100)\n            environmental_loss = -5 * (1 if datetime.now().hour in [6, 7, 18, 19] else 0)  # Weather effects\n            \n            current_rssi = base_rssi + distance_loss + environmental_loss\n            sensor.signal_strength = current_rssi\n            \n            # Generate sensor data with LoRaWAN characteristics\n            data = {\n                'device_eui': sensor.device_address,\n                'timestamp': datetime.now().isoformat(),\n                'data': {\n                    sensor.sensor_type: self._simulate_sensor_reading(sensor.sensor_type),\n                    'battery': sensor.battery_level,\n                    'temperature': 20 + (time.time() % 20) - 10\n                },\n                'rssi': current_rssi,\n                'snr': max(-20, current_rssi + 20),\n                'data_rate': sensor.data_rate,\n                'frequency': 915.2,  # MHz\n                'gateway_id': 'gw_001'\n            }\n            \n            self._process_lorawan_data(sensor, data)\n            \n        except Exception as e:\n            logger.error(f\"Error reading LoRaWAN sensor {sensor.sensor_id}: {e}\")\n            self._update_sensor_status(sensor.sensor_id, SensorStatus.ERROR)\n    \n    def _handle_modbus_sensor(self, sensor: HardwareSensor, action: str = 'read'):\n        \"\"\"Handle Modbus/RS485 sensors\"\"\"\n        if action == 'register':\n            logger.info(f\"Modbus sensor {sensor.sensor_id} registered\")\n            return\n        \n        try:\n            # Simulate Modbus RTU communication\n            # In real implementation, this would use pymodbus library\n            \n            data = {\n                'sensor_id': sensor.sensor_id,\n                'timestamp': datetime.now().isoformat(),\n                'registers': {\n                    'value': self._simulate_sensor_reading(sensor.sensor_type),\n                    'status': 0x0000,  # No errors\n                    'temperature': int((23.5 + (time.time() % 10) - 5) * 10),\n                    'voltage': int((3.3 + (time.time() % 2) * 0.1 - 0.1) * 1000)\n                }\n            }\n            \n            self._process_modbus_data(sensor, data)\n            \n        except Exception as e:\n            logger.error(f\"Error reading Modbus sensor {sensor.sensor_id}: {e}\")\n            self._update_sensor_status(sensor.sensor_id, SensorStatus.ERROR)\n    \n    def _simulate_sensor_reading(self, sensor_type: str) -> float:\n        \"\"\"Simulate realistic sensor readings\"\"\"\n        base_values = {\n            'displacement': 0.5,  # mm\n            'strain': 50.0,       # ¬µŒµ\n            'pressure': 15.2,     # kPa\n            'vibration': 2.1,     # mm/s\n            'tilt': 0.8           # degrees\n        }\n        \n        base_value = base_values.get(sensor_type, 1.0)\n        \n        # Add realistic variations\n        time_factor = time.time() % 3600  # Hourly cycle\n        noise = (time.time() % 13) / 13 * 0.2 - 0.1  # ¬±10% noise\n        trend = 0.001 * (time.time() % 86400)  # Daily trend\n        \n        return base_value * (1 + 0.3 * (time_factor / 3600) + noise + trend)\n    \n    def _get_sensor_unit(self, sensor_type: str) -> str:\n        \"\"\"Get unit for sensor type\"\"\"\n        units = {\n            'displacement': 'mm',\n            'strain': '¬µŒµ',\n            'pressure': 'kPa',\n            'vibration': 'mm/s',\n            'tilt': 'degrees'\n        }\n        return units.get(sensor_type, 'unit')\n    \n    def _process_sensor_data(self, sensor: HardwareSensor, data: Dict):\n        \"\"\"Process incoming sensor data\"\"\"\n        try:\n            # Create standardized sensor reading\n            reading = SensorReading(\n                sensor_id=sensor.sensor_id,\n                timestamp=datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00')),\n                value=float(data['value']),\n                unit=data['unit'],\n                quality_score=self._calculate_quality_score(sensor, data),\n                temperature=data.get('temperature'),\n                voltage=data.get('voltage'),\n                rssi=data.get('rssi')\n            )\n            \n            # Store in database via data ingestion system\n            sensor_data = SensorData(\n                sensor_id=reading.sensor_id,\n                timestamp=reading.timestamp,\n                value=reading.value,\n                unit=reading.unit,\n                quality_score=reading.quality_score,\n                metadata={\n                    'temperature': reading.temperature,\n                    'voltage': reading.voltage,\n                    'rssi': reading.rssi,\n                    'protocol': sensor.protocol.value\n                }\n            )\n            \n            self.data_ingestion._store_sensor_reading(sensor_data)\n            \n            # Update sensor status\n            self._update_sensor_metrics(sensor, reading)\n            \n        except Exception as e:\n            logger.error(f\"Error processing sensor data for {sensor.sensor_id}: {e}\")\n    \n    def _process_lorawan_data(self, sensor: HardwareSensor, data: Dict):\n        \"\"\"Process LoRaWAN-specific data\"\"\"\n        try:\n            payload_data = data['data']\n            \n            for measurement_type, value in payload_data.items():\n                if measurement_type in ['battery', 'temperature']:\n                    continue  # Metadata, not sensor readings\n                \n                reading = SensorReading(\n                    sensor_id=sensor.sensor_id,\n                    timestamp=datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00')),\n                    value=float(value),\n                    unit=self._get_sensor_unit(measurement_type),\n                    quality_score=self._calculate_lorawan_quality(data),\n                    rssi=data.get('rssi'),\n                    snr=data.get('snr')\n                )\n                \n                # Store reading\n                sensor_data = SensorData(\n                    sensor_id=reading.sensor_id,\n                    timestamp=reading.timestamp,\n                    value=reading.value,\n                    unit=reading.unit,\n                    quality_score=reading.quality_score,\n                    metadata={\n                        'rssi': reading.rssi,\n                        'snr': reading.snr,\n                        'data_rate': data.get('data_rate'),\n                        'frequency': data.get('frequency'),\n                        'gateway_id': data.get('gateway_id'),\n                        'protocol': 'lorawan'\n                    }\n                )\n                \n                self.data_ingestion._store_sensor_reading(sensor_data)\n            \n            # Update sensor metrics\n            sensor.battery_level = payload_data.get('battery', sensor.battery_level)\n            sensor.signal_strength = data.get('rssi', sensor.signal_strength)\n            sensor.last_reading = datetime.now()\n            \n        except Exception as e:\n            logger.error(f\"Error processing LoRaWAN data for {sensor.sensor_id}: {e}\")\n    \n    def _process_modbus_data(self, sensor: HardwareSensor, data: Dict):\n        \"\"\"Process Modbus-specific data\"\"\"\n        try:\n            registers = data['registers']\n            \n            reading = SensorReading(\n                sensor_id=sensor.sensor_id,\n                timestamp=datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00')),\n                value=float(registers['value']),\n                unit=self._get_sensor_unit(sensor.sensor_type),\n                quality_score=1.0 if registers['status'] == 0x0000 else 0.5,\n                temperature=registers.get('temperature', 0) / 10.0,  # Convert from scaled int\n                voltage=registers.get('voltage', 0) / 1000.0  # Convert from mV to V\n            )\n            \n            # Store reading\n            sensor_data = SensorData(\n                sensor_id=reading.sensor_id,\n                timestamp=reading.timestamp,\n                value=reading.value,\n                unit=reading.unit,\n                quality_score=reading.quality_score,\n                metadata={\n                    'temperature': reading.temperature,\n                    'voltage': reading.voltage,\n                    'status_register': registers['status'],\n                    'protocol': 'modbus'\n                }\n            )\n            \n            self.data_ingestion._store_sensor_reading(sensor_data)\n            \n        except Exception as e:\n            logger.error(f\"Error processing Modbus data for {sensor.sensor_id}: {e}\")\n    \n    def _calculate_quality_score(self, sensor: HardwareSensor, data: Dict) -> float:\n        \"\"\"Calculate data quality score\"\"\"\n        quality = 1.0\n        \n        # Signal strength factor\n        rssi = data.get('rssi', sensor.signal_strength)\n        if rssi < -100:\n            quality *= 0.3\n        elif rssi < -80:\n            quality *= 0.7\n        elif rssi < -60:\n            quality *= 0.9\n        \n        # Battery level factor\n        if sensor.battery_level < 20:\n            quality *= 0.6\n        elif sensor.battery_level < 50:\n            quality *= 0.8\n        \n        # Voltage stability factor\n        voltage = data.get('voltage', 3.3)\n        if voltage < 2.8 or voltage > 3.6:\n            quality *= 0.7\n        \n        return max(0.1, quality)\n    \n    def _calculate_lorawan_quality(self, data: Dict) -> float:\n        \"\"\"Calculate LoRaWAN-specific quality score\"\"\"\n        quality = 1.0\n        \n        # RSSI factor\n        rssi = data.get('rssi', -100)\n        if rssi > -80:\n            quality *= 1.0\n        elif rssi > -100:\n            quality *= 0.8\n        else:\n            quality *= 0.4\n        \n        # SNR factor\n        snr = data.get('snr', -20)\n        if snr > 0:\n            quality *= 1.0\n        elif snr > -10:\n            quality *= 0.9\n        else:\n            quality *= 0.6\n        \n        return max(0.1, quality)\n    \n    def _update_sensor_metrics(self, sensor: HardwareSensor, reading: SensorReading):\n        \"\"\"Update sensor operational metrics\"\"\"\n        sensor.last_reading = reading.timestamp\n        sensor.data_quality_score = reading.quality_score\n        \n        # Update status based on metrics\n        if reading.quality_score < 0.3:\n            sensor.status = SensorStatus.WEAK_SIGNAL\n        elif sensor.battery_level < 20:\n            sensor.status = SensorStatus.LOW_BATTERY\n        else:\n            sensor.status = SensorStatus.ONLINE\n    \n    def _update_sensor_status(self, sensor_id: str, status: SensorStatus):\n        \"\"\"Update sensor status\"\"\"\n        if sensor_id in self.sensors:\n            self.sensors[sensor_id].status = status\n            logger.info(f\"Sensor {sensor_id} status updated to {status.value}\")\n    \n    async def start_monitoring(self):\n        \"\"\"Start continuous sensor monitoring\"\"\"\n        self.is_running = True\n        logger.info(\"Starting IoT sensor monitoring...\")\n        \n        # Start background tasks for each protocol\n        tasks = []\n        \n        # HTTP polling task\n        tasks.append(asyncio.create_task(self._http_polling_loop()))\n        \n        # LoRaWAN monitoring task\n        tasks.append(asyncio.create_task(self._lorawan_monitoring_loop()))\n        \n        # Modbus polling task\n        tasks.append(asyncio.create_task(self._modbus_polling_loop()))\n        \n        # Health monitoring task\n        tasks.append(asyncio.create_task(self._health_monitoring_loop()))\n        \n        # Wait for all tasks\n        await asyncio.gather(*tasks)\n    \n    async def _http_polling_loop(self):\n        \"\"\"HTTP sensor polling loop\"\"\"\n        while self.is_running:\n            try:\n                http_sensors = [s for s in self.sensors.values() if s.protocol == SensorProtocol.HTTP]\n                \n                for sensor in http_sensors:\n                    if sensor.status != SensorStatus.OFFLINE:\n                        self._handle_http_sensor(sensor, 'read')\n                \n                await asyncio.sleep(30)  # Poll every 30 seconds\n                \n            except Exception as e:\n                logger.error(f\"Error in HTTP polling loop: {e}\")\n                await asyncio.sleep(60)\n    \n    async def _lorawan_monitoring_loop(self):\n        \"\"\"LoRaWAN sensor monitoring loop\"\"\"\n        while self.is_running:\n            try:\n                lorawan_sensors = [s for s in self.sensors.values() if s.protocol == SensorProtocol.LORAWAN]\n                \n                for sensor in lorawan_sensors:\n                    if sensor.status != SensorStatus.OFFLINE:\n                        self._handle_lorawan_sensor(sensor, 'read')\n                \n                await asyncio.sleep(sensor.reading_interval if lorawan_sensors else 60)\n                \n            except Exception as e:\n                logger.error(f\"Error in LoRaWAN monitoring loop: {e}\")\n                await asyncio.sleep(120)\n    \n    async def _modbus_polling_loop(self):\n        \"\"\"Modbus sensor polling loop\"\"\"\n        while self.is_running:\n            try:\n                modbus_sensors = [s for s in self.sensors.values() if s.protocol == SensorProtocol.MODBUS]\n                \n                for sensor in modbus_sensors:\n                    if sensor.status != SensorStatus.OFFLINE:\n                        self._handle_modbus_sensor(sensor, 'read')\n                \n                await asyncio.sleep(10)  # Poll Modbus sensors frequently\n                \n            except Exception as e:\n                logger.error(f\"Error in Modbus polling loop: {e}\")\n                await asyncio.sleep(30)\n    \n    async def _health_monitoring_loop(self):\n        \"\"\"Sensor health and diagnostics monitoring\"\"\"\n        while self.is_running:\n            try:\n                current_time = datetime.now()\n                \n                for sensor in self.sensors.values():\n                    # Check for missed readings\n                    if sensor.last_reading:\n                        time_since_reading = (current_time - sensor.last_reading).total_seconds()\n                        expected_interval = sensor.reading_interval * 2  # Allow 2x tolerance\n                        \n                        if time_since_reading > expected_interval:\n                            sensor.missed_readings += 1\n                            if sensor.missed_readings > 5:\n                                sensor.status = SensorStatus.OFFLINE\n                    \n                    # Check battery levels\n                    if sensor.battery_level < 20:\n                        sensor.status = SensorStatus.LOW_BATTERY\n                    \n                    # Simulate battery drain\n                    if sensor.status == SensorStatus.ONLINE:\n                        sensor.battery_level = max(0, sensor.battery_level - 0.001)  # Slow drain\n                \n                await asyncio.sleep(300)  # Check every 5 minutes\n                \n            except Exception as e:\n                logger.error(f\"Error in health monitoring loop: {e}\")\n                await asyncio.sleep(600)\n    \n    def stop_monitoring(self):\n        \"\"\"Stop sensor monitoring\"\"\"\n        self.is_running = False\n        logger.info(\"IoT sensor monitoring stopped\")\n    \n    def get_sensor_status(self, sensor_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get detailed sensor status\"\"\"\n        if sensor_id not in self.sensors:\n            return None\n        \n        sensor = self.sensors[sensor_id]\n        return {\n            'sensor_id': sensor.sensor_id,\n            'status': sensor.status.value,\n            'battery_level': sensor.battery_level,\n            'signal_strength': sensor.signal_strength,\n            'last_reading': sensor.last_reading.isoformat() if sensor.last_reading else None,\n            'data_quality_score': sensor.data_quality_score,\n            'error_count': sensor.error_count,\n            'missed_readings': sensor.missed_readings,\n            'protocol': sensor.protocol.value,\n            'coordinates': sensor.coordinates\n        }\n    \n    def get_all_sensors_status(self) -> List[Dict[str, Any]]:\n        \"\"\"Get status of all sensors\"\"\"\n        return [self.get_sensor_status(sensor_id) for sensor_id in self.sensors.keys()]\n\n# Global sensor manager instance\niot_sensor_manager = IoTSensorManager()","size_bytes":24903},"attached_assets/extracted/MineRockGuard/mobile/field_app.py":{"content":"\"\"\"\nMobile Application Interface for Field Personnel\nProvides offline capabilities, emergency communication, and real-time updates\n\"\"\"\n\nimport json\nimport sqlite3\nimport os\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, asdict\nimport streamlit as st\nfrom database.database_manager import RockfallDatabaseManager\nfrom alerts.notification_system import NotificationSystem\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass FieldReport:\n    \"\"\"Field inspection report\"\"\"\n    report_id: str\n    inspector_name: str\n    timestamp: datetime\n    location: Dict[str, float]\n    mine_site_id: int\n    \n    # Inspection details\n    inspection_type: str  # routine, emergency, follow_up\n    weather_conditions: str\n    visibility: str\n    access_conditions: str\n    \n    # Observations\n    visual_cracks: List[Dict[str, Any]]\n    surface_conditions: str\n    vegetation_changes: bool\n    erosion_observed: bool\n    debris_present: bool\n    water_seepage: bool\n    \n    # Photos and media\n    photos: List[str]  # File paths\n    videos: List[str]  # File paths\n    voice_notes: List[str]  # File paths\n    \n    # Risk assessment\n    immediate_danger: bool\n    recommended_actions: List[str]\n    priority_level: str  # low, medium, high, critical\n    \n    # Offline status\n    synchronized: bool = False\n    sync_timestamp: Optional[datetime] = None\n\n@dataclass\nclass EmergencyAlert:\n    \"\"\"Emergency alert from field personnel\"\"\"\n    alert_id: str\n    reporter_name: str\n    location: Dict[str, float]\n    timestamp: datetime\n    alert_type: str  # rockfall, equipment_failure, injury, evacuation\n    severity: str  # low, medium, high, critical\n    description: str\n    immediate_action_required: bool\n    personnel_at_risk: int\n    evacuation_requested: bool\n    photos: List[str]\n    synchronized: bool = False\n\nclass OfflineDataManager:\n    \"\"\"Manages offline data storage and synchronization\"\"\"\n    \n    def __init__(self, data_dir: str = \"mobile_data\"):\n        self.data_dir = data_dir\n        self.db_path = os.path.join(data_dir, \"offline_data.db\")\n        self._ensure_data_directory()\n        self._initialize_offline_database()\n    \n    def _ensure_data_directory(self):\n        \"\"\"Ensure data directory exists\"\"\"\n        if not os.path.exists(self.data_dir):\n            os.makedirs(self.data_dir)\n            \n        # Create subdirectories\n        for subdir in ['reports', 'photos', 'videos', 'voice_notes', 'cache']:\n            path = os.path.join(self.data_dir, subdir)\n            if not os.path.exists(path):\n                os.makedirs(path)\n    \n    def _initialize_offline_database(self):\n        \"\"\"Initialize SQLite database for offline storage\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        try:\n            cursor = conn.cursor()\n            \n            # Field reports table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS field_reports (\n                    report_id TEXT PRIMARY KEY,\n                    inspector_name TEXT,\n                    timestamp TEXT,\n                    location TEXT,\n                    mine_site_id INTEGER,\n                    data_json TEXT,\n                    synchronized INTEGER DEFAULT 0,\n                    sync_timestamp TEXT\n                )\n            ''')\n            \n            # Emergency alerts table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS emergency_alerts (\n                    alert_id TEXT PRIMARY KEY,\n                    reporter_name TEXT,\n                    timestamp TEXT,\n                    location TEXT,\n                    alert_type TEXT,\n                    severity TEXT,\n                    data_json TEXT,\n                    synchronized INTEGER DEFAULT 0\n                )\n            ''')\n            \n            # Cached sensor data table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS cached_sensor_data (\n                    sensor_id TEXT,\n                    timestamp TEXT,\n                    value REAL,\n                    unit TEXT,\n                    cache_time TEXT,\n                    PRIMARY KEY (sensor_id, timestamp)\n                )\n            ''')\n            \n            # Offline maps and reference data\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS reference_data (\n                    data_type TEXT,\n                    data_key TEXT,\n                    data_value TEXT,\n                    last_updated TEXT,\n                    PRIMARY KEY (data_type, data_key)\n                )\n            ''')\n            \n            conn.commit()\n            logger.info(\"Offline database initialized\")\n            \n        except Exception as e:\n            logger.error(f\"Error initializing offline database: {e}\")\n        finally:\n            conn.close()\n    \n    def store_field_report(self, report: FieldReport) -> bool:\n        \"\"\"Store field report offline\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute('''\n                INSERT OR REPLACE INTO field_reports \n                (report_id, inspector_name, timestamp, location, mine_site_id, data_json, synchronized)\n                VALUES (?, ?, ?, ?, ?, ?, ?)\n            ''', (\n                report.report_id,\n                report.inspector_name,\n                report.timestamp.isoformat(),\n                json.dumps(report.location),\n                report.mine_site_id,\n                json.dumps(asdict(report)),\n                0  # Not synchronized\n            ))\n            \n            conn.commit()\n            conn.close()\n            \n            logger.info(f\"Stored field report {report.report_id} offline\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error storing field report: {e}\")\n            return False\n    \n    def store_emergency_alert(self, alert: EmergencyAlert) -> bool:\n        \"\"\"Store emergency alert offline\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            cursor.execute('''\n                INSERT OR REPLACE INTO emergency_alerts \n                (alert_id, reporter_name, timestamp, location, alert_type, severity, data_json, synchronized)\n                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n            ''', (\n                alert.alert_id,\n                alert.reporter_name,\n                alert.timestamp.isoformat(),\n                json.dumps(alert.location),\n                alert.alert_type,\n                alert.severity,\n                json.dumps(asdict(alert)),\n                0  # Not synchronized\n            ))\n            \n            conn.commit()\n            conn.close()\n            \n            logger.info(f\"Stored emergency alert {alert.alert_id} offline\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error storing emergency alert: {e}\")\n            return False\n    \n    def get_unsynchronized_data(self) -> Dict[str, List[Dict]]:\n        \"\"\"Get all unsynchronized data\"\"\"\n        unsync_data = {'reports': [], 'alerts': []}\n        \n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # Get unsynchronized reports\n            cursor.execute('SELECT data_json FROM field_reports WHERE synchronized = 0')\n            for row in cursor.fetchall():\n                unsync_data['reports'].append(json.loads(row[0]))\n            \n            # Get unsynchronized alerts\n            cursor.execute('SELECT data_json FROM emergency_alerts WHERE synchronized = 0')\n            for row in cursor.fetchall():\n                unsync_data['alerts'].append(json.loads(row[0]))\n            \n            conn.close()\n            \n        except Exception as e:\n            logger.error(f\"Error getting unsynchronized data: {e}\")\n        \n        return unsync_data\n    \n    def mark_synchronized(self, item_type: str, item_id: str) -> bool:\n        \"\"\"Mark an item as synchronized\"\"\"\n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            if item_type == 'report':\n                cursor.execute('''\n                    UPDATE field_reports \n                    SET synchronized = 1, sync_timestamp = ? \n                    WHERE report_id = ?\n                ''', (datetime.now().isoformat(), item_id))\n            elif item_type == 'alert':\n                cursor.execute('''\n                    UPDATE emergency_alerts \n                    SET synchronized = 1 \n                    WHERE alert_id = ?\n                ''', (item_id,))\n            \n            conn.commit()\n            conn.close()\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error marking {item_type} {item_id} as synchronized: {e}\")\n            return False\n\nclass MobileFieldApp:\n    \"\"\"Main mobile application interface\"\"\"\n    \n    def __init__(self):\n        self.db_manager = RockfallDatabaseManager()\n        self.notification_system = NotificationSystem()\n        self.offline_manager = OfflineDataManager()\n        self.online = self._check_connectivity()\n        \n        # App state\n        if 'field_app_state' not in st.session_state:\n            st.session_state.field_app_state = {\n                'current_inspector': '',\n                'current_location': {'lat': 0.0, 'lon': 0.0},\n                'active_inspection': None,\n                'photo_count': 0\n            }\n    \n    def _check_connectivity(self) -> bool:\n        \"\"\"Check if the app has connectivity to the main system\"\"\"\n        try:\n            # Try to get mine sites from database\n            sites = self.db_manager.get_mine_sites()\n            return len(sites) > 0\n        except:\n            return False\n    \n    def render_mobile_interface(self):\n        \"\"\"Render the main mobile interface\"\"\"\n        st.set_page_config(\n            page_title=\"Field Inspector App\",\n            page_icon=\"üîç\",\n            layout=\"wide\",\n            initial_sidebar_state=\"collapsed\"\n        )\n        \n        # Header with connectivity status\n        col1, col2, col3 = st.columns([2, 1, 1])\n        with col1:\n            st.title(\"üîç Field Inspector\")\n        with col2:\n            if self.online:\n                st.success(\"üü¢ Online\")\n            else:\n                st.error(\"üî¥ Offline\")\n        with col3:\n            if st.button(\"üîÑ Sync\"):\n                self._synchronize_data()\n        \n        # Navigation\n        tab1, tab2, tab3, tab4 = st.tabs([\"üìã Inspection\", \"üö® Emergency\", \"üìä Dashboard\", \"‚öôÔ∏è Settings\"])\\n        \\n        with tab1:\\n            self._render_inspection_interface()\\n        \\n        with tab2:\\n            self._render_emergency_interface()\\n        \\n        with tab3:\\n            self._render_dashboard_interface()\\n        \\n        with tab4:\\n            self._render_settings_interface()\n    \n    def _render_inspection_interface(self):\n        \"\"\"Render inspection interface\"\"\"\n        st.header(\"Field Inspection\")\n        \n        # Inspector information\n        col1, col2 = st.columns(2)\n        with col1:\n            inspector_name = st.text_input(\n                \"Inspector Name\", \n                value=st.session_state.field_app_state['current_inspector']\n            )\n            st.session_state.field_app_state['current_inspector'] = inspector_name\n        \n        with col2:\n            mine_site = st.selectbox(\"Mine Site\", [\"Copper Ridge Mine\", \"Iron Mountain\", \"Silver Creek\"])\n        \n        # Location\n        st.subheader(\"üìç Location\")\n        col1, col2 = st.columns(2)\n        with col1:\n            lat = st.number_input(\"Latitude\", value=39.7392, format=\"%.6f\")\n        with col2:\n            lon = st.number_input(\"Longitude\", value=-104.9903, format=\"%.6f\")\n        \n        if st.button(\"üì± Use Current Location\"):\n            st.info(\"GPS location would be captured on a real mobile device\")\n        \n        # Inspection details\n        st.subheader(\"üîç Inspection Details\")\n        \n        col1, col2 = st.columns(2)\n        with col1:\n            inspection_type = st.selectbox(\"Inspection Type\", [\"Routine\", \"Follow-up\", \"Emergency\"])\n            weather = st.selectbox(\"Weather\", [\"Clear\", \"Cloudy\", \"Rainy\", \"Windy\", \"Foggy\"])\n        \n        with col2:\n            visibility = st.selectbox(\"Visibility\", [\"Excellent\", \"Good\", \"Fair\", \"Poor\"])\n            access = st.selectbox(\"Access Conditions\", [\"Normal\", \"Restricted\", \"Difficult\", \"Blocked\"])\n        \n        # Observations\n        st.subheader(\"üëÅÔ∏è Observations\")\n        \n        visual_cracks = st.checkbox(\"Visual cracks observed\")\n        erosion_observed = st.checkbox(\"Erosion observed\")\n        debris_present = st.checkbox(\"Debris present\")\n        vegetation_changes = st.checkbox(\"Vegetation changes\")\n        water_seepage = st.checkbox(\"Water seepage\")\n        \n        surface_conditions = st.text_area(\"Surface Conditions Description\")\n        \n        # Risk assessment\n        st.subheader(\"‚ö†Ô∏è Risk Assessment\")\n        immediate_danger = st.checkbox(\"‚ö†Ô∏è IMMEDIATE DANGER PRESENT\")\n        priority_level = st.selectbox(\"Priority Level\", [\"Low\", \"Medium\", \"High\", \"Critical\"])\n        \n        recommended_actions = st.text_area(\"Recommended Actions\")\n        \n        # Media capture simulation\n        st.subheader(\"üì∏ Media Capture\")\n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            if st.button(\"üì∏ Take Photo\"):\n                st.session_state.field_app_state['photo_count'] += 1\n                st.success(f\"Photo {st.session_state.field_app_state['photo_count']} captured\")\n        \n        with col2:\n            if st.button(\"üé• Record Video\"):\n                st.success(\"Video recording started (simulated)\")\n        \n        with col3:\n            if st.button(\"üé§ Voice Note\"):\n                st.success(\"Voice note recorded (simulated)\")\n        \n        # Submit report\n        if st.button(\"üíæ Submit Report\", type=\"primary\"):\n            if inspector_name and surface_conditions:\n                report = FieldReport(\n                    report_id=f\"REP_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n                    inspector_name=inspector_name,\n                    timestamp=datetime.now(),\n                    location={'lat': lat, 'lon': lon},\n                    mine_site_id=1,\n                    inspection_type=inspection_type.lower(),\n                    weather_conditions=weather,\n                    visibility=visibility,\n                    access_conditions=access,\n                    visual_cracks=[],  # Would contain crack details in real app\n                    surface_conditions=surface_conditions,\n                    vegetation_changes=vegetation_changes,\n                    erosion_observed=erosion_observed,\n                    debris_present=debris_present,\n                    water_seepage=water_seepage,\n                    photos=[f\"photo_{i}.jpg\" for i in range(st.session_state.field_app_state['photo_count'])],\n                    videos=[],\n                    voice_notes=[],\n                    immediate_danger=immediate_danger,\n                    recommended_actions=[recommended_actions] if recommended_actions else [],\n                    priority_level=priority_level.lower()\n                )\n                \n                # Store report\n                if self.offline_manager.store_field_report(report):\n                    st.success(\"‚úÖ Report saved successfully!\")\n                    if self.online:\n                        st.info(\"üîÑ Attempting to sync with main system...\")\n                        self._sync_report(report)\n                    else:\n                        st.warning(\"üì¥ Report saved offline - will sync when connection restored\")\n                else:\n                    st.error(\"‚ùå Failed to save report\")\n            else:\n                st.error(\"Please fill in all required fields\")\n    \n    def _render_emergency_interface(self):\n        \"\"\"Render emergency alert interface\"\"\"\n        st.header(\"üö® Emergency Alert\")\n        \n        st.warning(\"‚ö†Ô∏è USE ONLY FOR IMMEDIATE EMERGENCIES\")\n        \n        # Reporter info\n        reporter_name = st.text_input(\"Reporter Name\", value=st.session_state.field_app_state['current_inspector'])\n        \n        # Emergency details\n        col1, col2 = st.columns(2)\n        with col1:\n            alert_type = st.selectbox(\"Emergency Type\", [\n                \"Rockfall\", \"Equipment Failure\", \"Personnel Injury\", \"Evacuation Required\", \"Other\"\n            ])\n        \n        with col2:\n            severity = st.selectbox(\"Severity\", [\"Medium\", \"High\", \"Critical\"])\n        \n        # Location\n        col1, col2 = st.columns(2)\n        with col1:\n            lat = st.number_input(\"Emergency Latitude\", value=39.7392, format=\"%.6f\")\n        with col2:\n            lon = st.number_input(\"Emergency Longitude\", value=-104.9903, format=\"%.6f\")\n        \n        # Emergency details\n        description = st.text_area(\"Emergency Description\", placeholder=\"Describe the emergency situation...\")\n        \n        col1, col2 = st.columns(2)\n        with col1:\n            immediate_action = st.checkbox(\"Immediate action required\")\n            evacuation = st.checkbox(\"Evacuation requested\")\n        \n        with col2:\n            personnel_at_risk = st.number_input(\"Personnel at risk\", min_value=0, value=0)\n        \n        # Emergency photos\n        if st.button(\"üì∏ Take Emergency Photo\"):\n            st.success(\"Emergency photo captured\")\n        \n        # Submit emergency alert\n        if st.button(\"üö® SEND EMERGENCY ALERT\", type=\"primary\"):\n            if reporter_name and description:\n                alert = EmergencyAlert(\n                    alert_id=f\"EMG_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n                    reporter_name=reporter_name,\n                    location={'lat': lat, 'lon': lon},\n                    timestamp=datetime.now(),\n                    alert_type=alert_type.lower(),\n                    severity=severity.lower(),\n                    description=description,\n                    immediate_action_required=immediate_action,\n                    personnel_at_risk=personnel_at_risk,\n                    evacuation_requested=evacuation,\n                    photos=[]\n                )\n                \n                # Store and try to send immediately\n                if self.offline_manager.store_emergency_alert(alert):\n                    st.success(\"üö® EMERGENCY ALERT SENT!\")\n                    \n                    # Try to send via multiple channels\n                    if self.online:\n                        self._send_emergency_alert(alert)\n                    else:\n                        st.error(\"üì¥ No connection - Alert saved for immediate transmission when online\")\n                        # In a real app, this would try radio/satellite communication\n                        \n                else:\n                    st.error(\"‚ùå Failed to send emergency alert\")\n            else:\n                st.error(\"Please fill in all required fields\")\n    \n    def _render_dashboard_interface(self):\n        \"\"\"Render dashboard with cached data\"\"\"\n        st.header(\"üìä Field Dashboard\")\n        \n        # Connectivity status\n        if self.online:\n            try:\n                # Get recent sensor data\n                sensors = self.db_manager.get_sensors_for_site(1)\n                \n                st.subheader(\"üì° Sensor Status\")\n                for sensor in sensors[:10]:  # Show first 10\n                    col1, col2, col3 = st.columns(3)\n                    with col1:\n                        st.metric(\"Sensor\", sensor['sensor_id'])\n                    with col2:\n                        st.metric(\"Status\", sensor['status'])\n                    with col3:\n                        st.metric(\"Value\", sensor.get('latest_value', 'N/A'))\n                \n                # Recent alerts\n                alerts = self.db_manager.get_active_alerts(1)\n                st.subheader(\"üö® Active Alerts\")\n                if alerts:\n                    for alert in alerts:\n                        st.warning(f\"**{alert['severity'].upper()}**: {alert['title']}\")\n                else:\n                    st.success(\"No active alerts\")\n                \n            except Exception as e:\n                st.error(f\"Error loading dashboard data: {e}\")\n                self.online = False\n        \n        if not self.online:\n            st.warning(\"üì¥ Offline Mode - Showing cached data\")\n            st.info(\"Last sync: Not available\")\n            \n            # Show offline status\n            unsync_data = self.offline_manager.get_unsynchronized_data()\n            \n            col1, col2 = st.columns(2)\n            with col1:\n                st.metric(\"Pending Reports\", len(unsync_data['reports']))\n            with col2:\n                st.metric(\"Pending Alerts\", len(unsync_data['alerts']))\n    \n    def _render_settings_interface(self):\n        \"\"\"Render settings interface\"\"\"\n        st.header(\"‚öôÔ∏è Settings\")\n        \n        # App settings\n        st.subheader(\"üì± App Settings\")\n        \n        auto_sync = st.checkbox(\"Auto-sync when online\", value=True)\n        photo_quality = st.selectbox(\"Photo Quality\", [\"High\", \"Medium\", \"Low\"])\n        gps_accuracy = st.selectbox(\"GPS Accuracy\", [\"High\", \"Medium\", \"Battery Saver\"])\n        \n        # Storage info\n        st.subheader(\"üíæ Storage\")\n        col1, col2, col3 = st.columns(3)\n        with col1:\n            st.metric(\"Photos\", f\"{st.session_state.field_app_state['photo_count']}\")\n        with col2:\n            st.metric(\"Reports\", \"5\")\n        with col3:\n            st.metric(\"Available Space\", \"2.1 GB\")\n        \n        # Sync settings\n        st.subheader(\"üîÑ Synchronization\")\n        \n        if st.button(\"üîÑ Force Sync Now\"):\n            self._synchronize_data()\n        \n        if st.button(\"üóëÔ∏è Clear Offline Data\"):\n            if st.checkbox(\"Confirm deletion of all offline data\"):\n                st.warning(\"This would clear all offline data in a real app\")\n        \n        # Emergency contacts\n        st.subheader(\"üìû Emergency Contacts\")\n        st.text(\"Mine Control: +1-555-MINE-911\")\n        st.text(\"Emergency Services: 911\")\n        st.text(\"Site Manager: +1-555-SITE-MGR\")\n    \n    def _sync_report(self, report: FieldReport):\n        \"\"\"Sync a single report with the main system\"\"\"\n        try:\n            # In a real implementation, this would send the report to the main system\n            # For now, we'll simulate successful sync\n            st.success(f\"‚úÖ Report {report.report_id} synced successfully\")\n            self.offline_manager.mark_synchronized('report', report.report_id)\n            \n        except Exception as e:\n            st.error(f\"Failed to sync report: {e}\")\n    \n    def _send_emergency_alert(self, alert: EmergencyAlert):\n        \"\"\"Send emergency alert via multiple channels\"\"\"\n        try:\n            # Create alert in main system\n            alert_id = self.db_manager.create_alert(\n                mine_site_id=1,\n                alert_type=alert.alert_type,\n                severity=alert.severity,\n                title=f\"Field Emergency: {alert.alert_type.title()}\",\n                message=alert.description,\n                location=alert.location,\n                triggered_by=f\"field_app_{alert.reporter_name}\"\n            )\n            \n            # Send notifications\n            self.notification_system.send_emergency_alert(\n                alert.description, \n                alert.severity, \n                f\"GPS: {alert.location['lat']:.6f}, {alert.location['lon']:.6f}\"\n            )\n            \n            st.success(\"üö® Emergency alert sent via all available channels\")\n            self.offline_manager.mark_synchronized('alert', alert.alert_id)\n            \n        except Exception as e:\n            st.error(f\"Failed to send emergency alert: {e}\")\n    \n    def _synchronize_data(self):\n        \"\"\"Synchronize all offline data\"\"\"\n        if not self.online:\n            st.warning(\"üì¥ Cannot sync - No connection to main system\")\n            return\n        \n        try:\n            unsync_data = self.offline_manager.get_unsynchronized_data()\n            \n            # Sync reports\n            for report_data in unsync_data['reports']:\n                report = FieldReport(**report_data)\n                self._sync_report(report)\n            \n            # Sync alerts\n            for alert_data in unsync_data['alerts']:\n                alert = EmergencyAlert(**alert_data)\n                self._send_emergency_alert(alert)\n            \n            st.success(f\"‚úÖ Synchronized {len(unsync_data['reports'])} reports and {len(unsync_data['alerts'])} alerts\")\n            \n        except Exception as e:\n            st.error(f\"Synchronization failed: {e}\")\n\n# Global mobile app instance\nmobile_app = MobileFieldApp()","size_bytes":25305},"attached_assets/extracted/MineRockGuard/models/rockfall_predictor.py":{"content":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom datetime import datetime, timedelta\nimport json\nimport os\nfrom openai import OpenAI\n\nclass RockfallPredictor:\n    def __init__(self):\n        self.model = None\n        self.feature_names = [\n            'displacement_rate', 'strain_magnitude', 'pore_pressure',\n            'temperature', 'rainfall', 'wind_speed', 'vibration_level',\n            'slope_angle', 'soil_moisture', 'crack_density'\n        ]\n        self.model_metrics = {'accuracy': 0.85, 'precision': 0.82, 'recall': 0.88}\n        self.feature_importance = {}\n        self.initialize_model()\n        \n        # Initialize OpenAI for advanced analysis\n        self.openai_client = None\n        if os.getenv(\"OPENAI_API_KEY\"):\n            self.openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n    \n    def initialize_model(self):\n        \"\"\"Initialize the ensemble machine learning model\"\"\"\n        # Create ensemble model\n        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n        nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000)\n        svm_model = SVC(probability=True, random_state=42)\n        \n        self.model = VotingClassifier(\n            estimators=[('rf', rf_model), ('nn', nn_model), ('svm', svm_model)],\n            voting='soft'\n        )\n        \n        # Train with synthetic data\n        self._train_initial_model()\n    \n    def _train_initial_model(self):\n        \"\"\"Train the model with synthetic data\"\"\"\n        # Generate synthetic training data\n        n_samples = 1000\n        X = np.random.randn(n_samples, len(self.feature_names))\n        \n        # Create realistic relationships for rockfall risk\n        risk_score = (\n            X[:, 0] * 0.3 +  # displacement_rate\n            X[:, 1] * 0.25 + # strain_magnitude\n            X[:, 2] * 0.2 +  # pore_pressure\n            X[:, 4] * 0.15 + # rainfall\n            X[:, 6] * 0.1    # vibration_level\n        )\n        \n        # Add some noise and non-linear relationships\n        risk_score += np.random.normal(0, 0.1, n_samples)\n        risk_score += 0.1 * X[:, 0] * X[:, 4]  # displacement-rainfall interaction\n        \n        # Convert to binary classification (1 = high risk, 0 = low risk)\n        y = (risk_score > np.percentile(risk_score, 70)).astype(int)\n        \n        # Train model\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        if self.model is not None:\n            self.model.fit(X_train, y_train)\n            \n            # Calculate metrics\n            y_pred = self.model.predict(X_test)\n        else:\n            y_pred = np.random.choice([0, 1], size=len(y_test))\n        self.model_metrics = {\n            'accuracy': accuracy_score(y_test, y_pred),\n            'precision': precision_score(y_test, y_pred, average='weighted'),\n            'recall': recall_score(y_test, y_pred, average='weighted')\n        }\n        \n        # Calculate feature importance (using Random Forest component)\n        if hasattr(self.model, 'named_estimators_'):\n            rf_model = self.model.named_estimators_['rf']\n            importance_values = rf_model.feature_importances_\n            self.feature_importance = dict(zip(self.feature_names, importance_values))\n        else:\n            # Fallback feature importance\n            self.feature_importance = {name: np.random.uniform(0.05, 0.25) for name in self.feature_names}\n    \n    def predict_risk(self, sensor_data):\n        \"\"\"Predict rockfall risk for given sensor data\"\"\"\n        if isinstance(sensor_data, dict):\n            # Convert dict to array\n            features = np.array([sensor_data.get(name, 0) for name in self.feature_names]).reshape(1, -1)\n        else:\n            features = np.array(sensor_data).reshape(1, -1)\n        \n        # Get prediction probability\n        if self.model is not None:\n            proba = self.model.predict_proba(features)[0]\n            risk_probability = proba[1]\n            confidence = float(np.max(proba))\n        else:\n            # Fallback prediction\n            risk_probability = np.random.uniform(0.1, 0.8)\n            confidence = 0.75\n        \n        return {\n            'risk_probability': risk_probability,\n            'risk_level': self._categorize_risk(risk_probability),\n            'confidence': confidence\n        }\n    \n    def _categorize_risk(self, probability):\n        \"\"\"Categorize risk level based on probability\"\"\"\n        if probability >= 0.85:\n            return 'critical'\n        elif probability >= 0.7:\n            return 'high'\n        elif probability >= 0.3:\n            return 'medium'\n        else:\n            return 'low'\n    \n    def generate_predictions(self):\n        \"\"\"Generate prediction data for dashboard\"\"\"\n        # Generate predictions for next 24 hours\n        time_points = []\n        predictions = []\n        current_time = datetime.now()\n        \n        for i in range(24):\n            time_point = current_time + timedelta(hours=i)\n            time_points.append(time_point)\n            \n            # Simulate varying conditions over time\n            base_risk = 0.3 + 0.2 * np.sin(i * np.pi / 12)  # Daily cycle\n            noise = np.random.normal(0, 0.1)\n            risk = max(0, min(1, base_risk + noise))\n            \n            predictions.append({\n                'timestamp': time_point,\n                'risk_probability': risk,\n                'risk_level': self._categorize_risk(risk)\n            })\n        \n        return predictions\n    \n    def create_prediction_timeline(self, prediction_data):\n        \"\"\"Create timeline visualization of predictions\"\"\"\n        timestamps = [p['timestamp'] for p in prediction_data]\n        risks = [p['risk_probability'] for p in prediction_data]\n        levels = [p['risk_level'] for p in prediction_data]\n        \n        # Color mapping for risk levels\n        color_map = {'low': 'green', 'medium': 'yellow', 'high': 'orange', 'critical': 'red'}\n        colors = [color_map[level] for level in levels]\n        \n        fig = go.Figure()\n        \n        # Add risk probability line\n        fig.add_trace(go.Scatter(\n            x=timestamps,\n            y=risks,\n            mode='lines+markers',\n            name='Risk Probability',\n            line=dict(color='blue', width=2),\n            marker=dict(color=colors, size=8)\n        ))\n        \n        # Add risk level zones\n        fig.add_hline(y=0.85, line_dash=\"dash\", line_color=\"red\", \n                     annotation_text=\"Critical Threshold\")\n        fig.add_hline(y=0.7, line_dash=\"dash\", line_color=\"orange\", \n                     annotation_text=\"High Risk Threshold\")\n        fig.add_hline(y=0.3, line_dash=\"dash\", line_color=\"yellow\", \n                     annotation_text=\"Medium Risk Threshold\")\n        \n        fig.update_layout(\n            title=\"24-Hour Risk Prediction Timeline\",\n            xaxis_title=\"Time\",\n            yaxis_title=\"Risk Probability\",\n            yaxis=dict(range=[0, 1]),\n            hovermode='x unified'\n        )\n        \n        return fig\n    \n    def get_model_metrics(self):\n        \"\"\"Return current model performance metrics\"\"\"\n        return self.model_metrics\n    \n    def get_feature_importance(self):\n        \"\"\"Return feature importance dictionary\"\"\"\n        return self.feature_importance\n    \n    def get_current_risk_factors(self):\n        \"\"\"Get current risk factors affecting predictions\"\"\"\n        # Simulate current environmental conditions\n        return {\n            'displacement_rate': np.random.uniform(0.1, 0.8),\n            'strain_magnitude': np.random.uniform(0.05, 0.6),\n            'pore_pressure': np.random.uniform(0.2, 0.7),\n            'temperature_factor': np.random.uniform(0.1, 0.5),\n            'rainfall_impact': np.random.uniform(0.0, 0.9),\n            'vibration_level': np.random.uniform(0.0, 0.4)\n        }\n    \n    def retrain_model(self, model_type=\"ensemble\"):\n        \"\"\"Retrain the model with updated data\"\"\"\n        if model_type == \"Random Forest\":\n            self.model = RandomForestClassifier(n_estimators=150, random_state=42)\n        elif model_type == \"Neural Network\":\n            self.model = MLPClassifier(hidden_layer_sizes=(150, 75), random_state=42, max_iter=1000)\n        elif model_type == \"SVM\":\n            self.model = SVC(probability=True, random_state=42)\n        else:  # Ensemble\n            rf_model = RandomForestClassifier(n_estimators=150, random_state=42)\n            nn_model = MLPClassifier(hidden_layer_sizes=(150, 75), random_state=42, max_iter=1000)\n            svm_model = SVC(probability=True, random_state=42)\n            \n            self.model = VotingClassifier(\n                estimators=[('rf', rf_model), ('nn', nn_model), ('svm', svm_model)],\n                voting='soft'\n            )\n        \n        # Retrain with new synthetic data\n        self._train_initial_model()\n    \n    def analyze_with_ai(self, sensor_data, environmental_data):\n        \"\"\"Use OpenAI to provide advanced analysis of risk factors\"\"\"\n        if not self.openai_client:\n            return {\"analysis\": \"AI analysis not available - API key not configured\"}\n        \n        try:\n            # the newest OpenAI model is \"gpt-5\" which was released August 7, 2025.\n            # do not change this unless explicitly requested by the user\n            prompt = f\"\"\"\n            Analyze the following mine sensor and environmental data for rockfall risk assessment:\n            \n            Sensor Data: {json.dumps(sensor_data, indent=2)}\n            Environmental Data: {json.dumps(environmental_data, indent=2)}\n            \n            Provide a comprehensive risk analysis including:\n            1. Key risk factors identified\n            2. Potential failure mechanisms\n            3. Recommended monitoring focus areas\n            4. Suggested preventive measures\n            \n            Respond in JSON format with the analysis.\n            \"\"\"\n            \n            response = self.openai_client.chat.completions.create(\n                model=\"gpt-5\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                response_format={\"type\": \"json_object\"}\n            )\n            \n            content = response.choices[0].message.content\n            if content:\n                return json.loads(content)\n            else:\n                return {\"error\": \"Empty response from AI analysis\"}\n            \n        except Exception as e:\n            return {\"error\": f\"AI analysis failed: {str(e)}\"}\n","size_bytes":10876},"attached_assets/extracted/MineRockGuard/utils/config_manager.py":{"content":"import json\nimport os\nfrom datetime import datetime\n\nclass ConfigManager:\n    def __init__(self):\n        self.config_file = 'mine_config.json'\n        self.default_config = {\n            'mine_name': 'Open Pit Mine Alpha',\n            'coordinates': '45.123, -123.456',\n            'sensor_count': 47,\n            'sensor_freq_index': 1,\n            'model_update_interval': 60,\n            'data_retention_days': 90,\n            'alert_cooldown': 15,\n            'max_alerts_per_hour': 5,\n            'use_dem': True,\n            'use_drone': True,\n            'use_weather': True,\n            'risk_thresholds': {\n                'low': 0.3,\n                'medium': 0.7,\n                'high': 0.85\n            },\n            'notification_settings': {\n                'sms_enabled': True,\n                'email_enabled': True,\n                'audio_enabled': True,\n                'visual_enabled': True\n            },\n            'communication_settings': {\n                'lorawan_enabled': True,\n                'radio_backup_enabled': True,\n                'satellite_backup_enabled': True\n            },\n            'system_settings': {\n                'auto_retrain_model': True,\n                'backup_frequency_hours': 24,\n                'log_level': 'INFO',\n                'max_log_size_mb': 100\n            },\n            'mine_zones': [\n                {'id': 1, 'name': 'North Wall', 'risk_baseline': 0.2},\n                {'id': 2, 'name': 'South Wall', 'risk_baseline': 0.3},\n                {'id': 3, 'name': 'East Slope', 'risk_baseline': 0.4},\n                {'id': 4, 'name': 'West Platform', 'risk_baseline': 0.2},\n                {'id': 5, 'name': 'Central Pit', 'risk_baseline': 0.5},\n                {'id': 6, 'name': 'Access Road North', 'risk_baseline': 0.1},\n                {'id': 7, 'name': 'Access Road South', 'risk_baseline': 0.1},\n                {'id': 8, 'name': 'Processing Area', 'risk_baseline': 0.2},\n                {'id': 9, 'name': 'Equipment Zone', 'risk_baseline': 0.3},\n                {'id': 10, 'name': 'Maintenance Area', 'risk_baseline': 0.2},\n                {'id': 11, 'name': 'Emergency Exit 1', 'risk_baseline': 0.1},\n                {'id': 12, 'name': 'Emergency Exit 2', 'risk_baseline': 0.1}\n            ],\n            'created_date': datetime.now().isoformat(),\n            'last_updated': datetime.now().isoformat()\n        }\n        self.current_config = self.load_config()\n    \n    def load_config(self):\n        \"\"\"Load configuration from file or create default\"\"\"\n        try:\n            if os.path.exists(self.config_file):\n                with open(self.config_file, 'r') as f:\n                    config = json.load(f)\n                # Merge with defaults to ensure all keys exist\n                return {**self.default_config, **config}\n            else:\n                return self.default_config.copy()\n        except Exception as e:\n            print(f\"Error loading config: {e}\")\n            return self.default_config.copy()\n    \n    def save_config(self, new_config=None):\n        \"\"\"Save configuration to file\"\"\"\n        try:\n            if new_config:\n                self.current_config.update(new_config)\n            \n            self.current_config['last_updated'] = datetime.now().isoformat()\n            \n            with open(self.config_file, 'w') as f:\n                json.dump(self.current_config, f, indent=2, default=str)\n            \n            return True\n        except Exception as e:\n            print(f\"Error saving config: {e}\")\n            return False\n    \n    def get_current_config(self):\n        \"\"\"Get current configuration\"\"\"\n        return self.current_config.copy()\n    \n    def get_config_value(self, key, default=None):\n        \"\"\"Get specific configuration value\"\"\"\n        return self.current_config.get(key, default)\n    \n    def update_config_value(self, key, value):\n        \"\"\"Update specific configuration value\"\"\"\n        self.current_config[key] = value\n        return self.save_config()\n    \n    def reset_to_defaults(self):\n        \"\"\"Reset configuration to defaults\"\"\"\n        self.current_config = self.default_config.copy()\n        return self.save_config()\n    \n    def get_mine_zones(self):\n        \"\"\"Get mine zone configuration\"\"\"\n        return self.current_config.get('mine_zones', [])\n    \n    def update_mine_zone(self, zone_id, zone_data):\n        \"\"\"Update specific mine zone configuration\"\"\"\n        zones = self.current_config.get('mine_zones', [])\n        for zone in zones:\n            if zone['id'] == zone_id:\n                zone.update(zone_data)\n                break\n        else:\n            # Add new zone if not found\n            zone_data['id'] = zone_id\n            zones.append(zone_data)\n        \n        self.current_config['mine_zones'] = zones\n        return self.save_config()\n    \n    def get_risk_thresholds(self):\n        \"\"\"Get risk level thresholds\"\"\"\n        return self.current_config.get('risk_thresholds', {\n            'low': 0.3,\n            'medium': 0.7,\n            'high': 0.85\n        })\n    \n    def update_risk_thresholds(self, thresholds):\n        \"\"\"Update risk level thresholds\"\"\"\n        current_thresholds = self.get_risk_thresholds()\n        current_thresholds.update(thresholds)\n        self.current_config['risk_thresholds'] = current_thresholds\n        return self.save_config()\n    \n    def get_notification_settings(self):\n        \"\"\"Get notification settings\"\"\"\n        return self.current_config.get('notification_settings', {})\n    \n    def update_notification_settings(self, settings):\n        \"\"\"Update notification settings\"\"\"\n        current_settings = self.get_notification_settings()\n        current_settings.update(settings)\n        self.current_config['notification_settings'] = current_settings\n        return self.save_config()\n    \n    def get_api_settings(self):\n        \"\"\"Get API configuration settings\"\"\"\n        return {\n            'openai_configured': os.getenv('OPENAI_API_KEY') is not None,\n            'twilio_configured': all([\n                os.getenv('TWILIO_ACCOUNT_SID'),\n                os.getenv('TWILIO_AUTH_TOKEN'),\n                os.getenv('TWILIO_PHONE_NUMBER')\n            ]),\n            'sendgrid_configured': os.getenv('SENDGRID_API_KEY') is not None\n        }\n    \n    def export_config(self, filename=None):\n        \"\"\"Export configuration to a file\"\"\"\n        if not filename:\n            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n            filename = f'mine_config_backup_{timestamp}.json'\n        \n        try:\n            export_data = {\n                'config': self.current_config,\n                'export_timestamp': datetime.now().isoformat(),\n                'system_info': {\n                    'api_settings': self.get_api_settings(),\n                    'version': '1.0.0'\n                }\n            }\n            \n            with open(filename, 'w') as f:\n                json.dump(export_data, f, indent=2, default=str)\n            \n            return {'success': True, 'filename': filename}\n        except Exception as e:\n            return {'success': False, 'error': str(e)}\n    \n    def import_config(self, filename):\n        \"\"\"Import configuration from a file\"\"\"\n        try:\n            with open(filename, 'r') as f:\n                import_data = json.load(f)\n            \n            if 'config' in import_data:\n                imported_config = import_data['config']\n                # Validate imported config has required fields\n                if self._validate_config(imported_config):\n                    self.current_config = {**self.default_config, **imported_config}\n                    return self.save_config()\n                else:\n                    return False\n            else:\n                return False\n        except Exception as e:\n            print(f\"Error importing config: {e}\")\n            return False\n    \n    def _validate_config(self, config):\n        \"\"\"Validate configuration structure\"\"\"\n        required_keys = ['mine_name', 'coordinates', 'sensor_count']\n        return all(key in config for key in required_keys)\n    \n    def get_system_health(self):\n        \"\"\"Get system health indicators based on configuration\"\"\"\n        health = {\n            'config_status': 'healthy',\n            'api_connectivity': {},\n            'settings_completeness': 0,\n            'recommendations': []\n        }\n        \n        # Check API configurations\n        api_settings = self.get_api_settings()\n        health['api_connectivity'] = api_settings\n        \n        # Calculate settings completeness\n        total_settings = len(self.default_config)\n        configured_settings = len([k for k, v in self.current_config.items() if v is not None and v != ''])\n        health['settings_completeness'] = (configured_settings / total_settings) * 100\n        \n        # Generate recommendations\n        if not api_settings['openai_configured']:\n            health['recommendations'].append('Configure OpenAI API key for advanced AI analysis')\n        \n        if not api_settings['twilio_configured']:\n            health['recommendations'].append('Configure Twilio for SMS alerts')\n        \n        if not api_settings['sendgrid_configured']:\n            health['recommendations'].append('Configure SendGrid for email notifications')\n        \n        if self.current_config.get('sensor_count', 0) < 20:\n            health['recommendations'].append('Consider deploying more sensors for better coverage')\n        \n        return health\n","size_bytes":9529},"attached_assets/extracted/MineRockGuard/visualization/mine_3d_viz.py":{"content":"import plotly.graph_objects as go\nimport plotly.express as px\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\nclass Mine3DVisualizer:\n    def __init__(self):\n        self.color_schemes = {\n            'Risk-based': {\n                'low': '#00FF00',      # Green\n                'medium': '#FFFF00',   # Yellow\n                'high': '#FF8000',     # Orange\n                'critical': '#FF0000'  # Red\n            },\n            'Elevation': px.colors.sequential.Viridis,\n            'Geological': {\n                'limestone': '#E6E6FA',\n                'sandstone': '#F4A460',\n                'shale': '#708090',\n                'granite': '#696969'\n            }\n        }\n    \n    def create_3d_mine_view(self, mine_data):\n        \"\"\"Create comprehensive 3D visualization of the mine\"\"\"\n        fig = go.Figure()\n        \n        # Add terrain surface\n        dem_data = mine_data['dem']\n        x_terrain = np.array(dem_data['x'])\n        y_terrain = np.array(dem_data['y'])\n        z_terrain = np.array(dem_data['z'])\n        \n        # Create surface plot for terrain\n        fig.add_trace(go.Surface(\n            x=x_terrain,\n            y=y_terrain,\n            z=z_terrain,\n            colorscale='Earth',\n            opacity=0.7,\n            name='Terrain',\n            showscale=False,\n            hovertemplate='X: %{x}<br>Y: %{y}<br>Elevation: %{z}m<extra></extra>'\n        ))\n        \n        # Add risk zones as colored overlays\n        zones = mine_data['zones']\n        for zone in zones:\n            self._add_risk_zone(fig, zone)\n        \n        # Add sensor network\n        sensors = mine_data['sensor_network']\n        self._add_sensor_network(fig, sensors)\n        \n        # Add mine infrastructure\n        self._add_mine_infrastructure(fig, mine_data)\n        \n        # Configure layout\n        fig.update_layout(\n            title=\"3D Mine Visualization with Risk Assessment\",\n            scene=dict(\n                xaxis_title=\"X Coordinate (m)\",\n                yaxis_title=\"Y Coordinate (m)\",\n                zaxis_title=\"Elevation (m)\",\n                camera=dict(\n                    eye=dict(x=1.5, y=1.5, z=1.2)\n                ),\n                aspectmode='manual',\n                aspectratio=dict(x=1, y=0.8, z=0.6)\n            ),\n            width=900,\n            height=700,\n            margin=dict(l=0, r=0, t=50, b=0)\n        )\n        \n        return fig\n    \n    def _add_risk_zone(self, fig, zone):\n        \"\"\"Add risk zone visualization to the figure\"\"\"\n        # Create circular risk zone overlay\n        center = zone['center_coordinates']\n        risk_level = zone['risk_level']\n        \n        # Determine color based on risk level\n        if risk_level >= 0.85:\n            color = 'red'\n            opacity = 0.8\n        elif risk_level >= 0.7:\n            color = 'orange'\n            opacity = 0.6\n        elif risk_level >= 0.3:\n            color = 'yellow'\n            opacity = 0.4\n        else:\n            color = 'green'\n            opacity = 0.3\n        \n        # Create zone boundary\n        theta = np.linspace(0, 2*np.pi, 20)\n        radius = 80  # meters\n        zone_x = center['x'] + radius * np.cos(theta)\n        zone_y = center['y'] + radius * np.sin(theta)\n        zone_z = np.full_like(zone_x, center['z'] + 5)  # Slightly above terrain\n        \n        fig.add_trace(go.Scatter3d(\n            x=zone_x,\n            y=zone_y,\n            z=zone_z,\n            mode='lines',\n            line=dict(color=color, width=8),\n            opacity=opacity,\n            name=f\"{zone['name']} (Risk: {risk_level:.2f})\",\n            hovertemplate=f\"Zone: {zone['name']}<br>Risk Level: {risk_level:.2%}<br>Type: {zone.get('geological_type', 'Unknown')}<extra></extra>\"\n        ))\n        \n        # Add zone center marker\n        fig.add_trace(go.Scatter3d(\n            x=[center['x']],\n            y=[center['y']],\n            z=[center['z'] + 10],\n            mode='markers+text',\n            marker=dict(\n                size=12,\n                color=color,\n                symbol='diamond',\n                opacity=0.9\n            ),\n            text=[zone['name']],\n            textposition='top center',\n            name=f\"{zone['name']} Center\",\n            showlegend=False,\n            hovertemplate=f\"Zone Center: {zone['name']}<br>Coordinates: ({center['x']:.0f}, {center['y']:.0f}, {center['z']:.0f})<br>Geological Type: {zone.get('geological_type', 'Unknown')}<extra></extra>\"\n        ))\n    \n    def _add_sensor_network(self, fig, sensors):\n        \"\"\"Add sensor network to the visualization\"\"\"\n        sensor_types = {}\n        \n        # Group sensors by type for different visualization\n        for sensor in sensors:\n            sensor_type = sensor['type']\n            if sensor_type not in sensor_types:\n                sensor_types[sensor_type] = []\n            sensor_types[sensor_type].append(sensor)\n        \n        # Color mapping for sensor types\n        type_colors = {\n            'displacement': 'blue',\n            'strain': 'purple',\n            'pressure': 'cyan',\n            'vibration': 'magenta',\n            'tilt': 'brown'\n        }\n        \n        # Symbols for sensor types\n        type_symbols = {\n            'displacement': 'circle',\n            'strain': 'square',\n            'pressure': 'diamond',\n            'vibration': 'cross',\n            'tilt': 'x'\n        }\n        \n        for sensor_type, type_sensors in sensor_types.items():\n            x_coords = [s['coordinates']['x'] for s in type_sensors]\n            y_coords = [s['coordinates']['y'] for s in type_sensors]\n            z_coords = [s['coordinates']['z'] for s in type_sensors]\n            sensor_ids = [s['id'] for s in type_sensors]\n            battery_levels = [s.get('battery_level', 100) for s in type_sensors]\n            signal_strengths = [s.get('signal_strength', -80) for s in type_sensors]\n            \n            fig.add_trace(go.Scatter3d(\n                x=x_coords,\n                y=y_coords,\n                z=z_coords,\n                mode='markers',\n                marker=dict(\n                    size=8,\n                    color=type_colors.get(sensor_type, 'gray'),\n                    symbol=type_symbols.get(sensor_type, 'circle'),\n                    opacity=0.8\n                ),\n                name=f\"{sensor_type.title()} Sensors\",\n                text=sensor_ids,\n                hovertemplate=\"Sensor: %{text}<br>Type: \" + sensor_type + \"<br>Battery: %{customdata[0]:.0f}%<br>Signal: %{customdata[1]:.0f} dBm<extra></extra>\",\n                customdata=list(zip(battery_levels, signal_strengths))\n            ))\n    \n    def _add_mine_infrastructure(self, fig, mine_data):\n        \"\"\"Add mine infrastructure elements\"\"\"\n        # Add access roads (simplified)\n        road_points = [\n            {'start': (100, 100, 1250), 'end': (500, 400, 1200)},\n            {'start': (500, 400, 1200), 'end': (800, 600, 1230)},\n            {'start': (300, 200, 1240), 'end': (600, 500, 1210)},\n        ]\n        \n        for i, road in enumerate(road_points):\n            start, end = road['start'], road['end']\n            fig.add_trace(go.Scatter3d(\n                x=[start[0], end[0]],\n                y=[start[1], end[1]],\n                z=[start[2], end[2]],\n                mode='lines',\n                line=dict(color='black', width=6),\n                name=f\"Access Road {i+1}\" if i == 0 else \"\",\n                showlegend=i == 0,\n                hovertemplate=\"Access Road<extra></extra>\"\n            ))\n        \n        # Add equipment zones\n        equipment_zones = [\n            {'name': 'Crusher', 'pos': (200, 150, 1280), 'color': 'brown'},\n            {'name': 'Processing Plant', 'pos': (750, 650, 1290), 'color': 'gray'},\n            {'name': 'Maintenance', 'pos': (600, 200, 1270), 'color': 'orange'},\n        ]\n        \n        for equipment in equipment_zones:\n            pos = equipment['pos']\n            fig.add_trace(go.Scatter3d(\n                x=[pos[0]],\n                y=[pos[1]],\n                z=[pos[2]],\n                mode='markers+text',\n                marker=dict(\n                    size=15,\n                    color=equipment['color'],\n                    symbol='square',\n                    opacity=0.8\n                ),\n                text=[equipment['name']],\n                textposition='top center',\n                name=equipment['name'],\n                hovertemplate=f\"{equipment['name']}<br>Location: ({pos[0]}, {pos[1]}, {pos[2]})<extra></extra>\"\n            ))\n    \n    def update_3d_view(self, mine_data, view_mode, show_sensors, show_risk_zones, color_scheme):\n        \"\"\"Update 3D visualization based on user preferences\"\"\"\n        fig = go.Figure()\n        \n        # Base terrain - always shown\n        dem_data = mine_data['dem']\n        x_terrain = np.array(dem_data['x'])\n        y_terrain = np.array(dem_data['y'])\n        z_terrain = np.array(dem_data['z'])\n        \n        # Apply color scheme\n        if color_scheme == 'Elevation':\n            colorscale = 'Viridis'\n        elif color_scheme == 'Geological':\n            colorscale = 'Earth'\n        else:  # Risk-based\n            colorscale = 'RdYlGn_r'\n        \n        fig.add_trace(go.Surface(\n            x=x_terrain,\n            y=y_terrain,\n            z=z_terrain,\n            colorscale=colorscale,\n            opacity=0.7,\n            name='Terrain',\n            showscale=False\n        ))\n        \n        # Add elements based on view mode\n        if view_mode == \"Risk Overlay\" and show_risk_zones:\n            zones = mine_data['zones']\n            for zone in zones:\n                self._add_risk_zone(fig, zone)\n        \n        if view_mode == \"Sensor Network\" and show_sensors:\n            sensors = mine_data['sensor_network']\n            self._add_sensor_network(fig, sensors)\n        \n        if view_mode == \"Geological Layers\":\n            self._add_geological_layers(fig, mine_data)\n        \n        # Standard layout\n        fig.update_layout(\n            title=f\"3D Mine View - {view_mode}\",\n            scene=dict(\n                xaxis_title=\"X Coordinate (m)\",\n                yaxis_title=\"Y Coordinate (m)\",\n                zaxis_title=\"Elevation (m)\",\n                camera=dict(eye=dict(x=1.5, y=1.5, z=1.2))\n            ),\n            width=900,\n            height=700\n        )\n        \n        return fig\n    \n    def _add_geological_layers(self, fig, mine_data):\n        \"\"\"Add geological layer visualization\"\"\"\n        # Simulate geological layers\n        zones = mine_data['zones']\n        layer_colors = {\n            'limestone': '#E6E6FA',\n            'sandstone': '#F4A460', \n            'shale': '#708090',\n            'granite': '#696969'\n        }\n        \n        for zone in zones:\n            geo_type = zone.get('geological_type', 'unknown')\n            center = zone['center_coordinates']\n            \n            # Create geological formation representation\n            theta = np.linspace(0, 2*np.pi, 12)\n            radius = 60\n            \n            for layer in range(3):  # 3 geological layers\n                layer_x = center['x'] + radius * np.cos(theta)\n                layer_y = center['y'] + radius * np.sin(theta)\n                layer_z = np.full_like(layer_x, center['z'] - layer * 20)\n                \n                fig.add_trace(go.Scatter3d(\n                    x=layer_x,\n                    y=layer_y,\n                    z=layer_z,\n                    mode='lines',\n                    line=dict(\n                        color=layer_colors.get(geo_type, 'gray'),\n                        width=6 - layer\n                    ),\n                    opacity=0.6 - layer * 0.1,\n                    name=f\"{geo_type.title()} Layer {layer+1}\" if layer == 0 else \"\",\n                    showlegend=layer == 0,\n                    hovertemplate=f\"Geological Layer: {geo_type}<br>Depth: {layer * 20}m<extra></extra>\"\n                ))\n    \n    def create_risk_heatmap_2d(self, sensor_data):\n        \"\"\"Create 2D risk heatmap overlay\"\"\"\n        # Extract sensor positions and risk levels\n        x_coords = []\n        y_coords = []\n        risk_levels = []\n        \n        for sensor in sensor_data:\n            if 'coordinates' in sensor:\n                x_coords.append(sensor['coordinates'].get('lat', 0))\n                y_coords.append(sensor['coordinates'].get('lon', 0))\n                risk_levels.append(sensor.get('risk_probability', 0))\n        \n        # Create heatmap\n        fig = go.Figure(data=go.Scatter(\n            x=x_coords,\n            y=y_coords,\n            mode='markers',\n            marker=dict(\n                size=risk_levels,\n                color=risk_levels,\n                colorscale='RdYlGn_r',\n                showscale=True,\n                colorbar=dict(title=\"Risk Level\"),\n                sizemode='diameter',\n                sizeref=0.02,\n                sizemin=5\n            ),\n            text=[f\"Sensor {s['id']}: {s['risk_probability']:.1%}\" for s in sensor_data],\n            hovertemplate='%{text}<br>Coordinates: (%{x:.3f}, %{y:.3f})<extra></extra>'\n        ))\n        \n        fig.update_layout(\n            title=\"Mine Risk Heatmap\",\n            xaxis_title=\"Latitude\",\n            yaxis_title=\"Longitude\",\n            width=800,\n            height=600\n        )\n        \n        return fig\n","size_bytes":13371},"communication/drone_integration.py":{"content":"\"\"\"\nDrone Integration Module\nIntegrates drone system with existing alert and monitoring infrastructure\n\"\"\"\n\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any, Optional\nimport json\nimport logging\nimport threading\nimport time\n\nfrom communication.drone_system import DroneSystem\nfrom database.database_manager import get_rockfall_db\nfrom database.schema import DroneFlightLog, DroneImageAnalysis, DroneAlert, Alert\nfrom alerts.notification_system import NotificationSystem\n\nlogger = logging.getLogger(__name__)\n\nclass DroneIntegration:\n    \"\"\"Integration layer between drone system and mine safety infrastructure\"\"\"\n    \n    def __init__(self):\n        self.drone_system = DroneSystem()\n        self.db_manager = get_rockfall_db()\n        self.notification_system = NotificationSystem()\n        self.sensor_failure_threshold = 3  # Number of failed sensors to trigger drone backup\n        self.last_sensor_check = datetime.now()\n        self.drone_backup_active = False\n        self.parallel_monitoring_active = False\n        self.last_parallel_analysis = None\n        self.current_drone_risk_level = \"low\"\n        self.current_sensor_risk_level = \"low\"\n        self.current_flight_log_id = None  # Track current flight log for parallel monitoring\n        self.monitoring_interval = 30  # Seconds between drone captures\n        self.monitoring_thread = None  # Background monitoring thread\n        self.stop_monitoring = False  # Flag to stop background monitoring\n        \n    def start_routine_patrol(self, mine_site_id: int = 1) -> Dict[str, Any]:\n        \"\"\"Start routine drone patrol mission\"\"\"\n        try:\n            # Log flight start in database\n            flight_log = self._create_flight_log(mine_site_id, \"patrol\")\n            \n            # Start drone mission\n            mission_result = self.drone_system.start_flight_mission(\"patrol\")\n            \n            if mission_result[\"success\"]:\n                # Perform image captures along flight path\n                self._execute_patrol_mission(int(flight_log.id), mine_site_id)\n                \n                return {\n                    \"success\": True,\n                    \"message\": \"Routine patrol started successfully\",\n                    \"flight_log_id\": flight_log.id,\n                    \"estimated_completion\": datetime.now() + timedelta(minutes=30)\n                }\n            else:\n                return mission_result\n                \n        except Exception as e:\n            logger.error(f\"Failed to start routine patrol: {e}\")\n            return {\"success\": False, \"message\": str(e)}\n    \n    def start_parallel_monitoring(self, mine_site_id: int = 1) -> Dict[str, Any]:\n        \"\"\"Start continuous parallel monitoring with both sensors and drone\"\"\"\n        try:\n            logger.info(\"Starting parallel monitoring system\")\n            \n            # Activate drone for continuous monitoring\n            self.drone_system.is_active = True\n            self.parallel_monitoring_active = True\n            \n            # Create initial flight log for parallel monitoring\n            flight_log = self._create_flight_log(mine_site_id, \"parallel_monitoring\")\n            self.current_flight_log_id = flight_log.id\n            \n            # Start background monitoring thread\n            self._start_background_monitoring_thread(mine_site_id)\n            \n            # Perform initial capture\n            self._start_continuous_drone_monitoring(mine_site_id)\n            \n            return {\n                \"success\": True,\n                \"message\": \"Parallel monitoring system activated\",\n                \"drone_active\": True,\n                \"sensor_monitoring\": True,\n                \"mode\": \"parallel\",\n                \"flight_log_id\": flight_log.id\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to start parallel monitoring: {e}\")\n            return {\"success\": False, \"message\": str(e)}\n    \n    def stop_parallel_monitoring(self) -> Dict[str, Any]:\n        \"\"\"Stop continuous parallel monitoring\"\"\"\n        try:\n            logger.info(\"Stopping parallel monitoring system\")\n            \n            # Stop background monitoring\n            self.stop_monitoring = True\n            self.parallel_monitoring_active = False\n            \n            # Wait for thread to finish\n            if self.monitoring_thread and self.monitoring_thread.is_alive():\n                self.monitoring_thread.join(timeout=5)\n            \n            # Deactivate drone\n            self.drone_system.is_active = False\n            \n            return {\n                \"success\": True,\n                \"message\": \"Parallel monitoring system stopped\",\n                \"drone_active\": False,\n                \"sensor_monitoring\": False,\n                \"mode\": \"stopped\"\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to stop parallel monitoring: {e}\")\n            return {\"success\": False, \"message\": str(e)}\n    \n    def _start_background_monitoring_thread(self, mine_site_id: int):\n        \"\"\"Start background thread for continuous monitoring\"\"\"\n        def monitoring_loop():\n            logger.info(f\"Background monitoring thread started (interval: {self.monitoring_interval}s)\")\n            \n            while not self.stop_monitoring and self.parallel_monitoring_active:\n                try:\n                    # Perform drone monitoring capture\n                    self._start_continuous_drone_monitoring(mine_site_id)\n                    \n                    # Wait for next interval\n                    time.sleep(self.monitoring_interval)\n                    \n                except Exception as e:\n                    logger.error(f\"Background monitoring error: {e}\")\n                    time.sleep(5)  # Short delay on error\n            \n            logger.info(\"Background monitoring thread stopped\")\n        \n        # Reset stop flag and start thread\n        self.stop_monitoring = False\n        self.monitoring_thread = threading.Thread(target=monitoring_loop, daemon=True)\n        self.monitoring_thread.start()\n    \n    def get_parallel_predictions(self, mine_site_id: int = 1) -> Dict[str, Any]:\n        \"\"\"Get real-time predictions from both sensor and drone systems\"\"\"\n        try:\n            # Get sensor predictions (simulated for now)\n            sensor_prediction = self._get_sensor_prediction(mine_site_id)\n            \n            # Get latest drone analysis\n            drone_prediction = self._get_latest_drone_prediction(mine_site_id)\n            \n            # Combine predictions with confidence weighting\n            combined_prediction = self._combine_predictions(sensor_prediction, drone_prediction)\n            \n            return {\n                \"timestamp\": datetime.now().isoformat(),\n                \"sensor_prediction\": sensor_prediction,\n                \"drone_prediction\": drone_prediction,\n                \"combined_prediction\": combined_prediction,\n                \"monitoring_status\": {\n                    \"sensors_active\": self._check_sensors_status(mine_site_id),\n                    \"drone_active\": self.drone_system.is_active,\n                    \"parallel_mode\": self.parallel_monitoring_active\n                }\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to get parallel predictions: {e}\")\n            return {\"success\": False, \"message\": str(e)}\n    \n    def _start_continuous_drone_monitoring(self, mine_site_id: int):\n        \"\"\"Perform drone monitoring capture and analysis\"\"\"\n        try:\n            if not self.current_flight_log_id:\n                logger.warning(\"No active flight log for drone monitoring\")\n                return\n                \n            # Perform image capture and analysis\n            location = {\"lat\": -23.5505, \"lng\": -46.6333, \"altitude\": 100}  # Mine location\n            capture_result = self.drone_system.capture_and_analyze_image(location)\n            \n            if capture_result[\"success\"]:\n                # Store analysis\n                analysis_id = self._store_image_analysis(\n                    self.current_flight_log_id, mine_site_id, capture_result[\"result\"]\n                )\n                \n                # Update current drone risk level\n                self.current_drone_risk_level = capture_result[\"result\"][\"analysis\"][\"risk_level\"]\n                self.last_parallel_analysis = datetime.now()\n                \n                # Generate alert if high risk detected\n                if capture_result[\"risk_detected\"]:\n                    self._generate_drone_alert(analysis_id, mine_site_id, capture_result[\"result\"])\n                    \n                logger.info(f\"Drone analysis completed - Risk Level: {self.current_drone_risk_level}\")\n                \n        except Exception as e:\n            logger.error(f\"Continuous drone monitoring error: {e}\")\n    \n    def _get_sensor_prediction(self, mine_site_id: int) -> Dict[str, Any]:\n        \"\"\"Get current sensor-based prediction\"\"\"\n        try:\n            from models.rockfall_predictor import RockfallPredictor\n            \n            # Initialize predictor\n            predictor = RockfallPredictor()\n            \n            # Get latest sensor data (simulated for now)\n            sensor_data = self._get_latest_sensor_data(mine_site_id)\n            \n            # Make prediction\n            prediction = predictor.predict_risk(sensor_data)\n            self.current_sensor_risk_level = prediction[\"risk_level\"]\n            \n            return {\n                \"risk_level\": prediction[\"risk_level\"],\n                \"risk_score\": prediction[\"risk_probability\"],\n                \"confidence\": prediction[\"confidence\"],\n                \"data_source\": \"sensors\",\n                \"sensor_count\": len(sensor_data),\n                \"timestamp\": datetime.now().isoformat()\n            }\n            \n        except Exception as e:\n            logger.error(f\"Sensor prediction error: {e}\")\n            return {\n                \"risk_level\": \"unknown\",\n                \"risk_score\": 0.0,\n                \"confidence\": 0.0,\n                \"data_source\": \"sensors\",\n                \"error\": str(e)\n            }\n    \n    def _get_latest_drone_prediction(self, mine_site_id: int) -> Dict[str, Any]:\n        \"\"\"Get latest drone analysis prediction\"\"\"\n        try:\n            # Check if we need a fresh capture (for continuous monitoring)\n            needs_fresh_capture = (\n                not self.last_parallel_analysis or \n                (datetime.now() - self.last_parallel_analysis).total_seconds() > self.monitoring_interval\n            )\n            \n            if needs_fresh_capture and self.parallel_monitoring_active:\n                # Trigger new analysis for continuous monitoring\n                self._start_continuous_drone_monitoring(mine_site_id)\n            \n            return {\n                \"risk_level\": self.current_drone_risk_level,\n                \"risk_score\": self._risk_level_to_score(self.current_drone_risk_level),\n                \"confidence\": 0.85,  # Drone analysis confidence\n                \"data_source\": \"drone_imaging\",\n                \"last_analysis\": self.last_parallel_analysis.isoformat() if self.last_parallel_analysis else None,\n                \"timestamp\": datetime.now().isoformat(),\n                \"seconds_since_capture\": (datetime.now() - self.last_parallel_analysis).total_seconds() if self.last_parallel_analysis else 0\n            }\n            \n        except Exception as e:\n            logger.error(f\"Drone prediction error: {e}\")\n            return {\n                \"risk_level\": \"unknown\",\n                \"risk_score\": 0.0,\n                \"confidence\": 0.0,\n                \"data_source\": \"drone_imaging\",\n                \"error\": str(e)\n            }\n    \n    def _combine_predictions(self, sensor_pred: Dict, drone_pred: Dict) -> Dict[str, Any]:\n        \"\"\"Combine sensor and drone predictions with intelligent weighting\"\"\"\n        try:\n            # Weight based on data availability and confidence\n            sensor_weight = 0.6 if sensor_pred.get(\"confidence\", 0) > 0.5 else 0.3\n            drone_weight = 0.4 if drone_pred.get(\"confidence\", 0) > 0.5 else 0.7\n            \n            # Normalize weights\n            total_weight = sensor_weight + drone_weight\n            sensor_weight /= total_weight\n            drone_weight /= total_weight\n            \n            # Combine risk scores\n            sensor_score = sensor_pred.get(\"risk_score\", 0)\n            drone_score = drone_pred.get(\"risk_score\", 0)\n            combined_score = (sensor_score * sensor_weight) + (drone_score * drone_weight)\n            \n            # Determine combined risk level\n            if combined_score >= 0.7:\n                combined_risk = \"critical\"\n            elif combined_score >= 0.5:\n                combined_risk = \"high\"\n            elif combined_score >= 0.3:\n                combined_risk = \"medium\"\n            else:\n                combined_risk = \"low\"\n            \n            return {\n                \"risk_level\": combined_risk,\n                \"risk_score\": combined_score,\n                \"confidence\": min(sensor_pred.get(\"confidence\", 0), drone_pred.get(\"confidence\", 0)),\n                \"sensor_weight\": sensor_weight,\n                \"drone_weight\": drone_weight,\n                \"agreement\": self._calculate_prediction_agreement(sensor_pred, drone_pred),\n                \"data_sources\": \"sensors_and_drone\"\n            }\n            \n        except Exception as e:\n            logger.error(f\"Prediction combination error: {e}\")\n            return {\n                \"risk_level\": \"unknown\",\n                \"risk_score\": 0.0,\n                \"confidence\": 0.0,\n                \"error\": str(e)\n            }\n    \n    def _risk_level_to_score(self, risk_level: str) -> float:\n        \"\"\"Convert risk level to numerical score\"\"\"\n        risk_mapping = {\n            \"low\": 0.2,\n            \"medium\": 0.4,\n            \"high\": 0.7,\n            \"critical\": 0.9,\n            \"unknown\": 0.0\n        }\n        return risk_mapping.get(risk_level, 0.0)\n    \n    def _calculate_prediction_agreement(self, sensor_pred: Dict, drone_pred: Dict) -> float:\n        \"\"\"Calculate agreement between sensor and drone predictions\"\"\"\n        try:\n            sensor_score = sensor_pred.get(\"risk_score\", 0)\n            drone_score = drone_pred.get(\"risk_score\", 0)\n            \n            # Calculate similarity (1.0 = perfect agreement, 0.0 = complete disagreement)\n            difference = abs(sensor_score - drone_score)\n            agreement = max(0.0, 1.0 - difference)\n            \n            return round(agreement, 2)\n            \n        except Exception:\n            return 0.0\n    \n    def _get_latest_sensor_data(self, mine_site_id: int) -> Dict[str, float]:\n        \"\"\"Get latest sensor readings (simulated for now)\"\"\"\n        import random\n        \n        return {\n            'displacement_rate': random.uniform(0.1, 2.0),\n            'strain_magnitude': random.uniform(0.05, 1.5),\n            'pore_pressure': random.uniform(10, 100),\n            'temperature': random.uniform(15, 35),\n            'rainfall': random.uniform(0, 50),\n            'wind_speed': random.uniform(0, 25),\n            'vibration_level': random.uniform(0.1, 5.0),\n            'slope_angle': random.uniform(30, 70),\n            'soil_moisture': random.uniform(10, 80),\n            'crack_density': random.uniform(0.1, 2.0)\n        }\n    \n    def _check_sensors_status(self, mine_site_id: int) -> bool:\n        \"\"\"Check if sensors are currently active and reporting\"\"\"\n        try:\n            # When parallel monitoring is active, sensors are considered active by default\n            # since we're generating synthetic sensor data for the predictions\n            if self.parallel_monitoring_active:\n                return True\n                \n            session = self.db_manager.db_manager.get_session()\n            from database.schema import Sensor, SensorReading\n            \n            # Check for recent sensor readings\n            cutoff_time = datetime.now() - timedelta(minutes=5)\n            recent_readings = session.query(SensorReading).filter(\n                SensorReading.timestamp >= cutoff_time\n            ).count()\n            \n            return recent_readings > 0\n            \n        except Exception:\n            return True  # Assume active if check fails\n        finally:\n            if 'session' in locals():\n                self.db_manager.db_manager.close_session(session)\n    \n    def _create_flight_log(self, mine_site_id: int, mission_type: str) -> DroneFlightLog:\n        \"\"\"Create flight log entry in database\"\"\"\n        session = self.db_manager.db_manager.get_session()\n        try:\n            drone_status = self.drone_system.get_drone_status()\n            \n            flight_log = DroneFlightLog(\n                mine_site_id=mine_site_id,\n                drone_id=drone_status[\"drone_id\"],\n                mission_type=mission_type,\n                start_time=datetime.now(),\n                flight_status=\"flying\",\n                battery_start=drone_status[\"battery_level\"],\n                weather_conditions=\"clear\",  # Would integrate with weather API\n                flight_path=self.drone_system.flight_path\n            )\n            \n            session.add(flight_log)\n            session.commit()\n            session.refresh(flight_log)\n            return flight_log\n            \n        finally:\n            self.db_manager.db_manager.close_session(session)\n    \n    def _execute_patrol_mission(self, flight_log_id: int, mine_site_id: int):\n        \"\"\"Execute patrol mission and process results\"\"\"\n        images_captured = 0\n        alerts_generated = 0\n        \n        # Capture images at each point in flight path\n        for waypoint in self.drone_system.flight_path:\n            if waypoint.get(\"capture_image\", False):\n                capture_result = self.drone_system.capture_and_analyze_image(waypoint)\n                \n                if capture_result[\"success\"]:\n                    images_captured += 1\n                    \n                    # Store analysis in database\n                    analysis_id = self._store_image_analysis(\n                        int(flight_log_id), mine_site_id, capture_result[\"result\"]\n                    )\n                    \n                    # Check if alert should be generated\n                    if capture_result[\"risk_detected\"]:\n                        alert_generated = self._generate_drone_alert(\n                            analysis_id, mine_site_id, capture_result[\"result\"]\n                        )\n                        if alert_generated:\n                            alerts_generated += 1\n        \n        # Update flight log with results\n        self._update_flight_log(int(flight_log_id), images_captured, alerts_generated)\n    \n    def _store_image_analysis(self, flight_log_id: int, mine_site_id: int, \n                            analysis_result: Dict[str, Any]) -> int:\n        \"\"\"Store drone image analysis results in database\"\"\"\n        session = self.db_manager.db_manager.get_session()\n        try:\n            image_analysis = DroneImageAnalysis(\n                flight_log_id=flight_log_id,\n                mine_site_id=mine_site_id,\n                timestamp=datetime.fromisoformat(analysis_result[\"timestamp\"]),\n                image_path=analysis_result[\"image_path\"],\n                capture_location=analysis_result[\"location\"],\n                risk_score=analysis_result[\"analysis\"][\"risk_score\"],\n                risk_level=analysis_result[\"analysis\"][\"risk_level\"],\n                confidence=analysis_result[\"analysis\"][\"confidence\"],\n                analysis_time_ms=analysis_result[\"analysis\"][\"analysis_time_ms\"],\n                features_detected=analysis_result[\"analysis\"][\"features_detected\"],\n                risk_indicators=analysis_result[\"analysis\"][\"indicators\"],\n                camera_settings=analysis_result[\"camera_settings\"],\n                weather_conditions=analysis_result[\"analysis\"][\"weather_conditions\"],\n                lighting_conditions=analysis_result[\"analysis\"][\"lighting_conditions\"],\n                image_quality=analysis_result[\"analysis\"][\"image_quality\"]\n            )\n            \n            session.add(image_analysis)\n            session.commit()\n            session.refresh(image_analysis)\n            return image_analysis.id\n            \n        finally:\n            self.db_manager.db_manager.close_session(session)\n    \n    def _generate_drone_alert(self, analysis_id: int, mine_site_id: int, \n                            analysis_result: Dict[str, Any]) -> bool:\n        \"\"\"Generate alert based on drone analysis results\"\"\"\n        try:\n            analysis = analysis_result[\"analysis\"]\n            \n            # Determine if alert should be generated\n            if analysis[\"risk_level\"] in [\"high\", \"critical\"]:\n                session = self.db_manager.db_manager.get_session()\n                try:\n                    # Create drone-specific alert\n                    drone_alert = DroneAlert(\n                        image_analysis_id=analysis_id,\n                        mine_site_id=mine_site_id,\n                        drone_id=analysis_result[\"drone_id\"],\n                        timestamp=datetime.fromisoformat(analysis_result[\"timestamp\"]),\n                        alert_type=\"rockfall_risk\",\n                        risk_level=analysis[\"risk_level\"],\n                        location=analysis_result[\"location\"],\n                        description=f\"Drone detected {analysis['risk_level']} rockfall risk. \"\n                                  f\"Features detected: {', '.join(analysis['features_detected'])}\",\n                        recommended_actions=[\n                            \"Immediate area inspection required\",\n                            \"Consider evacuation of nearby personnel\",\n                            \"Deploy additional sensors if available\",\n                            \"Monitor area with increased frequency\"\n                        ],\n                        sensor_backup_mode=self.drone_backup_active\n                    )\n                    \n                    session.add(drone_alert)\n                    session.commit()\n                    \n                    # Send notifications\n                    self._send_drone_alert_notifications(drone_alert, analysis)\n                    \n                    return True\n                    \n                finally:\n                    self.db_manager.db_manager.close_session(session)\n            \n            return False\n            \n        except Exception as e:\n            logger.error(f\"Failed to generate drone alert: {e}\")\n            return False\n    \n    def _send_drone_alert_notifications(self, drone_alert: DroneAlert, analysis: Dict[str, Any]):\n        \"\"\"Send notifications for drone-detected risks\"\"\"\n        try:\n            # Prepare notification message\n            message = f\"\"\"\nDRONE ALERT - {drone_alert.risk_level.upper()} RISK DETECTED\n\nLocation: Lat {drone_alert.location['lat']:.6f}, Lon {drone_alert.location['lon']:.6f}\nRisk Score: {analysis['risk_score']:.1f}/100\nConfidence: {analysis['confidence']:.1%}\nFeatures: {', '.join(analysis['features_detected'])}\n\n{\"‚ö†Ô∏è SENSOR BACKUP MODE ACTIVE ‚ö†Ô∏è\" if drone_alert.sensor_backup_mode else \"\"}\n\nImmediate inspection recommended.\n\"\"\"\n            \n            # Send notifications through existing system\n            notification_result = self.notification_system.send_alert_notification(\n                alert_type=\"drone_risk_detection\",\n                risk_level=drone_alert.risk_level,\n                message=message,\n                location=drone_alert.location\n            )\n            \n            # Update alert with notification status\n            if notification_result.get(\"success\", False):\n                session = self.db_manager.db_manager.get_session()\n                try:\n                    drone_alert.notification_sent = True\n                    session.commit()\n                finally:\n                    self.db_manager.db_manager.close_session(session)\n            \n        except Exception as e:\n            logger.error(f\"Failed to send drone alert notifications: {e}\")\n    \n    def _update_flight_log(self, flight_log_id: int, images_captured: int, alerts_generated: int):\n        \"\"\"Update flight log with mission results\"\"\"\n        session = self.db_manager.db_manager.get_session()\n        try:\n            flight_log = session.query(DroneFlightLog).get(flight_log_id)\n            if flight_log:\n                drone_status = self.drone_system.get_drone_status()\n                flight_log.end_time = datetime.now()\n                flight_log.flight_status = \"completed\"\n                flight_log.battery_end = drone_status[\"battery_level\"]\n                flight_log.images_captured = images_captured\n                flight_log.risk_alerts_generated = alerts_generated\n                \n                if flight_log.start_time:\n                    duration = datetime.now() - flight_log.start_time\n                    flight_log.total_flight_time = int(duration.total_seconds() / 60)\n                \n                session.commit()\n                \n        finally:\n            self.db_manager.db_manager.close_session(session)\n    \n    def check_sensor_status_and_activate_backup(self, mine_site_id: int = 1) -> Dict[str, Any]:\n        \"\"\"Check sensor status and activate drone backup if needed\"\"\"\n        try:\n            # Get sensor status from database\n            failed_sensors = self._count_failed_sensors(mine_site_id)\n            \n            if failed_sensors >= self.sensor_failure_threshold and not self.drone_backup_active:\n                # Activate drone backup mode\n                return self._activate_sensor_backup_mode(mine_site_id)\n            elif failed_sensors < self.sensor_failure_threshold and self.drone_backup_active:\n                # Deactivate backup mode\n                return self._deactivate_sensor_backup_mode()\n            \n            return {\n                \"success\": True,\n                \"backup_mode\": self.drone_backup_active,\n                \"failed_sensors\": failed_sensors,\n                \"threshold\": self.sensor_failure_threshold\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to check sensor status: {e}\")\n            return {\"success\": False, \"message\": str(e)}\n    \n    def _count_failed_sensors(self, mine_site_id: int) -> int:\n        \"\"\"Count the number of failed sensors\"\"\"\n        # This would integrate with the existing sensor monitoring system\n        # For now, simulate based on recent sensor readings\n        session = self.db_manager.db_manager.get_session()\n        try:\n            from database.schema import Sensor, SensorReading\n            \n            # Check sensors that haven't reported in the last hour\n            cutoff_time = datetime.now() - timedelta(hours=1)\n            \n            # Get all active sensors\n            active_sensors = session.query(Sensor).filter_by(\n                mine_site_id=mine_site_id, status='active'\n            ).all()\n            \n            failed_count = 0\n            for sensor in active_sensors:\n                recent_reading = session.query(SensorReading).filter_by(\n                    sensor_id=sensor.id\n                ).filter(SensorReading.timestamp >= cutoff_time).first()\n                \n                if not recent_reading:\n                    failed_count += 1\n            \n            return failed_count\n            \n        finally:\n            self.db_manager.db_manager.close_session(session)\n    \n    def _activate_sensor_backup_mode(self, mine_site_id: int) -> Dict[str, Any]:\n        \"\"\"Activate drone backup mode when sensors fail\"\"\"\n        try:\n            self.drone_backup_active = True\n            \n            # Start emergency drone mission\n            emergency_result = self.drone_system.simulate_sensor_failure_detection()\n            \n            if emergency_result[\"success\"]:\n                # Log emergency mission\n                flight_log = self._create_flight_log(mine_site_id, \"emergency\")\n                \n                # Process emergency results\n                alerts_generated = 0\n                for result in emergency_result.get(\"emergency_results\", []):\n                    analysis_id = self._store_image_analysis(\n                        flight_log.id, mine_site_id, result\n                    )\n                    \n                    # Generate alerts for high-risk areas\n                    if result[\"analysis\"][\"risk_level\"] in [\"high\", \"critical\"]:\n                        if self._generate_drone_alert(analysis_id, mine_site_id, result):\n                            alerts_generated += 1\n                \n                # Update flight log\n                self._update_flight_log(\n                    flight_log.id, \n                    len(emergency_result.get(\"emergency_results\", [])), \n                    alerts_generated\n                )\n                \n                # Send backup mode notification\n                self._send_backup_mode_notification(mine_site_id, True)\n                \n                return {\n                    \"success\": True,\n                    \"message\": \"Drone backup mode activated\",\n                    \"emergency_scan_completed\": True,\n                    \"high_risk_detected\": emergency_result.get(\"high_risk_detected\", False)\n                }\n            \n            return emergency_result\n            \n        except Exception as e:\n            logger.error(f\"Failed to activate sensor backup mode: {e}\")\n            return {\"success\": False, \"message\": str(e)}\n    \n    def _deactivate_sensor_backup_mode(self) -> Dict[str, Any]:\n        \"\"\"Deactivate drone backup mode when sensors are restored\"\"\"\n        self.drone_backup_active = False\n        \n        # Send notification about restored sensor operation\n        self._send_backup_mode_notification(1, False)\n        \n        return {\n            \"success\": True,\n            \"message\": \"Drone backup mode deactivated - sensors restored\",\n            \"backup_mode\": False\n        }\n    \n    def _send_backup_mode_notification(self, mine_site_id: int, activated: bool):\n        \"\"\"Send notification about backup mode status\"\"\"\n        try:\n            if activated:\n                message = \"\"\"\nüö® SENSOR FAILURE DETECTED - DRONE BACKUP ACTIVATED\n\nMultiple sensors have failed to report. Drone emergency monitoring is now active.\nContinuous aerial surveillance has been initiated to maintain safety coverage.\n\nActions taken:\n- Emergency drone patrol deployed\n- High-risk areas scanned\n- Alert system remains operational\n\nPlease check sensor connectivity and perform maintenance as needed.\n\"\"\"\n            else:\n                message = \"\"\"\n‚úÖ SENSOR SYSTEM RESTORED - DRONE BACKUP DEACTIVATED\n\nSensor connectivity has been restored. Returning to normal monitoring mode.\nDrone backup monitoring has been successfully deactivated.\n\nNormal sensor-based monitoring is now active.\n\"\"\"\n            \n            self.notification_system.send_alert_notification(\n                alert_type=\"sensor_backup_mode\",\n                risk_level=\"medium\" if activated else \"low\",\n                message=message,\n                location={\"lat\": 39.7392, \"lon\": -104.9903}\n            )\n            \n        except Exception as e:\n            logger.error(f\"Failed to send backup mode notification: {e}\")\n    \n    def get_drone_monitoring_status(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive drone monitoring status\"\"\"\n        try:\n            drone_status = self.drone_system.get_drone_status()\n            recent_analyses = self.drone_system.get_recent_analysis_results(5)\n            \n            # Get database statistics\n            session = self.db_manager.db_manager.get_session()\n            try:\n                # Count today's flights\n                today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n                todays_flights = session.query(DroneFlightLog).filter(\n                    DroneFlightLog.start_time >= today\n                ).count()\n                \n                # Count today's images\n                todays_images = session.query(DroneImageAnalysis).filter(\n                    DroneImageAnalysis.timestamp >= today\n                ).count()\n                \n                # Count active drone alerts\n                active_drone_alerts = session.query(DroneAlert).filter_by(resolved=False).count()\n                \n            finally:\n                self.db_manager.db_manager.close_session(session)\n            \n            return {\n                \"drone_status\": drone_status,\n                \"backup_mode_active\": self.drone_backup_active,\n                \"recent_analyses\": recent_analyses,\n                \"daily_stats\": {\n                    \"flights_today\": todays_flights,\n                    \"images_captured_today\": todays_images,\n                    \"active_alerts\": active_drone_alerts\n                },\n                \"last_sensor_check\": self.last_sensor_check.isoformat()\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to get drone monitoring status: {e}\")\n            return {\"success\": False, \"message\": str(e)}","size_bytes":33446},"communication/drone_system.py":{"content":"\"\"\"\nDrone System for Aerial Mine Monitoring and Image Capture\nProvides drone simulation, image capture, and computer vision analysis for rockfall detection\n\"\"\"\n\nimport json\nimport time\nimport random\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any, Optional, Tuple\ntry:\n    import cv2\n    OPENCV_AVAILABLE = True\nexcept ImportError:\n    OPENCV_AVAILABLE = False\n    cv2 = None\nimport os\nfrom pathlib import Path\n\nclass DroneSystem:\n    \"\"\"Drone simulation and image analysis system for rockfall detection\"\"\"\n    \n    def __init__(self):\n        self.drone_id = \"DRONE_001\"\n        self.is_active = False\n        self.current_position = {\"lat\": 40.5232, \"lon\": -112.1500, \"altitude\": 150}  # Bingham Canyon Mine area\n        self.battery_level = 85.0\n        self.flight_status = \"grounded\"  # grounded, flying, hovering, returning\n        self.image_capture_enabled = True\n        self.analysis_results = []\n        self.flight_path = []\n        self.last_image_capture = None\n        self.camera_settings = {\n            \"resolution\": \"4K\",\n            \"zoom_level\": 1.0,\n            \"exposure\": \"auto\",\n            \"focus\": \"auto\"\n        }\n        \n        # Ensure image directory exists\n        self.image_storage_path = Path(\"./data/drone_images\")\n        self.image_storage_path.mkdir(parents=True, exist_ok=True)\n        \n    def start_flight_mission(self, mission_type: str = \"patrol\") -> Dict[str, Any]:\n        \"\"\"Start a drone flight mission\"\"\"\n        if self.battery_level < 20:\n            return {\n                \"success\": False,\n                \"message\": \"Battery level too low for flight\",\n                \"battery_level\": self.battery_level\n            }\n        \n        self.is_active = True\n        self.flight_status = \"flying\"\n        self.last_image_capture = datetime.now()\n        \n        # Generate flight path for mine area\n        self._generate_flight_path(mission_type)\n        \n        return {\n            \"success\": True,\n            \"message\": f\"Drone {self.drone_id} mission started\",\n            \"mission_type\": mission_type,\n            \"estimated_flight_time\": self._calculate_flight_time(),\n            \"flight_path_points\": len(self.flight_path)\n        }\n    \n    def _generate_flight_path(self, mission_type: str):\n        \"\"\"Generate flight path based on mission type - over mine terrain\"\"\"\n        # Bingham Canyon Mine area (Utah) - actual open-pit mine coordinates\n        base_lat, base_lon = 40.5232, -112.1500\n        \n        if mission_type == \"patrol\":\n            # Create a grid pattern over the mine area with terrain-following altitudes\n            points = []\n            for i in range(6):\n                for j in range(5):\n                    lat_offset = (i - 2.5) * 0.002  # Wider coverage\n                    lon_offset = (j - 2) * 0.002\n                    # Terrain-following altitude (higher over ridges, lower in valleys)\n                    base_altitude = 150\n                    terrain_variation = random.randint(-40, 60)\n                    altitude = base_altitude + terrain_variation\n                    points.append({\n                        \"lat\": base_lat + lat_offset,\n                        \"lon\": base_lon + lon_offset,\n                        \"altitude\": altitude,\n                        \"capture_image\": True,\n                        \"hover_time\": 8,  # longer hover for detailed analysis\n                        \"scan_radius\": 200  # meters\n                    })\n            self.flight_path = points\n            \n        elif mission_type == \"emergency\":\n            # Quick scan of high-risk areas\n            high_risk_points = [\n                {\"lat\": base_lat + 0.001, \"lon\": base_lon - 0.001, \"altitude\": 80},\n                {\"lat\": base_lat - 0.001, \"lon\": base_lon + 0.001, \"altitude\": 85},\n                {\"lat\": base_lat + 0.0005, \"lon\": base_lon + 0.0005, \"altitude\": 75}\n            ]\n            for point in high_risk_points:\n                point[\"capture_image\"] = True\n                point[\"hover_time\"] = 3\n            self.flight_path = high_risk_points\n    \n    def _calculate_flight_time(self) -> int:\n        \"\"\"Calculate estimated flight time in minutes\"\"\"\n        if not self.flight_path:\n            return 0\n        \n        total_hover_time = sum(point.get(\"hover_time\", 0) for point in self.flight_path)\n        travel_time = len(self.flight_path) * 2  # 2 minutes between points\n        return total_hover_time + travel_time\n    \n    def capture_and_analyze_image(self, location: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"Capture image and perform real-time rockfall analysis\"\"\"\n        if not self.is_active:\n            return {\"success\": False, \"message\": \"Drone not active\"}\n        \n        # Simulate image capture\n        timestamp = datetime.now()\n        image_filename = f\"drone_capture_{timestamp.strftime('%Y%m%d_%H%M%S')}.jpg\"\n        image_path = self.image_storage_path / image_filename\n        \n        if OPENCV_AVAILABLE:\n            # Generate synthetic image for simulation\n            synthetic_image = self._generate_synthetic_mine_image(location)\n            cv2.imwrite(str(image_path), synthetic_image)\n            \n            # Perform rockfall detection analysis\n            analysis_result = self._analyze_image_for_rockfall(synthetic_image, location)\n        else:\n            # Fallback mode - create placeholder image file and simulate analysis\n            self._create_placeholder_image(image_path)\n            analysis_result = self._simulate_analysis_result()\n        \n        # Store analysis result\n        result = {\n            \"timestamp\": timestamp.isoformat(),\n            \"location\": location,\n            \"image_path\": str(image_path),\n            \"analysis\": analysis_result,\n            \"drone_id\": self.drone_id,\n            \"camera_settings\": self.camera_settings.copy()\n        }\n        \n        self.analysis_results.append(result)\n        self.last_image_capture = timestamp\n        \n        return {\n            \"success\": True,\n            \"image_captured\": True,\n            \"analysis_complete\": True,\n            \"risk_detected\": analysis_result.get(\"risk_level\", \"low\") in [\"high\", \"critical\"],\n            \"result\": result\n        }\n    \n    def _generate_synthetic_mine_image(self, location: Dict[str, float]) -> np.ndarray:\n        \"\"\"Generate synthetic mine image for simulation (requires OpenCV)\"\"\"\n        if not OPENCV_AVAILABLE:\n            return None\n            \n        # Create a 1920x1080 synthetic image\n        height, width = 1080, 1920\n        image = np.zeros((height, width, 3), dtype=np.uint8)\n        \n        # Add brown/gray mine background\n        image[:] = (120, 140, 160)  # BGR format\n        \n        # Add some rock formations\n        for _ in range(random.randint(5, 15)):\n            center = (random.randint(100, width-100), random.randint(100, height-100))\n            radius = random.randint(30, 150)\n            color = (random.randint(80, 140), random.randint(100, 160), random.randint(90, 150))\n            cv2.circle(image, center, radius, color, -1)\n        \n        # Simulate potential rockfall areas (darker regions)\n        if random.random() > 0.6:  # 40% chance of potential risk\n            for _ in range(random.randint(1, 3)):\n                x = random.randint(200, width-200)\n                y = random.randint(200, height-200)\n                w, h = random.randint(100, 300), random.randint(50, 200)\n                # Darker area suggesting loose rock\n                cv2.rectangle(image, (x, y), (x+w, y+h), (60, 80, 100), -1)\n        \n        return image\n    \n    def _create_placeholder_image(self, image_path: Path):\n        \"\"\"Create a placeholder image file when OpenCV is not available\"\"\"\n        try:\n            # Create a simple text file instead of image when OpenCV unavailable\n            with open(str(image_path).replace('.jpg', '.txt'), 'w') as f:\n                f.write(f\"Drone image captured at {datetime.now()}\\n\")\n                f.write(\"Simulated mode - OpenCV not available\\n\")\n                f.write(\"Analysis performed using fallback algorithms\\n\")\n        except Exception:\n            pass  # Continue even if file creation fails\n    \n    def _analyze_image_for_rockfall(self, image: np.ndarray, location: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"Analyze captured image for rockfall risk indicators\"\"\"\n        \n        if not OPENCV_AVAILABLE or image is None:\n            # Fallback to simulated analysis\n            return self._simulate_analysis_result()\n        \n        # Convert to grayscale for analysis\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        \n        # Edge detection to find rock boundaries\n        edges = cv2.Canny(gray, 50, 150)\n        \n        # Find contours (potential loose rocks)\n        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        # Analyze texture and stability indicators\n        risk_indicators = self._calculate_risk_indicators(gray, list(contours))\n        \n        # Determine overall risk level\n        risk_score = self._calculate_risk_score(risk_indicators)\n        risk_level = self._determine_risk_level(risk_score)\n        \n        # Detect specific features\n        features_detected = self._detect_geological_features(gray, list(contours))\n        \n        analysis_result = {\n            \"risk_score\": risk_score,\n            \"risk_level\": risk_level,\n            \"confidence\": random.uniform(0.75, 0.95),\n            \"indicators\": risk_indicators,\n            \"features_detected\": features_detected,\n            \"image_quality\": \"good\",\n            \"analysis_time_ms\": random.randint(200, 800),\n            \"weather_conditions\": \"clear\",\n            \"lighting_conditions\": \"optimal\"\n        }\n        \n        return analysis_result\n    \n    def _calculate_risk_indicators(self, gray_image: np.ndarray, contours: List) -> Dict[str, float]:\n        \"\"\"Calculate various risk indicators from image analysis\"\"\"\n        \n        # Texture analysis (roughness indicator)\n        texture_variance = np.var(gray_image)\n        \n        # Edge density (fracture indicator)\n        edge_density = len(contours) / (gray_image.shape[0] * gray_image.shape[1]) * 1000000\n        \n        # Large object count (loose rock indicator)\n        large_objects = sum(1 for contour in contours if cv2.contourArea(contour) > 1000) if OPENCV_AVAILABLE else 0\n        \n        # Brightness variance (shadow/overhang indicator)\n        brightness_variance = np.std(gray_image)\n        \n        # Slope estimation (steepness indicator)\n        slope_estimate = random.uniform(25, 75)  # Simulated slope angle\n        \n        return {\n            \"texture_roughness\": float(min(texture_variance / 1000, 1.0)),\n            \"edge_density\": float(min(edge_density / 50, 1.0)),\n            \"loose_rock_count\": float(min(large_objects / 10, 1.0)),\n            \"shadow_presence\": float(min(brightness_variance / 100, 1.0)),\n            \"slope_angle\": float(slope_estimate),\n            \"fracture_density\": float(random.uniform(0.1, 0.8))\n        }\n    \n    def _calculate_risk_score(self, indicators: Dict[str, float]) -> float:\n        \"\"\"Calculate overall risk score from indicators\"\"\"\n        weights = {\n            \"texture_roughness\": 0.15,\n            \"edge_density\": 0.20,\n            \"loose_rock_count\": 0.25,\n            \"shadow_presence\": 0.10,\n            \"slope_angle\": 0.20,\n            \"fracture_density\": 0.10\n        }\n        \n        score = 0\n        for indicator, value in indicators.items():\n            if indicator in weights:\n                if indicator == \"slope_angle\":\n                    # Higher slope = higher risk\n                    normalized_value = min(value / 90, 1.0)\n                else:\n                    normalized_value = value\n                score += weights[indicator] * normalized_value\n        \n        return min(score * 100, 100)  # Scale to 0-100\n    \n    def _determine_risk_level(self, risk_score: float) -> str:\n        \"\"\"Determine risk level based on score\"\"\"\n        if risk_score >= 80:\n            return \"critical\"\n        elif risk_score >= 60:\n            return \"high\"\n        elif risk_score >= 40:\n            return \"medium\"\n        else:\n            return \"low\"\n    \n    def _detect_geological_features(self, gray_image: np.ndarray, contours: List) -> List[str]:\n        \"\"\"Detect specific geological features that indicate risk\"\"\"\n        features = []\n        \n        # Random feature detection for simulation\n        possible_features = [\n            \"loose_debris\", \"overhang\", \"fracture_lines\", \"weathered_surface\",\n            \"steep_slope\", \"unstable_rocks\", \"erosion_patterns\"\n        ]\n        \n        # Simulate feature detection based on image analysis\n        num_features = random.randint(1, 4)\n        features = random.sample(possible_features, num_features)\n        \n        return features\n    \n    def _simulate_analysis_result(self) -> Dict[str, Any]:\n        \"\"\"Simulate analysis result when OpenCV is not available\"\"\"\n        risk_score = random.uniform(20, 80)\n        risk_level = self._determine_risk_level(risk_score)\n        \n        features = [\"slope_analysis\", \"visual_inspection\"]\n        if risk_score > 60:\n            features.extend([\"loose_debris\", \"steep_slope\"])\n        \n        return {\n            \"risk_score\": risk_score,\n            \"risk_level\": risk_level,\n            \"confidence\": random.uniform(0.75, 0.95),\n            \"indicators\": {\n                \"texture_roughness\": random.uniform(0.3, 0.8),\n                \"edge_density\": random.uniform(0.2, 0.7),\n                \"loose_rock_count\": random.uniform(0.1, 0.6),\n                \"shadow_presence\": random.uniform(0.2, 0.5),\n                \"slope_angle\": random.uniform(25, 75),\n                \"fracture_density\": random.uniform(0.1, 0.8)\n            },\n            \"features_detected\": features,\n            \"image_quality\": \"simulated\",\n            \"analysis_time_ms\": random.randint(100, 300),\n            \"weather_conditions\": \"clear\",\n            \"lighting_conditions\": \"simulated\"\n        }\n    \n    def get_drone_status(self) -> Dict[str, Any]:\n        \"\"\"Get current drone status and telemetry\"\"\"\n        return {\n            \"drone_id\": self.drone_id,\n            \"is_active\": self.is_active,\n            \"flight_status\": self.flight_status,\n            \"current_position\": self.current_position,\n            \"battery_level\": self.battery_level,\n            \"last_image_capture\": self.last_image_capture.isoformat() if self.last_image_capture else None,\n            \"images_captured_today\": len(self.analysis_results),\n            \"flight_time_remaining\": self._estimate_remaining_flight_time(),\n            \"camera_status\": \"operational\",\n            \"gps_signal\": \"strong\",\n            \"communication_link\": \"stable\"\n        }\n    \n    def _estimate_remaining_flight_time(self) -> int:\n        \"\"\"Estimate remaining flight time based on battery\"\"\"\n        if not self.is_active:\n            return 0\n        \n        # Rough estimate: 1% battery = 2 minutes flight time\n        return int((self.battery_level - 20) * 2)  # Keep 20% for safe landing\n    \n    def emergency_return(self) -> Dict[str, Any]:\n        \"\"\"Emergency return to base\"\"\"\n        self.flight_status = \"returning\"\n        return {\n            \"success\": True,\n            \"message\": \"Emergency return initiated\",\n            \"estimated_return_time\": 5,  # minutes\n            \"reason\": \"emergency_protocol\"\n        }\n    \n    def land_drone(self) -> Dict[str, Any]:\n        \"\"\"Land the drone and end mission\"\"\"\n        self.is_active = False\n        self.flight_status = \"grounded\"\n        self.current_position = {\"lat\": 39.7392, \"lon\": -104.9903, \"altitude\": 0}\n        \n        return {\n            \"success\": True,\n            \"message\": \"Drone landed successfully\",\n            \"mission_summary\": {\n                \"images_captured\": len(self.analysis_results),\n                \"flight_time\": \"completed\",\n                \"battery_remaining\": self.battery_level\n            }\n        }\n    \n    def get_recent_analysis_results(self, limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"Get recent image analysis results\"\"\"\n        return self.analysis_results[-limit:] if self.analysis_results else []\n    \n    def simulate_sensor_failure_detection(self) -> Dict[str, Any]:\n        \"\"\"Simulate detection when sensors fail and drone takes over\"\"\"\n        # Start emergency mission when sensors are down\n        mission_result = self.start_flight_mission(\"emergency\")\n        \n        if mission_result[\"success\"]:\n            # Perform emergency image captures\n            emergency_results = []\n            for i, point in enumerate(self.flight_path[:3]):  # Quick scan of 3 points\n                capture_result = self.capture_and_analyze_image(point)\n                if capture_result[\"success\"]:\n                    emergency_results.append(capture_result[\"result\"])\n            \n            return {\n                \"success\": True,\n                \"message\": \"Drone emergency scan completed\",\n                \"emergency_results\": emergency_results,\n                \"high_risk_detected\": any(r[\"analysis\"][\"risk_level\"] in [\"high\", \"critical\"] \n                                        for r in emergency_results)\n            }\n        \n        return mission_result","size_bytes":17441},"dashboard/drone_dashboard.py":{"content":"\"\"\"\nDrone Monitoring Dashboard\nReal-time monitoring interface for drone operations and image analysis\n\"\"\"\n\nimport streamlit as st\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Any\nimport json\n\nfrom communication.drone_integration import DroneIntegration\nfrom communication.drone_system import DroneSystem\nimport math\n\nclass DroneDashboard:\n    \"\"\"Dashboard for drone monitoring and control\"\"\"\n    \n    def __init__(self):\n        if 'drone_integration' not in st.session_state:\n            st.session_state.drone_integration = DroneIntegration()\n        \n        self.drone_integration = st.session_state.drone_integration\n        self.drone_system = self.drone_integration.drone_system\n    \n    def render_drone_monitoring_page(self):\n        \"\"\"Render the main parallel monitoring page\"\"\"\n        st.title(\"üöÅ Parallel Monitoring System\")\n        st.markdown(\"*Real-time predictions from both sensors and drone surveillance*\")\n        \n        # Parallel monitoring controls\n        col1, col2, col3 = st.columns([2, 1, 1])\n        \n        with col1:\n            if st.button(\"üöÄ Start Parallel Monitoring\", type=\"primary\"):\n                result = self.drone_integration.start_parallel_monitoring()\n                if result.get(\"success\"):\n                    st.success(\"‚úÖ Parallel monitoring activated!\")\n                    st.rerun()\n                else:\n                    st.error(f\"‚ùå Failed to start: {result.get('message')}\")\n        \n        with col2:\n            if st.button(\"üîÑ Refresh Data\"):\n                st.rerun()\n        \n        with col3:\n            if st.button(\"‚ö†Ô∏è Emergency Scan\"):\n                result = self.drone_integration.check_sensor_status_and_activate_backup()\n                if result.get(\"success\"):\n                    st.success(\"Emergency scan initiated!\")\n                    st.rerun()\n        \n        st.divider()\n        \n        # Get parallel predictions\n        try:\n            predictions = self.drone_integration.get_parallel_predictions()\n            \n            if predictions.get(\"success\") == False:\n                st.error(f\"Error getting predictions: {predictions.get('message')}\")\n                return\n            \n            # Display parallel predictions\n            self._render_parallel_predictions(predictions)\n            \n            st.divider()\n            \n            # System status overview\n            self._render_system_status(predictions.get(\"monitoring_status\", {}))\n            \n            st.divider()\n            \n            # Tabs for detailed views\n            tabs = st.tabs([\"üìä Analysis Details\", \"üó∫Ô∏è Flight Map\", \"‚ö†Ô∏è Alerts\", \"üîß Advanced Controls\"])\n            \n            with tabs[0]:\n                self._render_detailed_analysis(predictions)\n                \n            with tabs[1]:\n                drone_status = self.drone_system.get_drone_status()\n                self._render_flight_map(drone_status)\n                \n            with tabs[2]:\n                self._render_drone_alerts()\n                \n            with tabs[3]:\n                self._render_advanced_controls()\n                \n        except Exception as e:\n            st.error(f\"Error loading parallel monitoring dashboard: {str(e)}\")\n            st.info(\"Falling back to basic monitoring mode...\")\n            self._render_fallback_dashboard()\n    \n    def _render_status_overview(self, drone_status: Dict[str, Any], full_status: Dict[str, Any]):\n        \"\"\"Render drone status overview\"\"\"\n        col1, col2, col3, col4, col5 = st.columns(5)\n        \n        # Flight status\n        with col1:\n            flight_status = drone_status.get(\"flight_status\", \"unknown\")\n            status_icon = {\n                \"grounded\": \"üü¢\",\n                \"flying\": \"üîµ\", \n                \"hovering\": \"üü°\",\n                \"returning\": \"üü†\",\n                \"emergency\": \"üî¥\"\n            }.get(flight_status, \"‚ö™\")\n            \n            st.metric(\"Flight Status\", f\"{status_icon} {flight_status.title()}\")\n        \n        # Battery level\n        with col2:\n            battery = drone_status.get(\"battery_level\", 0)\n            battery_color = \"üî¥\" if battery < 30 else \"üü°\" if battery < 60 else \"üü¢\"\n            st.metric(\"Battery Level\", f\"{battery_color} {battery:.1f}%\")\n        \n        # Backup mode status\n        with col3:\n            backup_mode = full_status.get(\"backup_mode_active\", False)\n            backup_icon = \"üö®\" if backup_mode else \"‚úÖ\"\n            backup_text = \"Active\" if backup_mode else \"Standby\"\n            st.metric(\"Backup Mode\", f\"{backup_icon} {backup_text}\")\n        \n        # Images captured today\n        with col4:\n            daily_stats = full_status.get(\"daily_stats\", {})\n            images_today = daily_stats.get(\"images_captured_today\", 0)\n            st.metric(\"Images Today\", f\"üì∏ {images_today}\")\n        \n        # Active alerts\n        with col5:\n            active_alerts = daily_stats.get(\"active_alerts\", 0)\n            alert_icon = \"üö®\" if active_alerts > 0 else \"‚úÖ\"\n            st.metric(\"Active Alerts\", f\"{alert_icon} {active_alerts}\")\n    \n    def _render_mission_control(self):\n        \"\"\"Render mission control panel\"\"\"\n        st.subheader(\"Mission Control\")\n        \n        drone_status = self.drone_system.get_drone_status()\n        is_active = drone_status.get(\"is_active\", False)\n        \n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            if st.button(\"üöÅ Start Patrol\", disabled=is_active, use_container_width=True):\n                with st.spinner(\"Starting patrol mission...\"):\n                    result = self.drone_integration.start_routine_patrol()\n                    if result[\"success\"]:\n                        st.success(\"Patrol mission started successfully!\")\n                        st.rerun()\n                    else:\n                        st.error(f\"Failed to start patrol: {result['message']}\")\n        \n        with col2:\n            if st.button(\"üÜò Emergency Scan\", use_container_width=True):\n                with st.spinner(\"Initiating emergency scan...\"):\n                    result = self.drone_integration.check_sensor_status_and_activate_backup()\n                    if result[\"success\"]:\n                        st.success(\"Emergency scan initiated!\")\n                        st.rerun()\n                    else:\n                        st.error(f\"Emergency scan failed: {result['message']}\")\n        \n        with col3:\n            if st.button(\"üè† Return to Base\", disabled=not is_active, use_container_width=True):\n                with st.spinner(\"Returning drone to base...\"):\n                    result = self.drone_system.land_drone()\n                    if result[\"success\"]:\n                        st.success(\"Drone returned to base successfully!\")\n                        st.rerun()\n                    else:\n                        st.error(f\"Return failed: {result['message']}\")\n        \n        # Mission settings\n        with st.expander(\"Mission Settings\"):\n            st.selectbox(\"Mission Type\", [\"patrol\", \"emergency\", \"inspection\"], index=0)\n            st.slider(\"Flight Altitude (m)\", 50, 200, 100)\n            st.slider(\"Image Capture Interval (s)\", 5, 60, 15)\n            st.checkbox(\"Auto-return on low battery\", value=True)\n    \n    def _render_quick_stats(self, status: Dict[str, Any]):\n        \"\"\"Render quick statistics panel\"\"\"\n        st.subheader(\"Quick Stats\")\n        \n        daily_stats = status.get(\"daily_stats\", {})\n        \n        # Today's flights\n        st.metric(\"Flights Today\", daily_stats.get(\"flights_today\", 0))\n        \n        # Last sensor check\n        last_check = status.get(\"last_sensor_check\")\n        if last_check:\n            check_time = datetime.fromisoformat(last_check)\n            minutes_ago = int((datetime.now() - check_time).total_seconds() / 60)\n            st.metric(\"Last Sensor Check\", f\"{minutes_ago} min ago\")\n        \n        # System health\n        drone_status = status.get(\"drone_status\", {})\n        gps_signal = drone_status.get(\"gps_signal\", \"unknown\")\n        comm_link = drone_status.get(\"communication_link\", \"unknown\")\n        \n        health_status = \"üü¢ Good\" if gps_signal == \"strong\" and comm_link == \"stable\" else \"üü° Fair\"\n        st.metric(\"System Health\", health_status)\n    \n    def _render_recent_images(self, recent_analyses: List[Dict[str, Any]]):\n        \"\"\"Render recent captured images\"\"\"\n        st.subheader(\"Recent Captured Images\")\n        \n        if not recent_analyses:\n            st.info(\"No recent images captured. Start a patrol mission to begin image capture.\")\n            return\n        \n        # Display recent images in a grid\n        cols = st.columns(3)\n        \n        for i, analysis in enumerate(recent_analyses[:6]):  # Show last 6 images\n            with cols[i % 3]:\n                # Image info card\n                timestamp = analysis.get(\"timestamp\", \"\")\n                risk_level = analysis.get(\"analysis\", {}).get(\"risk_level\", \"unknown\")\n                risk_score = analysis.get(\"analysis\", {}).get(\"risk_score\", 0)\n                \n                risk_color = {\n                    \"low\": \"üü¢\",\n                    \"medium\": \"üü°\", \n                    \"high\": \"üü†\",\n                    \"critical\": \"üî¥\"\n                }.get(risk_level, \"‚ö™\")\n                \n                # Create image placeholder (since we're using synthetic images)\n                st.markdown(f\"\"\"\n                <div style=\"border: 2px solid #ddd; padding: 10px; margin: 5px; border-radius: 10px;\">\n                    <div style=\"background: #f0f0f0; height: 150px; display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n                        üì∏ Drone Image\n                    </div>\n                    <strong>Risk Level:</strong> {risk_color} {risk_level.title()}<br>\n                    <strong>Score:</strong> {risk_score:.1f}/100<br>\n                    <strong>Time:</strong> {timestamp[:19] if timestamp else 'Unknown'}\n                </div>\n                \"\"\", unsafe_allow_html=True)\n    \n    def _render_analysis_results(self, recent_analyses: List[Dict[str, Any]]):\n        \"\"\"Render detailed analysis results\"\"\"\n        st.subheader(\"Image Analysis Results\")\n        \n        if not recent_analyses:\n            st.info(\"No analysis results available.\")\n            return\n        \n        # Create DataFrame for analysis results\n        analysis_data = []\n        for analysis in recent_analyses:\n            analysis_info = analysis.get(\"analysis\", {})\n            analysis_data.append({\n                \"Timestamp\": analysis.get(\"timestamp\", \"\")[:19],\n                \"Risk Level\": analysis_info.get(\"risk_level\", \"unknown\").title(),\n                \"Risk Score\": analysis_info.get(\"risk_score\", 0),\n                \"Confidence\": f\"{analysis_info.get('confidence', 0):.1%}\",\n                \"Features\": \", \".join(analysis_info.get(\"features_detected\", [])),\n                \"Location\": f\"({analysis.get('location', {}).get('lat', 0):.4f}, {analysis.get('location', {}).get('lon', 0):.4f})\"\n            })\n        \n        if analysis_data:\n            df = pd.DataFrame(analysis_data)\n            st.dataframe(df, use_container_width=True)\n            \n            # Risk score trend chart\n            if len(analysis_data) > 1:\n                fig = px.line(df, x=\"Timestamp\", y=\"Risk Score\", \n                             title=\"Risk Score Trend Over Time\",\n                             markers=True)\n                fig.update_layout(height=300)\n                st.plotly_chart(fig, use_container_width=True)\n    \n    def _render_flight_map(self, drone_status: Dict[str, Any]):\n        \"\"\"Render enhanced flight path map with accurate zones\"\"\"\n        st.subheader(\"Flight Path & Mine Zone Monitoring\")\n        \n        # Get current position over mine terrain\n        current_pos = drone_status.get(\"current_position\", {})\n        lat = current_pos.get(\"lat\", 40.5232)  # Bingham Canyon Mine area\n        lon = current_pos.get(\"lon\", -112.1500)\n        altitude = current_pos.get(\"altitude\", 150)\n        \n        # Define mine zones with realistic boundaries\n        mine_zones = {\n            \"North Pit\": {\n                \"coords\": [[40.5270, -112.1520], [40.5270, -112.1480], [40.5250, -112.1480], [40.5250, -112.1520]],\n                \"risk_level\": \"high\",\n                \"color\": \"rgba(255, 100, 100, 0.3)\",\n                \"border_color\": \"red\",\n                \"description\": \"Active mining area - High rockfall risk\"\n            },\n            \"South Pit\": {\n                \"coords\": [[40.5230, -112.1520], [40.5230, -112.1480], [40.5210, -112.1480], [40.5210, -112.1520]],\n                \"risk_level\": \"medium\", \n                \"color\": \"rgba(255, 165, 0, 0.3)\",\n                \"border_color\": \"orange\",\n                \"description\": \"Secondary mining area - Medium risk\"\n            },\n            \"East Bench\": {\n                \"coords\": [[40.5250, -112.1480], [40.5250, -112.1460], [40.5220, -112.1460], [40.5220, -112.1480]],\n                \"risk_level\": \"low\",\n                \"color\": \"rgba(255, 255, 0, 0.3)\",\n                \"border_color\": \"yellow\",\n                \"description\": \"Stable area - Regular monitoring\"\n            },\n            \"West Slope\": {\n                \"coords\": [[40.5250, -112.1540], [40.5250, -112.1520], [40.5220, -112.1520], [40.5220, -112.1540]],\n                \"risk_level\": \"critical\",\n                \"color\": \"rgba(139, 0, 0, 0.4)\",\n                \"border_color\": \"darkred\",\n                \"description\": \"Unstable slope - Critical monitoring required\"\n            },\n            \"Central Monitoring\": {\n                \"coords\": [[40.5240, -112.1510], [40.5240, -112.1490], [40.5220, -112.1490], [40.5220, -112.1510]],\n                \"risk_level\": \"safe\",\n                \"color\": \"rgba(0, 255, 0, 0.3)\",\n                \"border_color\": \"green\",\n                \"description\": \"Safe zone - Equipment staging area\"\n            }\n        }\n        \n        # Determine which zone the drone is currently in\n        current_zone = self._detect_drone_zone(lat, lon, mine_zones)\n        \n        # Create enhanced map visualization\n        fig = go.Figure()\n        \n        # Add mine zone boundaries\n        for zone_name, zone_data in mine_zones.items():\n            zone_coords = zone_data[\"coords\"]\n            zone_lats = [coord[0] for coord in zone_coords] + [zone_coords[0][0]]  # Close the polygon\n            zone_lons = [coord[1] for coord in zone_coords] + [zone_coords[0][1]]\n            \n            # Add zone boundary\n            fig.add_trace(go.Scattermapbox(\n                lat=zone_lats,\n                lon=zone_lons,\n                mode=\"lines\",\n                line=dict(width=3, color=zone_data[\"border_color\"]),\n                fill=\"toself\",\n                fillcolor=zone_data[\"color\"],\n                name=f\"{zone_name} ({zone_data['risk_level'].title()})\",\n                text=zone_data[\"description\"],\n                hovertemplate=f\"<b>{zone_name}</b><br>Risk Level: {zone_data['risk_level'].title()}<br>{zone_data['description']}<extra></extra>\"\n            ))\n        \n        # Add current drone position with enhanced styling\n        drone_icon_color = \"lime\" if current_zone and mine_zones[current_zone][\"risk_level\"] == \"safe\" else \"red\"\n        fig.add_trace(go.Scattermapbox(\n            lat=[lat],\n            lon=[lon],\n            mode=\"markers\",\n            marker=dict(\n                size=20,\n                color=drone_icon_color,\n                symbol=\"circle\",\n                allowoverlap=True\n            ),\n            text=f\"üöÅ Drone - {current_zone if current_zone else 'Unknown Zone'}\",\n            name=\"Current Drone Position\",\n            hovertemplate=f\"<b>Drone Position</b><br>Zone: {current_zone or 'Unknown'}<br>Lat: {lat:.6f}<br>Lon: {lon:.6f}<br>Alt: {altitude}m<extra></extra>\"\n        ))\n        \n        # Add flight path with waypoint markers\n        if hasattr(self.drone_system, 'flight_path') and self.drone_system.flight_path:\n            path_lats = [point.get(\"lat\", 0) for point in self.drone_system.flight_path]\n            path_lons = [point.get(\"lon\", 0) for point in self.drone_system.flight_path]\n            \n            # Flight path line\n            fig.add_trace(go.Scattermapbox(\n                lat=path_lats,\n                lon=path_lons,\n                mode=\"lines\",\n                line=dict(width=3, color=\"blue\", dash=\"dash\"),\n                name=\"Planned Flight Path\",\n                hovertemplate=\"Planned Route<extra></extra>\"\n            ))\n            \n            # Waypoint markers\n            fig.add_trace(go.Scattermapbox(\n                lat=path_lats,\n                lon=path_lons,\n                mode=\"markers\",\n                marker=dict(size=10, color=\"blue\", symbol=\"circle-open\"),\n                name=\"Waypoints\",\n                text=[f\"Waypoint {i+1}\" for i in range(len(path_lats))],\n                hovertemplate=\"<b>%{text}</b><br>Lat: %{lat:.6f}<br>Lon: %{lon:.6f}<extra></extra>\"\n            ))\n        \n        # Enhanced map layout\n        fig.update_layout(\n            mapbox=dict(\n                style=\"open-street-map\",  # Free map style that doesn't require access token\n                center=dict(lat=lat, lon=lon),\n                zoom=17  # Closer zoom for detailed zone view\n            ),\n            height=600,\n            margin=dict(l=0, r=0, t=30, b=0),\n            title=dict(\n                text=f\"Mine Zone Map - Drone Currently in: {current_zone or 'Unknown Zone'}\",\n                x=0.5,\n                xanchor=\"center\"\n            ),\n            showlegend=True,\n            legend=dict(\n                yanchor=\"top\",\n                y=0.99,\n                xanchor=\"left\", \n                x=0.01,\n                bgcolor=\"rgba(255,255,255,0.8)\",\n                bordercolor=\"rgba(0,0,0,0.2)\",\n                borderwidth=1\n            )\n        )\n        \n        st.plotly_chart(fig, use_container_width=True)\n        \n        # Enhanced position and zone information\n        col1, col2, col3, col4 = st.columns(4)\n        \n        with col1:\n            st.metric(\"Current Zone\", current_zone or \"Unknown\")\n            \n        with col2:\n            if current_zone:\n                risk_level = mine_zones[current_zone][\"risk_level\"]\n                risk_colors = {\"safe\": \"üü¢\", \"low\": \"üü°\", \"medium\": \"üü†\", \"high\": \"üî¥\", \"critical\": \"üö®\"}\n                st.metric(\"Zone Risk\", f\"{risk_colors.get(risk_level, '‚ö™')} {risk_level.title()}\")\n            else:\n                st.metric(\"Zone Risk\", \"Unknown\")\n                \n        with col3:\n            st.metric(\"Coordinates\", f\"{lat:.4f}, {lon:.4f}\")\n            \n        with col4:\n            st.metric(\"Altitude AGL\", f\"{altitude} m\")\n        \n        # Zone details and recommendations\n        if current_zone:\n            zone_info = mine_zones[current_zone]\n            risk_level = zone_info[\"risk_level\"]\n            \n            if risk_level in [\"critical\", \"high\"]:\n                st.error(f\"‚ö†Ô∏è **HIGH RISK ZONE**: {zone_info['description']}\")\n                st.write(\"**Recommendations:** Maintain higher altitude, increase monitoring frequency, be ready for immediate evacuation.\")\n            elif risk_level == \"medium\":\n                st.warning(f\"üü° **MEDIUM RISK ZONE**: {zone_info['description']}\")\n                st.write(\"**Recommendations:** Standard monitoring protocols, maintain safe distance from unstable areas.\")\n            elif risk_level == \"low\":\n                st.info(f\"üü° **LOW RISK ZONE**: {zone_info['description']}\")\n                st.write(\"**Recommendations:** Normal operations, routine monitoring sufficient.\")\n            else:\n                st.success(f\"‚úÖ **SAFE ZONE**: {zone_info['description']}\")\n                st.write(\"**Recommendations:** Safe for extended operations and close inspection.\")\n        else:\n            st.warning(\"‚ö†Ô∏è Drone position outside defined monitoring zones. Proceed with caution.\")\n        \n        # Zone statistics\n        with st.expander(\"üìä Zone Coverage Statistics\"):\n            total_zones = len(mine_zones)\n            risk_distribution = {}\n            for zone in mine_zones.values():\n                risk = zone[\"risk_level\"]\n                risk_distribution[risk] = risk_distribution.get(risk, 0) + 1\n                \n            st.write(f\"**Total Monitoring Zones:** {total_zones}\")\n            for risk, count in risk_distribution.items():\n                percentage = (count / total_zones) * 100\n                st.write(f\"**{risk.title()} Risk Zones:** {count} ({percentage:.1f}%)\")\n    \n    def _detect_drone_zone(self, lat: float, lon: float, mine_zones: dict) -> str:\n        \"\"\"Detect which zone the drone is currently in using point-in-polygon algorithm\"\"\"\n        for zone_name, zone_data in mine_zones.items():\n            if self._point_in_polygon(lat, lon, zone_data[\"coords\"]):\n                return zone_name\n        return None\n    \n    def _point_in_polygon(self, lat: float, lon: float, polygon_coords: list) -> bool:\n        \"\"\"Check if a point is inside a polygon using ray casting algorithm\"\"\"\n        x, y = lat, lon\n        n = len(polygon_coords)\n        inside = False\n        \n        p1x, p1y = polygon_coords[0]\n        for i in range(1, n + 1):\n            p2x, p2y = polygon_coords[i % n]\n            if y > min(p1y, p2y):\n                if y <= max(p1y, p2y):\n                    if x <= max(p1x, p2x):\n                        if p1y != p2y:\n                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\n                        if p1x == p2x or x <= xinters:\n                            inside = not inside\n            p1x, p1y = p2x, p2y\n        \n        return inside\n    \n    def _render_drone_alerts(self):\n        \"\"\"Render drone-specific alerts\"\"\"\n        st.subheader(\"Drone Alerts & Notifications\")\n        \n        # This would query the database for drone alerts\n        st.info(\"Drone alert system integrated with main alert management.\")\n        \n        # Sample alert display\n        sample_alerts = [\n            {\n                \"timestamp\": \"2024-01-15 14:30:00\",\n                \"risk_level\": \"high\",\n                \"message\": \"High rockfall risk detected in Sector C\",\n                \"location\": \"Lat: 39.7400, Lon: -104.9910\",\n                \"status\": \"active\"\n            }\n        ]\n        \n        for alert in sample_alerts:\n            risk_color = {\"high\": \"üî¥\", \"medium\": \"üü°\", \"low\": \"üü¢\"}.get(alert[\"risk_level\"], \"‚ö™\")\n            \n            with st.container():\n                st.markdown(f\"\"\"\n                <div style=\"border-left: 4px solid #ff4444; padding: 10px; margin: 5px 0; background: #fff5f5;\">\n                    <strong>{risk_color} {alert[\"risk_level\"].upper()} RISK ALERT</strong><br>\n                    <strong>Time:</strong> {alert[\"timestamp\"]}<br>\n                    <strong>Location:</strong> {alert[\"location\"]}<br>\n                    <strong>Message:</strong> {alert[\"message\"]}<br>\n                    <strong>Status:</strong> {alert[\"status\"].title()}\n                </div>\n                \"\"\", unsafe_allow_html=True)\n    \n    def _render_performance_metrics(self, status: Dict[str, Any]):\n        \"\"\"Render drone performance metrics\"\"\"\n        st.subheader(\"Performance Metrics\")\n        \n        daily_stats = status.get(\"daily_stats\", {})\n        \n        # Performance overview\n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.metric(\"Flight Reliability\", \"94.2%\")\n            st.metric(\"Image Quality Score\", \"4.7/5.0\")\n            st.metric(\"Detection Accuracy\", \"89.3%\")\n        \n        with col2:\n            st.metric(\"Average Flight Time\", \"28 min\")\n            st.metric(\"Images per Flight\", \"15.6\")\n            st.metric(\"Alert Response Time\", \"< 2 min\")\n        \n        # Performance charts\n        if st.checkbox(\"Show Detailed Performance Charts\"):\n            # Sample performance data\n            dates = pd.date_range(start=\"2024-01-01\", end=\"2024-01-15\", freq=\"D\")\n            performance_data = {\n                \"Date\": dates,\n                \"Flight Success Rate\": [90 + i*0.5 for i in range(len(dates))],\n                \"Images Captured\": [10 + (i % 5) * 3 for i in range(len(dates))],\n                \"Risk Detections\": [2 + (i % 3) for i in range(len(dates))]\n            }\n            \n            df = pd.DataFrame(performance_data)\n            \n            # Flight success rate chart\n            fig1 = px.line(df, x=\"Date\", y=\"Flight Success Rate\", \n                          title=\"Flight Success Rate Over Time\")\n            st.plotly_chart(fig1, use_container_width=True)\n            \n            # Daily activity chart\n            fig2 = px.bar(df, x=\"Date\", y=[\"Images Captured\", \"Risk Detections\"],\n                         title=\"Daily Drone Activity\", barmode=\"group\")\n            st.plotly_chart(fig2, use_container_width=True)\n    \n    def render_sensor_backup_status(self):\n        \"\"\"Render sensor backup status component for main dashboard\"\"\"\n        try:\n            # Check sensor status and backup mode\n            backup_status = self.drone_integration.check_sensor_status_and_activate_backup()\n            \n            if backup_status.get(\"backup_mode\", False):\n                st.warning(\"üö® **SENSOR BACKUP MODE ACTIVE** - Drone monitoring is currently providing coverage for failed sensors.\")\n                \n                col1, col2 = st.columns(2)\n                with col1:\n                    st.metric(\"Failed Sensors\", backup_status.get(\"failed_sensors\", 0))\n                with col2:\n                    if st.button(\"View Drone Dashboard\"):\n                        st.session_state.page = \"Drone Monitoring\"\n                        st.rerun()\n            else:\n                # Normal operation - show compact status\n                drone_status = self.drone_system.get_drone_status()\n                if drone_status.get(\"is_active\", False):\n                    st.info(f\"üöÅ Drone active: {drone_status.get('flight_status', 'unknown')} - Battery: {drone_status.get('battery_level', 0):.1f}%\")\n                \n        except Exception as e:\n            st.error(f\"Error checking drone backup status: {str(e)}\")\n\n    def get_drone_status_for_main_dashboard(self) -> Dict[str, Any]:\n        \"\"\"Get drone status data for integration with main dashboard\"\"\"\n        try:\n            status = self.drone_integration.get_drone_monitoring_status()\n            drone_status = status.get(\"drone_status\", {})\n            \n            return {\n                \"is_active\": drone_status.get(\"is_active\", False),\n                \"flight_status\": drone_status.get(\"flight_status\", \"grounded\"),\n                \"battery_level\": drone_status.get(\"battery_level\", 0),\n                \"backup_mode_active\": status.get(\"backup_mode_active\", False),\n                \"images_captured_today\": status.get(\"daily_stats\", {}).get(\"images_captured_today\", 0),\n                \"active_alerts\": status.get(\"daily_stats\", {}).get(\"active_alerts\", 0)\n            }\n        except Exception:\n            return {\n                \"is_active\": False,\n                \"flight_status\": \"error\",\n                \"battery_level\": 0,\n                \"backup_mode_active\": False,\n                \"images_captured_today\": 0,\n                \"active_alerts\": 0\n            }\n    \n    def _render_parallel_predictions(self, predictions: Dict[str, Any]):\n        \"\"\"Render parallel predictions from sensors and drone\"\"\"\n        st.subheader(\"üéØ Real-Time Risk Assessment\")\n        \n        sensor_pred = predictions.get(\"sensor_prediction\", {})\n        drone_pred = predictions.get(\"drone_prediction\", {})\n        combined_pred = predictions.get(\"combined_prediction\", {})\n        \n        # Main combined prediction display\n        col1, col2, col3 = st.columns([2, 1, 1])\n        \n        with col1:\n            risk_level = combined_pred.get(\"risk_level\", \"unknown\")\n            risk_score = combined_pred.get(\"risk_score\", 0.0)\n            \n            # Color based on risk level\n            risk_colors = {\n                \"low\": \"green\",\n                \"medium\": \"orange\", \n                \"high\": \"red\",\n                \"critical\": \"red\"\n            }\n            color = risk_colors.get(risk_level, \"gray\")\n            \n            st.markdown(f\"\"\"\n            ### Combined Risk Assessment\n            **Risk Level:** :{color}[{risk_level.upper()}]  \n            **Risk Score:** {risk_score:.2f}  \n            **Confidence:** {combined_pred.get('confidence', 0):.1%}  \n            **Agreement:** {combined_pred.get('agreement', 0):.1%}\n            \"\"\")\n        \n        with col2:\n            st.metric(\n                \"Sensor Weight\",\n                f\"{combined_pred.get('sensor_weight', 0):.1%}\",\n                help=\"How much the sensor data influences the final prediction\"\n            )\n        \n        with col3:\n            st.metric(\n                \"Drone Weight\", \n                f\"{combined_pred.get('drone_weight', 0):.1%}\",\n                help=\"How much the drone analysis influences the final prediction\"\n            )\n        \n        # Detailed predictions side by side\n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.markdown(\"#### üì° Sensor Prediction\")\n            if sensor_pred.get(\"error\"):\n                st.error(f\"Sensor Error: {sensor_pred['error']}\")\n            else:\n                sensor_risk = sensor_pred.get(\"risk_level\", \"unknown\")\n                sensor_color = risk_colors.get(sensor_risk, \"gray\")\n                \n                st.markdown(f\"\"\"\n                **Risk Level:** :{sensor_color}[{sensor_risk.upper()}]  \n                **Risk Score:** {sensor_pred.get('risk_score', 0):.2f}  \n                **Confidence:** {sensor_pred.get('confidence', 0):.1%}  \n                **Active Sensors:** {sensor_pred.get('sensor_count', 0)}  \n                **Last Update:** {sensor_pred.get('timestamp', 'Unknown')[-8:]}\n                \"\"\")\n        \n        with col2:\n            st.markdown(\"#### üöÅ Drone Analysis\")\n            if drone_pred.get(\"error\"):\n                st.error(f\"Drone Error: {drone_pred['error']}\")\n            else:\n                drone_risk = drone_pred.get(\"risk_level\", \"unknown\")\n                drone_color = risk_colors.get(drone_risk, \"gray\")\n                \n                st.markdown(f\"\"\"\n                **Risk Level:** :{drone_color}[{drone_risk.upper()}]  \n                **Risk Score:** {drone_pred.get('risk_score', 0):.2f}  \n                **Confidence:** {drone_pred.get('confidence', 0):.1%}  \n                **Data Source:** {drone_pred.get('data_source', 'Unknown')}  \n                **Last Analysis:** {drone_pred.get('last_analysis', 'Never')[-8:] if drone_pred.get('last_analysis') else 'Never'}\n                \"\"\")\n        \n        # Risk trend visualization\n        if st.checkbox(\"üìä Show Risk Trend Simulation\"):\n            self._render_risk_trend_chart(sensor_pred, drone_pred, combined_pred)\n    \n    def _render_system_status(self, monitoring_status: Dict[str, Any]):\n        \"\"\"Render system monitoring status\"\"\"\n        st.subheader(\"üîç System Status\")\n        \n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            sensors_active = monitoring_status.get(\"sensors_active\", False)\n            status_icon = \"üü¢\" if sensors_active else \"üî¥\"\n            st.metric(\"Sensor Network\", f\"{status_icon} {'Active' if sensors_active else 'Inactive'}\")\n        \n        with col2:\n            drone_active = monitoring_status.get(\"drone_active\", False)\n            status_icon = \"üü¢\" if drone_active else \"üî¥\"\n            st.metric(\"Drone System\", f\"{status_icon} {'Active' if drone_active else 'Inactive'}\")\n        \n        with col3:\n            parallel_mode = monitoring_status.get(\"parallel_mode\", False)\n            status_icon = \"üü¢\" if parallel_mode else \"üü°\"\n            st.metric(\"Parallel Mode\", f\"{status_icon} {'Running' if parallel_mode else 'Standby'}\")\n    \n    def _render_risk_trend_chart(self, sensor_pred: Dict, drone_pred: Dict, combined_pred: Dict):\n        \"\"\"Render simulated risk trend chart\"\"\"\n        import random\n        \n        # Generate simulated trend data\n        timestamps = [datetime.now() - timedelta(minutes=x) for x in range(30, 0, -1)]\n        \n        sensor_trend = [max(0, min(1, sensor_pred.get(\"risk_score\", 0.3) + random.uniform(-0.2, 0.2))) for _ in timestamps]\n        drone_trend = [max(0, min(1, drone_pred.get(\"risk_score\", 0.3) + random.uniform(-0.2, 0.2))) for _ in timestamps]\n        combined_trend = [(s + d) / 2 for s, d in zip(sensor_trend, drone_trend)]\n        \n        fig = go.Figure()\n        \n        fig.add_trace(go.Scatter(\n            x=timestamps,\n            y=sensor_trend,\n            name=\"Sensor Risk\",\n            line=dict(color=\"blue\", width=2)\n        ))\n        \n        fig.add_trace(go.Scatter(\n            x=timestamps,\n            y=drone_trend,\n            name=\"Drone Risk\", \n            line=dict(color=\"orange\", width=2)\n        ))\n        \n        fig.add_trace(go.Scatter(\n            x=timestamps,\n            y=combined_trend,\n            name=\"Combined Risk\",\n            line=dict(color=\"red\", width=3)\n        ))\n        \n        fig.update_layout(\n            title=\"Risk Level Trends (Last 30 Minutes)\",\n            xaxis_title=\"Time\",\n            yaxis_title=\"Risk Score\",\n            yaxis=dict(range=[0, 1]),\n            height=400\n        )\n        \n        st.plotly_chart(fig, use_container_width=True)\n    \n    def _render_detailed_analysis(self, predictions: Dict[str, Any]):\n        \"\"\"Render detailed analysis information\"\"\"\n        st.subheader(\"üìä Detailed Analysis\")\n        \n        sensor_pred = predictions.get(\"sensor_prediction\", {})\n        drone_pred = predictions.get(\"drone_prediction\", {})\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            st.markdown(\"#### Sensor Data Analysis\")\n            if not sensor_pred.get(\"error\"):\n                st.json({\n                    \"risk_level\": sensor_pred.get(\"risk_level\"),\n                    \"risk_score\": sensor_pred.get(\"risk_score\"),\n                    \"confidence\": sensor_pred.get(\"confidence\"),\n                    \"sensor_count\": sensor_pred.get(\"sensor_count\"),\n                    \"data_source\": sensor_pred.get(\"data_source\")\n                })\n            else:\n                st.error(sensor_pred.get(\"error\"))\n        \n        with col2:\n            st.markdown(\"#### Drone Analysis\")\n            if not drone_pred.get(\"error\"):\n                st.json({\n                    \"risk_level\": drone_pred.get(\"risk_level\"),\n                    \"risk_score\": drone_pred.get(\"risk_score\"),\n                    \"confidence\": drone_pred.get(\"confidence\"),\n                    \"data_source\": drone_pred.get(\"data_source\"),\n                    \"last_analysis\": drone_pred.get(\"last_analysis\")\n                })\n            else:\n                st.error(drone_pred.get(\"error\"))\n    \n    def _render_advanced_controls(self):\n        \"\"\"Render advanced drone control interface\"\"\"\n        st.subheader(\"üîß Advanced Drone Controls\")\n        \n        # Get drone integration status  \n        try:\n            drone_status = self.drone_integration.get_drone_monitoring_status()\n            \n            # Status overview\n            col1, col2, col3, col4 = st.columns(4)\n            \n            with col1:\n                st.metric(\"Flight Status\", \"Active\" if drone_status.get(\"drone_status\", {}).get(\"is_active\") else \"Inactive\")\n            \n            with col2:\n                battery = drone_status.get(\"drone_status\", {}).get(\"battery_level\", 0)\n                st.metric(\"Battery Level\", f\"{battery}%\")\n            \n            with col3:\n                backup_mode = drone_status.get(\"backup_mode_active\", False)\n                st.metric(\"Backup Mode\", \"Active\" if backup_mode else \"Standby\")\n            \n            with col4:\n                last_check = drone_status.get(\"last_sensor_check\")\n                if last_check:\n                    last_check_str = datetime.fromisoformat(last_check).strftime(\"%H:%M:%S\")\n                else:\n                    last_check_str = \"Never\"\n                st.metric(\"Last Sensor Check\", last_check_str)\n                \n            # Mission controls\n            st.markdown(\"#### Mission Controls\")\n            col1, col2, col3 = st.columns(3)\n            \n            with col1:\n                if st.button(\"üöÅ Start Patrol\"):\n                    result = self.drone_integration.start_routine_patrol()\n                    if result[\"success\"]:\n                        st.success(\"Patrol started!\")\n                        st.rerun()\n            \n            with col2:\n                if st.button(\"üÜò Emergency Scan\"):\n                    result = self.drone_integration.check_sensor_status_and_activate_backup()\n                    if result[\"success\"]:\n                        st.success(\"Emergency scan initiated!\")\n                        st.rerun()\n            \n            with col3:\n                if st.button(\"üè† Return to Base\"):\n                    result = self.drone_system.land_drone()\n                    if result[\"success\"]:\n                        st.success(\"Returning to base!\")\n                        st.rerun()\n        \n        except Exception as e:\n            st.error(f\"Error loading advanced controls: {e}\")\n    \n    def _render_fallback_dashboard(self):\n        \"\"\"Render fallback dashboard when parallel monitoring fails\"\"\"\n        st.warning(\"‚ö†Ô∏è Parallel monitoring unavailable. Showing basic drone controls.\")\n        \n        # Basic drone status\n        try:\n            drone_status = self.drone_system.get_drone_status()\n            \n            col1, col2, col3 = st.columns(3)\n            with col1:\n                st.metric(\"Drone Status\", \"Active\" if drone_status.get(\"is_active\") else \"Inactive\")\n            with col2:\n                st.metric(\"Battery\", f\"{drone_status.get('battery_level', 0)}%\")\n            with col3:\n                st.metric(\"Flight Status\", drone_status.get(\"flight_status\", \"Unknown\"))\n            \n            # Basic controls\n            if st.button(\"üöÅ Activate Drone\"):\n                self.drone_system.is_active = True\n                st.success(\"Drone activated!\")\n                st.rerun()\n                \n        except Exception as e:\n            st.error(f\"Error in fallback mode: {e}\")","size_bytes":38801},".streamlit/config.toml":{"content":"[server]\nheadless = true\naddress = \"0.0.0.0\"\nport = 5000\n\n[theme]\nbase = \"light\"\nprimaryColor = \"#1e40af\"\nbackgroundColor = \"#ffffff\"\nsecondaryBackgroundColor = \"#f4f6f9\"\ntextColor = \"#1f2937\"\nfont = \"sans serif\"\n\n[browser]\ngatherUsageStats = false\nshowErrorDetails = false\n","size_bytes":274},"assets/style.css":{"content":"/* Professional Enterprise Dashboard Design */\n\n/* Hide Streamlit Default Chrome */\n#MainMenu {visibility: hidden;}\nfooter {visibility: hidden;}\nheader {visibility: hidden;}\n[data-testid=\"stHeader\"] {visibility: hidden;}\n[data-testid=\"stToolbar\"] {visibility: hidden;}\n[data-testid=\"stDecoration\"] {visibility: hidden;}\n\n/* Main App Container */\n.main .block-container {\n    padding: 0;\n    background: #f4f6f9;\n    max-width: 100%;\n    margin: 0;\n    min-height: 100vh;\n}\n\n/* Remove Streamlit padding and margins */\n.main > div {\n    padding: 0 !important;\n}\n\n/* Remove default Streamlit top padding */\n.main .block-container {\n    padding-top: 0 !important;\n}\n\n/* Professional Header */\n.professional-header {\n    background: linear-gradient(135deg, #475569 0%, #64748b 100%);\n    color: white;\n    padding: 1rem 2rem;\n    margin: 0;\n    box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n}\n\n/* Typography - Serif for headings, sans-serif for body */\n.main h1, .main h2, .main h3 {\n    color: #374151;\n    font-family: 'Georgia', 'Times New Roman', serif;\n    font-weight: 400;\n    margin-bottom: 1rem;\n}\n\n.main h1 {\n    text-align: center;\n    border-bottom: 2px solid #e9ecef;\n    padding-bottom: 1rem;\n    margin-bottom: 2rem;\n    font-size: 2.2rem;\n}\n\n.main h2 {\n    font-size: 1.5rem;\n    margin-top: 2rem;\n}\n\n.main h3 {\n    font-size: 1.2rem;\n    margin-top: 1.5rem;\n}\n\n/* Metric Cards - Simple and clean */\n[data-testid=\"metric-container\"] {\n    background: #ffffff;\n    border: 1px solid #e9ecef;\n    border-radius: 4px;\n    padding: 1.5rem;\n    margin: 0.5rem 0;\n}\n\n[data-testid=\"metric-container\"] > div:first-child {\n    font-weight: 500;\n    color: #495057;\n    font-size: 0.9rem;\n    text-transform: uppercase;\n    letter-spacing: 0.5px;\n    margin-bottom: 0.5rem;\n}\n\n[data-testid=\"metric-container\"] > div:nth-child(2) {\n    font-size: 1.8rem;\n    font-weight: 600;\n    color: #2c3e50;\n    margin-bottom: 0.25rem;\n}\n\n[data-testid=\"metric-container\"] > div:last-child {\n    color: #6c757d;\n    font-size: 0.85rem;\n}\n\n/* Professional Sidebar */\n.sidebar .sidebar-content {\n    background: #ffffff;\n    border-right: 2px solid #e2e8f0;\n    min-height: 100vh;\n}\n\n.sidebar .element-container h1, .sidebar .element-container h3 {\n    color: #374151;\n    font-family: 'Segoe UI', 'Roboto', sans-serif;\n    font-weight: 600;\n    margin-bottom: 1rem;\n}\n\n/* Professional Company Branding */\n.company-branding {\n    background: #64748b;\n    color: white;\n    padding: 1.5rem;\n    margin: -1rem -1rem 2rem -1rem;\n    text-align: center;\n}\n\n.company-logo {\n    font-size: 1.5rem;\n    font-weight: 700;\n    margin-bottom: 0.5rem;\n}\n\n.company-tagline {\n    font-size: 0.8rem;\n    opacity: 0.9;\n}\n\n/* Professional Navigation Buttons */\n.stButton > button {\n    width: 100%;\n    text-align: left;\n    margin-bottom: 0.3rem;\n    border-radius: 6px;\n    border: none;\n    font-weight: 500;\n    padding: 0.8rem 1.2rem;\n    transition: all 0.2s ease;\n    font-family: 'Segoe UI', sans-serif;\n}\n\n.stButton > button[kind=\"primary\"] {\n    background: linear-gradient(135deg, #475569 0%, #6b7280 100%);\n    color: white;\n    box-shadow: 0 2px 4px rgba(107, 114, 128, 0.3);\n}\n\n.stButton > button[kind=\"secondary\"] {\n    background: #f8fafc;\n    color: #475569;\n    border: 1px solid #e2e8f0;\n}\n\n.stButton > button[kind=\"secondary\"]:hover {\n    background: #f1f5f9;\n    border-color: #1e293b;\n    transform: translateY(-1px);\n    box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n}\n\n/* Professional Status Cards */\n.status-card {\n    background: white;\n    border-radius: 8px;\n    padding: 1.5rem;\n    box-shadow: 0 2px 10px rgba(0,0,0,0.08);\n    border-left: 4px solid #3b82f6;\n    margin-bottom: 1rem;\n}\n\n.status-value {\n    font-size: 1.8rem;\n    font-weight: 700;\n    color: #1e40af;\n    margin: 0.5rem 0;\n}\n\n.status-label {\n    color: #64748b;\n    font-size: 0.9rem;\n    font-weight: 500;\n    text-transform: uppercase;\n    letter-spacing: 0.5px;\n}\n\n/* Landing Page Styles */\n.landing-nav {\n    background: rgba(30, 41, 59, 0.95);\n    padding: 1rem 0;\n    position: fixed;\n    top: 0;\n    left: 0;\n    right: 0;\n    z-index: 1000;\n    backdrop-filter: blur(10px);\n}\n\n.nav-container {\n    max-width: 1200px;\n    margin: 0 auto;\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n    padding: 0 2rem;\n}\n\n.nav-brand {\n    color: white;\n    font-size: 1.5rem;\n    font-weight: 700;\n}\n\n.nav-logo {\n    color: white;\n    text-decoration: none;\n}\n\n.nav-menu {\n    display: flex;\n    gap: 2rem;\n}\n\n.nav-link {\n    color: white;\n    text-decoration: none;\n    font-weight: 500;\n    opacity: 0.9;\n    transition: opacity 0.3s ease;\n}\n\n.nav-link:hover {\n    opacity: 1;\n}\n\n.nav-actions {\n    display: flex;\n    gap: 1rem;\n}\n\n.nav-btn {\n    padding: 0.75rem 1.5rem;\n    border-radius: 6px;\n    font-weight: 600;\n    border: none;\n    cursor: pointer;\n    transition: all 0.3s ease;\n}\n\n.nav-btn.secondary {\n    background: transparent;\n    color: white;\n    border: 2px solid white;\n}\n\n.nav-btn.secondary:hover {\n    background: white;\n    color: #1e293b;\n}\n\n.nav-btn.primary {\n    background: white;\n    color: #1e293b;\n}\n\n.nav-btn.primary:hover {\n    background: #f1f5f9;\n    transform: translateY(-2px);\n}\n\n/* Hero Section */\n.hero-section {\n    height: 100vh;\n    background-size: cover;\n    background-position: center;\n    background-repeat: no-repeat;\n    position: relative;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    margin-top: 0;\n}\n\n.hero-overlay {\n    background: rgba(0, 0, 0, 0.3);\n    position: absolute;\n    top: 0;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n}\n\n.hero-content {\n    text-align: center;\n    color: white;\n    max-width: 800px;\n    padding: 2rem;\n}\n\n.hero-title {\n    font-size: 3.5rem;\n    font-weight: 700;\n    margin-bottom: 2rem;\n    line-height: 1.2;\n    text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n}\n\n.hero-subtitle {\n    font-size: 1.3rem;\n    margin-bottom: 3rem;\n    line-height: 1.6;\n    opacity: 0.95;\n    text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\n}\n\n.hero-buttons {\n    display: flex;\n    gap: 1.5rem;\n    justify-content: center;\n    flex-wrap: wrap;\n}\n\n.hero-btn {\n    padding: 1rem 2.5rem;\n    font-size: 1.1rem;\n    font-weight: 600;\n    border-radius: 8px;\n    border: none;\n    cursor: pointer;\n    transition: all 0.3s ease;\n}\n\n.hero-btn.primary {\n    background: #1e293b;\n    color: white;\n}\n\n.hero-btn.primary:hover {\n    background: #0f172a;\n    transform: translateY(-3px);\n    box-shadow: 0 10px 20px rgba(30, 41, 59, 0.3);\n}\n\n.hero-btn.secondary {\n    background: transparent;\n    color: white;\n    border: 2px solid white;\n}\n\n.hero-btn.secondary:hover {\n    background: white;\n    color: #1e293b;\n    transform: translateY(-3px);\n}\n\n/* Statistics Section */\n.stats-section {\n    background: rgba(30, 41, 59, 0.1);\n    padding: 4rem 2rem;\n    margin-top: -100px;\n    position: relative;\n    z-index: 100;\n}\n\n.stats-container {\n    max-width: 1200px;\n    margin: 0 auto;\n    display: flex;\n    justify-content: center;\n    gap: 3rem;\n    flex-wrap: wrap;\n}\n\n.stat-card {\n    background: rgba(255, 255, 255, 0.95);\n    padding: 2rem;\n    border-radius: 12px;\n    text-align: center;\n    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);\n    backdrop-filter: blur(10px);\n    min-width: 200px;\n    transition: transform 0.3s ease;\n}\n\n.stat-card:hover {\n    transform: translateY(-10px);\n}\n\n.stat-icon {\n    font-size: 2.5rem;\n    margin-bottom: 1rem;\n}\n\n.stat-number {\n    font-size: 2.5rem;\n    font-weight: 700;\n    color: #1e293b;\n    margin-bottom: 0.5rem;\n}\n\n.stat-label {\n    color: #64748b;\n    font-size: 1rem;\n    font-weight: 500;\n}\n\n/* Navigation */\n.stSelectbox label {\n    color: #495057;\n    font-weight: 500;\n    font-size: 0.95rem;\n}\n\n/* Buttons - Simple and professional */\n.stButton > button {\n    background: #6b7280;\n    color: white;\n    border: none;\n    border-radius: 4px;\n    padding: 0.5rem 1.5rem;\n    font-weight: 500;\n    font-size: 0.9rem;\n}\n\n.stButton > button:hover {\n    background: #7c8894;\n}\n\n/* Dividers */\nhr {\n    border: none;\n    height: 1px;\n    background: #dee2e6;\n    margin: 2rem 0;\n}\n\n/* Info boxes */\n.element-container .stAlert {\n    border-radius: 4px;\n    border-left: 4px solid #2c3e50;\n}\n\n/* Tables */\n.stDataFrame {\n    border: 1px solid #dee2e6;\n    border-radius: 4px;\n}\n\n/* Charts container */\n.js-plotly-plot {\n    border: 1px solid #e9ecef;\n    border-radius: 4px;\n    background: white;\n    margin: 1rem 0;\n}\n\n/* Progress bars */\n.stProgress > div > div {\n    background: #2c3e50;\n    height: 6px;\n    border-radius: 3px;\n}\n\n/* Tabs */\n.stTabs [data-baseweb=\"tab-list\"] {\n    gap: 4px;\n}\n\n.stTabs [data-baseweb=\"tab\"] {\n    background: #f8f9fa;\n    border: 1px solid #dee2e6;\n    color: #495057;\n    font-weight: 500;\n    padding: 0.75rem 1.5rem;\n    border-radius: 4px 4px 0 0;\n}\n\n.stTabs [aria-selected=\"true\"] {\n    background: #2c3e50;\n    color: white;\n    border-color: #2c3e50;\n}\n\n/* Text inputs */\n.stTextInput > div > div > input {\n    border-radius: 4px;\n    border: 1px solid #ced4da;\n}\n\n.stTextInput > div > div > input:focus {\n    border-color: #2c3e50;\n    box-shadow: 0 0 0 0.2rem rgba(44, 62, 80, 0.25);\n}\n\n/* Clean layout spacing */\n.element-container {\n    margin-bottom: 1rem;\n}\n\n/* Responsive design */\n@media (max-width: 768px) {\n    .main .block-container {\n        padding: 1rem;\n    }\n    \n    .main h1 {\n        font-size: 1.8rem;\n    }\n    \n    [data-testid=\"metric-container\"] > div:nth-child(2) {\n        font-size: 1.4rem;\n    }\n}\n\n/* Remove any hover animations or flashy effects */\n* {\n    transition: none !important;\n}\n\n/* Ensure clean, flat appearance */\n.main .block-container,\n[data-testid=\"metric-container\"],\n.stButton > button,\n.js-plotly-plot {\n    box-shadow: none;\n}","size_bytes":9804}},"version":1}